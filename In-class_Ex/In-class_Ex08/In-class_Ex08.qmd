---
title: "In-class Exercise 8: Geographically Weighted Predictive Models"
author: "Nguyen Bao Thu Phuong"
date: "21 October 2024" 
date-modified: "last-modified"
execute:
  eval: true
  echo: true
  message: false
  freeze: true
---

# Install and Load R Packages

```{r}
pacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse, knitr,kableExtra)
```

# Prepare the Data

## Read data file from rds

The below code chunk reads data from rds file and store in `mdata` as simple feature dataframe.

```{r}
mdata <- read_rds("data/mdata.rds")
```

## Data Sampling

The data is split into train and test data sets with with size of 65% and 35% respectively using `initial_split()` of **rsample** package. **rsample** is one of the package from **tidymodels**.

```{r}
#| eval: false
set.seed(1234)
resale_split <- initial_split(mdata, 
                              prop = 6.5/10,)
train_data <- training(resale_split)
test_data <- testing(resale_split)
```

We write the data to rds format.

```{r}
#| eval: false
write_rds(train_data, "data/train_data.rds")
write_rds(test_data, "data/test_data.rds")
```

Read the data from rds format.

```{r}
train_data <- read_rds("data/train_data.rds")
test_data <- read_rds("data/test_data.rds")
```

## Multicollinearity Check

It is a good practice to use correlation matrix to examine if there is sign of multicollinearity before loading the predictors into a predictive model.

```{r}
#| fig-width: 12
#| fig-height: 10
mdata_nogeo = mdata |>
  st_drop_geometry()
ggstatsplot::ggcorrmat(mdata_nogeo[,2:17])
```

# Build a non-sptial multiple linear regression

```{r}
price_mlr <- lm(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                data=train_data)
olsrr::ols_regress(price_mlr)
```

## Multicollinearity check with VIF

### VIF Table

```{r}
vif = performance::check_collinearity(price_mlr)
kable(vif,
      caption = "Variance Inflator Factor (VIF) Results") |>
  kable_styling(font_size = 10)
```

### VIF Plot

```{r}
plot(vif) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

# Predective Modelling with MLR

## Compute adaptive bandwidth

```{r}
#| eval: false
bw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm +
                  storey_order + remaining_lease_mths +
                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +
                  PROX_MRT + PROX_PARK + PROX_MALL + 
                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                  WITHIN_1KM_PRISCH,
                  data=train_data,
                  approach="CV",
                  kernel="gaussian",
                  adaptive=TRUE,
                  longlat=FALSE)
```

The result shows that 40 neighbour points is the optimal adaptive bandwidth to be used for this data set.

```{r}
#| eval: false
write_rds(bw_adaptive, "data/bw_adaptive.rds")
```

## Construct the adaptive bandwidth gwr model

First we call the save bandwidth using the code chunk below.

```{r}
bw_adaptive <- read_rds("data/bw_adaptive.rds")
```

Now, we go ahead to calibrate the gwr-based hedonic pricing model using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.

```{r}
#| eval: false
gwr_adaptive <- gwr.basic(formula = resale_price ~
                            floor_area_sqm + storey_order +
                            remaining_lease_mths + PROX_CBD + 
                            PROX_ELDERLYCARE + PROX_HAWKER +
                            PROX_MRT + PROX_PARK + PROX_MALL + 
                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                            WITHIN_1KM_PRISCH,
                          data=train_data,
                          bw=bw_adaptive, 
                          kernel = 'gaussian', 
                          adaptive=TRUE,
                          longlat = FALSE)
```

Next the model is saved in rds format for future use.

```{r}
#| eval: false
write_rds(gwr_adaptive, "data/gwr_adaptive.rds")
```

## Retrieve gwr output object

The code chunk below retrieves the save gwr model object.

```{r}
gwr_adaptive <- read_rds("data/gwr_adaptive.rds")
```

The model output can be displayed using below code.

```{r}
gwr_adaptive
```

## Predict with Test Data

```{r}
#| eval: false
gwr_pred <- gwr.predict(formula = resale_price ~
                          floor_area_sqm + storey_order +
                          remaining_lease_mths + PROX_CBD + 
                          PROX_ELDERLYCARE + PROX_HAWKER + 
                          PROX_MRT + PROX_PARK + PROX_MALL + 
                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
                          WITHIN_1KM_PRISCH, 
                        data=train_data, 
                        predictdata = test_data, 
                        bw = bw_adaptive, 
                        kernel = 'gaussian', 
                        adaptive=TRUE, 
                        longlat = FALSE)
```

# Predictive Modelling: SpatialML methods

## Prepare Coordinates data

The code chunk below extracts the x,y coordinates of the full, training and test data sets.

```{r}
coords <- st_coordinates(mdata)
coords_train <- st_coordinates(train_data)
coords_test <- st_coordinates(test_data)
```

We write all the output into rds for future use.

```{r}
coords_train <- write_rds(coords_train, "data/coords_train.rds" )
coords_test <- write_rds(coords_test, "data/coords_test.rds" )
```

## Drop Geometry field

First, we drop the geometry column of the sf data.frame using `st_drop_geometry()` of sf package as `ranger()` function require tible dataframe.

```{r}
train_data_nogeom <- train_data %>% 
  st_drop_geometry()
```

## Calibrate Random Forest model

We calibrate a model to predict HDB resale price using random forest function of **ranger** package.

```{r}
#| eval: false
set.seed(1234)
rf <- ranger(resale_price ~ floor_area_sqm + storey_order + 
               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + 
               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + 
               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + 
               WITHIN_1KM_PRISCH,
             data=train_data_nogeom)
```

```{r}
#| eval: false
write_rds(rf, "data/rf.rds")
```

```{r}
rf <- read_rds("data/rf.rds")
rf
```

## Calibrate with grf()

In this section, we explore how to calibrate a model to predict HDB resale price by using `grf()` of **SpatialML** package.

```{r}
#| eval: false
set.seed(1234)
gwRF_adaptive <- grf(formula = resale_price ~ floor_area_sqm + storey_order +
                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +
                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +
                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +
                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +
                       WITHIN_1KM_PRISCH,
                     dframe=train_data_nogeom, 
                     bw=55,
                     kernel="adaptive",
                     coords=coords_train)
```

The model output is saved into rds format using the below code chunk.

```{r}
#| eval: false
write_rds(gwRF_adaptive, "data/gwRF_adaptive.rds")
```

The below code chunk retrieves the saved model.

```{r}
gwRF_adaptive <- read_rds("data/gwRF_adaptive.rds")
```

## Predict using the test data

### Prepare the test data

The code chunk combines the test data with its corresponding coordinates data.

```{r}
test_data_nogeom <- cbind(test_data, coords_test) %>%
  st_drop_geometry()
```

### Predict with the test data

Next, `predict.grf()` of **spatialML** package is used to predict the resale value using the test data and `gwRF_adaptive` model calibrated earlier.

```{r}
#| eval: false
gwRF_pred <- predict.grf(gwRF_adaptive, 
                           test_data_nogeom, 
                           x.var.name="X",
                           y.var.name="Y", 
                           local.w=1,
                           global.w=0)
```

Before moving on, we save the output into rds file for future usage.

```{r}
#| eval: false
GRF_pred <- write_rds(gwRF_pred, "data/GRF_pred.rds")
```

### Convert the predicting output into a data frame

The output of the `predict.grf()` is a vector of predicted values. It is more efficient to convert it into a data frame for further visualisation and analysis.

```{r}
GRF_pred <- read_rds("data/GRF_pred.rds")
GRF_pred_df <- as.data.frame(GRF_pred)
```

Next `cbind()` is used to append the predicted values onto `test_data`.

```{r}
test_data_p <- cbind(test_data, GRF_pred_df)
```

```{r}
write_rds(test_data_p, "data/test_data_p.rds")
```

## Visualiza the predicted values

```{r}
ggplot(data = test_data_p,
       aes(x = GRF_pred,
           y = resale_price)) +
  geom_point()
```

Plot in map form to see which area the model tends to overestimate/underestimate (how the errors distribute throughout the space).
