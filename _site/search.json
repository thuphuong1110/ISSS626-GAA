[
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "",
    "text": "Import the relevant R package using p_load() of pacman package as in below code chunk.\n\npacman::p_load(GWmodel, sf, spdep, tmap, tidyverse, knitr, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#hunan-shapefile",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#hunan-shapefile",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "2.1 Hunan Shapefile",
    "text": "2.1 Hunan Shapefile\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#hunan-2012-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#hunan-2012-data",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "2.2 Hunan 2012 Data",
    "text": "2.2 Hunan 2012 Data\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#join-hunan-and-hunan-2012-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#join-hunan-and-hunan-2012-data",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "2.3 Join Hunan and Hunan 2012 data",
    "text": "2.3 Join Hunan and Hunan 2012 data\nThe following code chunk uses left_join() from the dplyr package to update the attribute table of hunan’s SpatialPolygonsDataFrame by merging it with the attribute fields from the hunan2012 dataframe.\n\nhunan_sf &lt;- left_join(hunan,hunan2012, by = \"County\" ) %&gt;%\n  select(1:3, 7, 15, 16, 31, 32)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-adaptive-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "5.1 Determine adaptive bandwidth",
    "text": "5.1 Determine adaptive bandwidth\n\nCross-validationAIC\n\n\nCross validation of different bandwidth values is calculated using below code chunk, using approach = CV, longlat = T (to indicate the use of coordinates in degree)\n\nbw_CV = bw.gwr(GDPPC ~ 1, \n               data = hunan_sp,\n               approach = \"CV\",\n               adaptive = TRUE,\n               kernel = \"bisquare\",\n               longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_CV\n\n[1] 22\n\n\n\n\n\nbw_AIC = bw.gwr(GDPPC ~ 1, \n               data = hunan_sp,\n               approach = \"AIC\",\n               adaptive = TRUE,\n               kernel = \"bisquare\",\n               longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\n\nbw_AIC\n\n[1] 22"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#determine-fixed-bandwidth",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "5.2 Determine fixed bandwidth",
    "text": "5.2 Determine fixed bandwidth\n\n5.2.1 Cross Validation\n\nbw_CV_fixed = bw.gwr(GDPPC ~ 1, \n               data = hunan_sp,\n               approach = \"CV\",\n               adaptive = FALSE,\n               kernel = \"bisquare\",\n               longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\n\nbw_CV_fixed\n\n[1] 76.29126\n\n\n\n\n5.2.2 AIC\n\nbw_AIC_fixed = bw.gwr(GDPPC ~ 1, \n               data = hunan_sp,\n               approach = \"AIC\",\n               adaptive = FALSE,\n               kernel = \"bisquare\",\n               longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\n\nbw_AIC_fixed\n\n[1] 160.5517"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#compute-geographically-weighted-summary-statistics",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#compute-geographically-weighted-summary-statistics",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "5.3 Compute geographically weighted summary statistics",
    "text": "5.3 Compute geographically weighted summary statistics\n\ngwstat = gwss(data = hunan_sp,\n              vars = \"GDPPC\",\n              bw = bw_AIC,\n              kernel = \"bisquare\",\n              adaptive = TRUE,\n              longlat = T)\n\nTaking a look at the gwstat gwss object:\n\nGDPPC_LM: the local means of 22 neighbours calculated for all the points\nGDPPC_LVar: the local variance of 22 neighbours calculated for all the points"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#prepare-the-output-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#prepare-the-output-data",
    "title": "In-class Exercise 4: Geographically Weighted Summary Statistics - GWmodel",
    "section": "5.4 Prepare the output data",
    "text": "5.4 Prepare the output data\nThe code chunk below is used to extract SDF data table from gwss object (output from gwss()). It is converted into data.frame using as.data.frame().\n\ngwstat_df = as.data.frame(gwstat$SDF)\n\nNext cbind() is used to append the newly derived data.frame onto hunan_sf sf data frame.\n\nhunan_gstat = cbind(hunan_sf, gwstat_df)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geospatial Analytics and Application (ISSS626)",
    "section": "",
    "text": "1 Welcome to my Geospatial Analytics Learning Journey\nHello there! I am Phuong. Welcome to my ISSS626 Geospatial Analysis and Application homepage. This course is taught by Prof KAM Tin Seong as part of my Master of IT in Business program at Singapore Management University. In this website, you will find my coursework prepared for this course, encompassing practical application of different techniques to transform and analyze spatial data.\n\n\n2 Website Sections\nThe coursework is divided into 3 main sections:\n\n\n\n\n\n\n\n\n\nHands-on Exercise\n\n\n\n\n\n\n\nIn-class Exercise\n\n\n\n\n\n\n\nTake-home Exercise\n\n\n\n\n\n\nHands-on Exercise: Hands-on practice under the guidance given by Prof Kam, using relevant R packages to perform geospatial analysis using public data sources.\nIn-class Exercise: Extend from the methods learned through Hands-on Exercise and include analysis result communication through data visualization.\nTake-home Exercise: Synthesize learning from course materials and above exercises to analyze real-world geospatial cases."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "According to the World Health Organization (WHO) report, road traffic accidents cause 1.19 million deaths annually, with most fatalities occurring in low- and middle-income countries. Vulnerable road users, including pedestrians and motorcyclists, account for over half of these deaths, and road injuries are the leading cause of death for ages 5–29. The economic impact is severe, costing countries 3% of their GDP.\nThailand’s roads are the deadliest in Southeast Asia, with about 20,000 deaths annually. Between 2014 and 2021, Thailand saw a notable rise in accident frequencies. 19% of all accidents occurs on national highways, with most accidents happening on straight roads and at intersections.\n\n\n\nRoad traffic accidents are largely influenced by behavioral factors (driver behavior and performance) and environmental factors (weather and road conditions). While studies using Spatial Point Patterns Analysis (SPPA) have explored these factors, they often overlook temporal elements like season, day in the week, or time during the day.\nThis study will focus on discovering factors affecting road traffic accidents in the Bangkok Metropolitan Region (BMR) - one of the most populated metropolitan regions in Thailand, using different spatio-temporal point pattern analysis techniques:\n\nVisualize the spatio-temporal dynamics of traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nPerform spatial analysis of traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nConduct spatio-temporal analysis using appropriate Temporal Network Spatial Point Patterns Analysis methods.\n\n\n\n\nFor the purpose of this study, 3 data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle: provides statistics on recorded accidents in Thailand from 2019 to 2022. This dataset is in csv format.\nThailand Roads (OpenStreetMap Export) on HDX: road network in Thailand in ESRI shapefile format.\nThailand - Subnational Administrative Boundaries on HDX: boundaries at different administrative levels in Thailand in ESRI shapefile format.\n\nAll these dataset should be downloaded and store in data/rawdata folder under the same folder path with the Quarto document."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "1 Install R packages\nInstall retired maptools package from Posit Public Package Manager\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\nImport other R packages.\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\n\n2 Create Coastal Outline\nWhile sp packages only allow for storing objects as is, sf packages provides other methods to manipulate geospatial data as well.\nWe use st_union() from sf package to create the coastal outline sf tibble data frame and plot the result as below\n\n# Read in Master Plan 2014 Subzone Boundary\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n# Create Coastal outline\nsg_sf = mpsz_sf %&gt;%\n  st_union()\nplot(sg_sf)\n\n\n\n\n\n\n\n\n\n\n3 Import Geospatial Data & Convert to ppp object\nFirst we read in the data and perform data transformation. For sf objects, as.ppp() and as.owin() from spatstat.geom can be used, whereas ppp() and owin() is to be used for sp objects.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nchildcare_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nsg_owin &lt;- as.owin(sg_sf)\nchildcareSG_ppp = childcare_ppp[sg_owin]\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nNext derive adaptive kernel density estimation using the adaptive.density() function from spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\n\n\n\n4 Inspect ppp object\nWe plot the childcare_ppp object using below code chunk\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map\n\n\n\n\n\n\n\n\n\n\n\n5 Kernel Density Estimation\nFunction from maptools can be used as in below code chunk given maptools was installed.\n\ngridded_kde_childcareSG_ad &lt;- maptools::as.SpatialGridDataFrame.im(kde_childcareSG_adaptive)\n\nPlease note that 'maptools' will be retired during October 2023,\nplan transition at your earliest convenience (see\nhttps://r-spatial.org/r/2023/05/15/evolution4.html and earlier blogs\nfor guidance);some functionality will be moved to 'sp'.\n Checking rgeos availability: FALSE\n\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\nThe appropriate way is to using spatstat.geom method as in below code chunk.\n\ngridded_kde_childcareSG_ad &lt;- as(kde_childcareSG_adaptive,\"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_ad)\n\n\n\n\n\n\n\n\n\n\n6 Monte Carlo Simulation\nFirst we set the seed to ensure reproducibility when running Monte Carlo simulation.\n\nset.seed(1234)\n\n\n\n7 Edge correction methods of spatstat\nEdge correction methods are used to handle bias when estimating spatial statistics near the boundaries of the study region. For example, if we are looking at specific study areas with in the region (Singapore boundary in this case). If the study is to be done for the whole Singapore, then edge correction is not needed.\nAs edge correction increase computation time, the argument can be set to none when edge correction is not needed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex01/data/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPAA) is a set of methods specifically designed to analyze spatial point events that occur on or alongside a network, such as traffic accidents or childcare centers along road or river networks.\nIn this hands-on exercise, we explore how to use the spNetwork package to:\n\nDerive network kernel density estimation (NKDE).\nPerform network G-function and K-function analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#prepare-the-lixels-objects",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#prepare-the-lixels-objects",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.1 Prepare the lixels objects",
    "text": "6.1 Prepare the lixels objects\nBefore computing NKDE, the SpatialLines object needs to be divided into lixels (line pixels) with a specified minimum distance. This can be done using the lixelize_lines() function from the spNetwork package, as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)\n\nThe followings are observed from the above code chunk.\n\nThe length of each lixel (lx_length) is set to 700 meters.\nThe minimum length of a lixel (mindist) is set to 375 meters.\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is merged with the previous lixel. If mindist = NULL, then it defaults to maxdist/10. Segments that are already shorter than the minimum distance are left unmodified.\nNote: The lixelize_lines.mc() function offers multicore support for this process."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#generate-line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#generate-line-centre-points",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.2 Generate line centre points",
    "text": "6.2 Generate line centre points\nNext, lines_center() of spNetwork is used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at center of the line based on the length of the line."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#perform-nkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex031.html#perform-nkde",
    "title": "Hands-on Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.3 Perform NKDE",
    "text": "6.3 Perform NKDE\nBefore computing the network density using nkde(), we notice that childcare sf dataframe contains an additional Z dimension with all values equal 0 whereas network only have XY dimension. This will cause error when nkde() try to combine the two dataframes.\nFirst we drop the Z dimension of childcare using below code chunk.\n\nchildcare = st_zm(childcare)\n\nchildcare dimension now only contains XY.\n\nchildcare\n\nSimple feature collection with 61 features and 1 field\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 34423.98 ymin: 41503.6 xmax: 37619.47 ymax: 44685.77\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n      Name                  geometry\n1   kml_10 POINT (36173.81 42550.33)\n2   kml_99 POINT (36479.56 42405.21)\n3  kml_100 POINT (36618.72 41989.13)\n4  kml_101 POINT (36285.37 42261.42)\n5  kml_122  POINT (35414.54 42625.1)\n6  kml_161 POINT (36545.16 42580.09)\n7  kml_172 POINT (35289.44 44083.57)\n8  kml_188 POINT (36520.56 42844.74)\n9  kml_205  POINT (36924.01 41503.6)\n10 kml_222 POINT (37141.76 42326.36)\n\n\nNext the NKDE is computing using below code chunk.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nNote: Some of the key arguments given above code chunk:\n\nThe kernel_name argument indicates that the quartic kernel is being used. Other kernel methods supported by spNetwork include: triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov, or uniform.\nThe method argument specifies that the simple method is used for NKDE calculation. There are three supported methods in spNetwork:\n\nmethod=simple: Proposed by Xie et al. (2008), this method adapts the kernel formula for network distances and calculates density over a linear unit instead of an areal unit.\nmethod=discontinuous: Suggested by Okabe et al. (2008), this method divides mass density equally at intersections of lixels.\nmethod=continuous: Also proposed by Okabe et al. (2008), this version adjusts the density before intersections to create a continuous function while still dividing mass at intersections.\n\n\nIt is recommended to read the spNetwork package user guide for a deeper understanding of the various parameters available for calibrating the NKDE model.\n\n6.3.1 Visualize NKDE\nBefore visualizing the NKDE values, the code chunk below inserts the computed density values (densities) into the samples and lixels objects as a new density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small (e.g., 0.0000005). The code chunk below rescales the density values from events per meter to events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThe above interactive map reveals road segments with relatively higher density of childcare centres (darker color) and road segments with relatively lower density of childcare centres (lighter color)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis examines the pattern or distribution of points on a surface. These points can represent locations of events such as crimes, traffic accidents, or disease outbreaks, as well as business services (like coffee shops and fast food outlets) or facilities like childcare and eldercare centers.\nIn this hands-on exercise, we will use functions from the spatstat package to explore the spatial distribution of childcare centers in Singapore.\nThe key questions we aim to answer are:\n\nAre the childcare centers in Singapore randomly distributed across the country?\nIf not, where are the areas with a higher concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#import-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#import-spatial-data",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Import Spatial Data",
    "text": "4.1 Import Spatial Data\nFirst we use st_read() of sf package used to import these three geospatial data sets into R.\n\nChildcare centresCoastal OutlineMaster Plan 2014 Subzone Boundary\n\n\nAs the childcare_sf simple feature data frame is in wgs84 geodetic CRS, which is not suitable for geospatial analysis, st_transform() of sf package is used to reproject the data frame to svy21 at the same time of import using below code chunk.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe re-check the crs using below code chunk. The EPSG already reflects 3414 as expected.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nGeospatial data is imported using below code chunk.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nCheck the predefined coordinate system of this simple feature data frame using st_crs() of sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe last lines of the print shows that EPSG code 9001 is used instead of the correct EPSG code 3414 for coordinate reference system svy21. The correct EPSG code is assigned using st_set_crs() as below.\n\nsg_sf = st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe check the CRS again.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe EPSG code is now 3414.\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFirst, we check the predefined coordinate system of mpsz_sf simple feature data frame using st_crs().\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nOutput interpretation: The last lines of the print shows that EPSG code 9001 is used instead of the correct EPSG code 3414 for coordinate reference system svy21. The correct EPSG code is assigned to mpsz_sf data frame using st_set_crs() as below.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf,3414)\n\nWe check the CRS again.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe EPSG code is now 3414."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#plot-the-map-from-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#plot-the-map-from-geospatial-data-sets",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Plot the Map from geospatial data sets",
    "text": "4.2 Plot the Map from geospatial data sets\nAfter verifying the coordinate reference system (CRS) of each geospatial dataset, it is helpful to plot a map to visualize their spatial patterns.\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers share the same map extent, indicating that their coordinate reference systems and values are aligned to the same spatial context. This alignment is crucial for any geospatial analysis.\nAlternatively, we can create a pin map using the code snippet below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nIn interactive mode, tmap uses the Leaflet for R API. The benefit of this interactive pin map is that it allows us to freely navigate and zoom in or out. Additionally, we can click on each point to query detailed information about that feature. Three background options of the online map layer are currently available: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap, with ESRI.WorldGrayCanvas set as the default.\nNote: Always switch back to plot mode after using the interactive map, as each interactive session consumes a connection. Additionally, to prevent issues when publishing on Netlify, keep to fewer than 10 interactive maps in a single RMarkdown document."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Convert sf data frames to sp’s Spatial* class",
    "text": "5.1 Convert sf data frames to sp’s Spatial* class\nThe code chunk below uses the as_Spatial() function from the sf package to convert the three geospatial data from simple feature data frames to sp Spatial* classes.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nChildcareCoastal OutlineMaster Plan 2014 Subzone\n\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Convert the Spatial* class into generic sp format",
    "text": "5.2 Convert the Spatial* class into generic sp format\nspatstat requires analytical data in ppp object form. There is no direct method to convert Spatial* classes into ppp objects, so we first need to convert Spatial* classes into generic sp objects.\nThe code chunk below performs this conversion.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nThese sp objects properties are displayed as below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNote: The are certain differences between Spatial* classes and generic sp object. Taking SpatialPointsDataFrame (Spatial* classes) and SpatialPoints (generic sp object) as an example:\n\nSpatialPoints class: used to represent a simple collection of spatial points in a given coordinate system. This class focuses solely on the geometric aspect of spatial data, i.e., the locations of the points.\nSpatialPointsDataFrame class: extends SpatialPoints by combining spatial coordinates with a data frame of attribute data. This class allows you to store both spatial and non-spatial (attribute) data together."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Convert the generic sp format into spatstat’s ppp format",
    "text": "5.3 Convert the generic sp format into spatstat’s ppp format\nNext ppp() function of spatstat is used to convert the SpatialPoints object into spatstat’s ppp object using 2 steps:\n\nExtract the point coordinates from the SpatialPoints object.\nDefine the observation window for the ppp object, usually as a rectangle or polygon encompassing all the points.\n\n\n# Extract the bounding box and point coordinates from the SpatialPoints object\nbbox &lt;- bbox(childcare_sp)\ncoords &lt;- coordinates(childcare_sp)\n# Define the observation window for the ppp object, usually as a rectangle or polygon encompassing all the points.\nwindow &lt;- owin(xrange = bbox[1, ], yrange = bbox[2, ])\n# Convert SpatialPoints object to ppp using ppp()\nchildcare_ppp &lt;- ppp(x = coords[, 1], y = coords[, 2], window = window)\n\nWarning: data contain duplicated points\n\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nWe can see the subzone boundary is not shown and the points are displayed in overlapping characters.\nThe summary statistics of the newly created ppp object is shown using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNote the warning message about duplicates. In spatial point pattern analysis, duplicates are a significant issue. The statistical methods used for spatial point pattern analysis often assume that the processes are simple, meaning that points should not overlap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#handle-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#handle-duplicated-points",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handle duplicated points",
    "text": "5.4 Handle duplicated points\nWe can check if the ppp object contain any duplicated point using below code chunk.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nThe multiplicity() function can be used to count the number of co-incident points.\n\nmultiplicity(childcare_ppp)\n\nThe number of locations having more than one point event is counted using the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output indicates there are 128 duplicated point events.\nTo visualize the locations of these duplicate points, we plot the childcare data using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNote: As alpha defines the transparency of the dots, locations with darker dots (less transparent) indicates duplication since it have multiple points overlaying the same spot.\nThere are three ways to address this issue of duplicated points:\n\nThe simplest method is to delete the duplicates, but this could result in losing valuable point events.\nThe second option is to use jittering, which adds a small perturbation to the duplicate points so they no longer occupy the exact same location.\nThe third approach is to make each point “unique” and attach duplicates as marks or attributes to these points. This requires using analytical techniques that consider these marks.\n\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nWe check again for duplication.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nThe output is FALSE indicating there are no duplicated point in childcare_ppp_jit"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#create-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#create-owin-object",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Create owin object",
    "text": "5.5 Create owin object\nWhen analyzing spatial point patterns, it is important to limit the analysis to a specific geographical area, such as the boundary of Singapore. In spatstat, an object called owin is specifically designed to represent such polygonal regions.\nThe code chunk below converts the sg simple feature object into an owin object for use in spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nPlot the output object using plot() function.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nView the summary using summary() of Base R.\n\nsummary(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#combine-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#combine-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combine point events object and owin object",
    "text": "5.6 Combine point events object and owin object\nIn this final step of geospatial data wrangling, we use the below code chunk to extract childcare events that are located within Singapore boundary.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combines both the point and polygon features into a single ppp object class, as shown below.\n\nsummary(childcareSG_ppp)\n\nPlot the output object.\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#kernel-density-estimation",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.1 Kernel Density Estimation",
    "text": "6.1 Kernel Density Estimation\n\n6.1.1 Compute Kernel Density Estimation using Automatic Bandwidth Selection method\nThe code chunk below computes a kernel density estimation using spatstat package’s density() function with the following configurations:\n\nBandwidth selection method: bw.diggle() is used for automatic bandwidth selection. Other recommended methods include bw.CvL(), bw.scott(), or bw.ppl().\nSmoothing kernel: The Gaussian kernel is used by default. Other available smoothing methods are “epanechnikov,” “quartic,” and “disc.”\nEdge effect bias correction: The intensity estimate is corrected for edge effects using the method described by Jones (1993) and Diggle (2010, equation 18.9). This correction is set to TRUE by default.\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\nWe use the plot() function of Base R to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe density values in the output range from 0 to 0.000035 (the bar on the right hand side), which is too small to interpret easily. This is because the default unit of measurement for svy21 is meters, so the computed density values are in “number of points per square meter.”\nThe bandwidth used to compute the KDE layer can be retrieved using below code chunk.\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n6.1.2 Rescale KDE values\nWe can covert the unit of measurement from meter to kilometer using rescale.ppp().\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nRe-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, \n                              sigma=bw.diggle, \n                              edge=TRUE, \n                              kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\n\n\n\n\nThe output map looks identical to the earlier version, the only difference is the density values range (the legend on the right)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#work-with-different-automatic-bandwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#work-with-different-automatic-bandwidth-methods",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.2 Work with different Automatic Bandwidth Methods",
    "text": "6.2 Work with different Automatic Bandwidth Methods\nApart from bw.diggle(), there are three other spatstat functions that can be used to determine the bandwidth: bw.CvL(), bw.scott(), and bw.ppl().\nLet’s examine the bandwidth values returned by these automatic calculation methods using below code chunk.\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et al. (2016) suggested using bw.ppl() algorithm because, in their experience, it tends to produce more appropriate values when the point pattern mainly consists of tight clusters. However, if the goal of a study is to detect a single tight cluster within random noise, the bw.diggle() method is considered by them to be the best choice.\nThe code chunk below compare the outputs of the bw.diggle() and bw.ppl() methods.\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\nThere are no significant difference between the 2 plots. However the output map using bw.ppl seems to have more areas with high density values (more areas colored in the higher value range)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#work-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#work-with-different-kernel-methods",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "6.3 Work with different kernel methods",
    "text": "6.3 Work with different kernel methods\nBy default, the kernel method used in density.ppp() is Gaussian. However, there are three other options: Epanechnikov, Quartic, and Disc.\nThe code chunk below compute three additional kernel density estimations using these kernel functions and plot the output of all four kernel methods for comparison.\n\npar(mfrow=c(2,2))\nsigma_val = bw.ppl(childcareSG_ppp.km)\nplot(density(childcareSG_ppp.km, \n             sigma=sigma_val, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=sigma_val, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=sigma_val, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=sigma_val, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#computing-kde-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#computing-kde-using-fixed-bandwidth",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.1 Computing KDE using fixed bandwidth",
    "text": "7.1 Computing KDE using fixed bandwidth\nNext we compute a Kernel Density Estimation (KDE) layer by defining a bandwidth of 600 meters. In the below code chunk, the sigma value is set to 0.6 since the unit of measurement of childcareSG_ppp.km object is in kilometers, so 600 meters = 0.6 kilometers.\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, \n                               sigma=0.6, \n                               edge=TRUE, \n                               kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#compute-kde-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#compute-kde-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.2 Compute KDE using adaptive bandwidth",
    "text": "7.2 Compute KDE using adaptive bandwidth\nAs fixed bandwidth methods is very sensitive to highly skewed distributions of spatial point patterns across different geographical units, such as urban and rural areas. To address this issue, we can use adaptive bandwidth methods.\nIn this section, we explore how to derive adaptive kernel density estimation using the adaptive.density() function from spatstat.\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs using below code chunk.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed Bandwith\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive Bandwith\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-kde-output-into-grid-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#convert-kde-output-into-grid-object",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.3 Convert KDE output into grid object",
    "text": "7.3 Convert KDE output into grid object\nThe result is the same, the conversion is to make the data suitable for mapping purposes.\nThe KDE output is in pixel image as shown below.\n\nsummary(kde_childcareSG.bw)\n\nreal-valued pixel image\n128 x 128 pixel array (ny, nx)\nenclosing rectangle: [2.663926, 56.04779] x [16.35798, 50.24403] km\ndimensions of each pixel: 0.417 x 0.2647348 km\nImage is defined on a subset of the rectangular grid\nSubset area = 726.060565732197 square km\nSubset area fraction = 0.401\nPixel values (inside window):\n    range = [-8.476185e-15, 28.51831]\n    integral = 1547.222\n    mean = 2.130982\n\n\nThe KDE output image is converted to SpatialGridDataFrame and plot using below code.\n\n# Convert image output to SpatialGridDataFrame\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\n\n# Plot the SpatialGridDataFrame\nspplot(gridded_kde_childcareSG_bw, main = \"Kernel Density Estimate\")\n\n\n\n\n\n\n\n\n\n7.3.1 Convert gridded output into raster\nWe convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nkde_childcareSG_bw_raster &lt;- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNote: the crs property is NA.\n\n\n7.3.2 Assign projection systems\nThe code chunk below assigns the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nThe CRS property is completed now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#visualize-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#visualize-the-output-in-tmap",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.4 Visualize the output in tmap",
    "text": "7.4 Visualize the output in tmap\nWe display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\n**Note*: The raster values are encoded explicitly onto the raster pixel using the values in “v”” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#compare-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#compare-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "7.5 Compare Spatial Point Patterns using KDE",
    "text": "7.5 Compare Spatial Point Patterns using KDE\nIn this section, we explore how to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n7.5.1 Extract study area\nThe below code chunk is used to extract the 4 target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot the target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n\n7.5.2 Create owin object\nWe convert these sf objects into owin objects as required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n7.5.3 Combine childcare points and the study area\nWe extract childcare centres within the selected regions for further analysis.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n7.5.4 Compute KDE\nThe below code chunk computes the KDE of these four planning area. bw.diggle method is used to derive the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\n\nWarning: Berman-Diggle Cross-Validation criterion was minimised at right-hand\nend of interval [0, 0.245]; use argument 'hmax' to specify a wider interval for\nbandwidth 'sigma'\n\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n\n\n\n\n7.5.5 Compute fixed bandwidth KDE\n250m bandwidth is used in below code chunk for comparison purpose.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex021.html#clark-and-evans-test",
    "title": "Hands-on Exercise 2.1: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "8.1 Clark and Evans Test",
    "text": "8.1 Clark and Evans Test\n\nSingapore NationwideChoa Chu Kang planning areaTampinesJurong WestPunggol\n\n\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nAs p-value is smaller than 0.05, we can reject the null hypothesis and infer that the distribution of childcare centres in Singapore is not random but rather clustered (due to alternative=“clustered”).\n\n\nWe use clarkevans.test() to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.98729, p-value = 0.8494\nalternative hypothesis: two-sided\n\n\nAs p-value is larger than 0.05, we cannot reject the null hypothesis that the distribution of childcare centre in Choa Chu Kang is randomly distributed.\n\n\nWe use clarkevans.test() to performs Clark-Evans test of aggregation for childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.79124, p-value = 0.0001648\nalternative hypothesis: two-sided\n\n\nAs p-value is smaller than 0.05, we can reject the null hypothesis and infer that the distribution of childcare centres in Tampines is not random but either have a clustered or regular pattern (due to alternative=“two.sided”).\nThe below density map shows that the distribution in Tampines is rather clustered.\n\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")\n\n\n\n\n\n\n\n\n\n\nWe use clarkevans.test() to performs Clark-Evans test of aggregation for childcare centre in Jurong West planning area.\n\nclarkevans.test(childcare_jw_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_jw_ppp\nR = 0.90301, p-value = 0.08177\nalternative hypothesis: two-sided\n\n\nAs p-value is larger than 0.05, we cannot reject the null hypothesis that the distribution of childcare centre in Jurong West is randomly distributed.\n\n\nWe use clarkevans.test() to performs Clark-Evans test of aggregation for childcare centre in Punggol planning area.\n\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.88762, p-value = 0.09314\nalternative hypothesis: two-sided\n\n\nAs p-value is larger than 0.05, we cannot reject the null hypothesis that the distribution of childcare centre in Punggol is randomly distributed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis examines the pattern or distribution of points on a surface. These points can represent locations of events such as crimes, traffic accidents, or disease outbreaks, as well as business services (like coffee shops and fast food outlets) or facilities like childcare and eldercare centers.\nIn this hands-on exercise, we will use functions from the spatstat package to explore the spatial distribution of childcare centers in Singapore.\nThe key questions we aim to answer are:\n\nAre the childcare centers in Singapore randomly distributed across the country?\nIf not, where are the areas with a higher concentration of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#import-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#import-spatial-data",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.1 Import Spatial Data",
    "text": "4.1 Import Spatial Data\nFirst we use st_read() of sf package used to import these three geospatial data sets into R.\n\nChildcare centresCoastal OutlineMaster Plan 2014 Subzone Boundary\n\n\nAs the childcare_sf simple feature data frame is in wgs84 geodetic CRS, which is not suitable for geospatial analysis, st_transform() of sf package is used to reproject the data frame to svy21 at the same time of import using below code chunk.\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWe re-check the crs using below code chunk. The EPSG already reflects 3414 as expected.\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\nGeospatial data is imported using below code chunk.\n\nsg_sf &lt;- st_read(dsn = \"data\", layer = \"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nCheck the predefined coordinate system of this simple feature data frame using st_crs() of sf package.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nThe last lines of the print shows that EPSG code 9001 is used instead of the correct EPSG code 3414 for coordinate reference system svy21. The correct EPSG code is assigned using st_set_crs() as below.\n\nsg_sf = st_set_crs(sg_sf, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\n\nWe check the CRS again.\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe EPSG code is now 3414.\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nFirst, we check the predefined coordinate system of mpsz_sf simple feature data frame using st_crs().\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nOutput interpretation: The last lines of the print shows that EPSG code 9001 is used instead of the correct EPSG code 3414 for coordinate reference system svy21. The correct EPSG code is assigned to mpsz_sf data frame using st_set_crs() as below.\n\nmpsz_sf &lt;- st_set_crs(mpsz_sf,3414)\n\nWe check the CRS again.\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe EPSG code is now 3414."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#plot-the-map-from-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#plot-the-map-from-geospatial-data-sets",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "4.2 Plot the Map from geospatial data sets",
    "text": "4.2 Plot the Map from geospatial data sets\nAfter verifying the coordinate reference system (CRS) of each geospatial dataset, it is helpful to plot a map to visualize their spatial patterns.\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +\ntm_shape(childcare_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nNotice that all the geospatial layers share the same map extent, indicating that their coordinate reference systems and values are aligned to the same spatial context. This alignment is crucial for any geospatial analysis.\nAlternatively, we can create a pin map using the code snippet below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nIn interactive mode, tmap uses the Leaflet for R API. The benefit of this interactive pin map is that it allows us to freely navigate and zoom in or out. Additionally, we can click on each point to query detailed information about that feature. Three background options of the online map layer are currently available: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap, with ESRI.WorldGrayCanvas set as the default.\nNote: Always switch back to plot mode after using the interactive map, as each interactive session consumes a connection. Additionally, to prevent issues when publishing on Netlify, keep to fewer than 10 interactive maps in a single RMarkdown document."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.1 Convert sf data frames to sp’s Spatial* class",
    "text": "5.1 Convert sf data frames to sp’s Spatial* class\nThe code chunk below uses the as_Spatial() function from the sf package to convert the three geospatial data from simple feature data frames to sp Spatial* classes.\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\n\nChildcareCoastal OutlineMaster Plan 2014 Subzone\n\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\n\n\nThe geospatial data have been converted into their respective sp’s Spatial* classes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.2 Convert the Spatial* class into generic sp format",
    "text": "5.2 Convert the Spatial* class into generic sp format\nspatstat requires analytical data in ppp object form. There is no direct method to convert Spatial* classes into ppp objects, so we first need to convert Spatial* classes into generic sp objects.\nThe code chunk below performs this conversion.\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nThese sp objects properties are displayed as below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\nNote: The are certain differences between Spatial* classes and generic sp object. Taking SpatialPointsDataFrame (Spatial* classes) and SpatialPoints (generic sp object) as an example:\n\nSpatialPoints class: used to represent a simple collection of spatial points in a given coordinate system. This class focuses solely on the geometric aspect of spatial data, i.e., the locations of the points.\nSpatialPointsDataFrame class: extends SpatialPoints by combining spatial coordinates with a data frame of attribute data. This class allows you to store both spatial and non-spatial (attribute) data together."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#convert-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.3 Convert the generic sp format into spatstat’s ppp format",
    "text": "5.3 Convert the generic sp format into spatstat’s ppp format\nNext ppp() function of spatstat is used to convert the SpatialPoints object into spatstat’s ppp object using 2 steps:\n\nExtract the point coordinates from the SpatialPoints object.\nDefine the observation window for the ppp object, usually as a rectangle or polygon encompassing all the points.\n\n\n# Extract the bounding box and point coordinates from the SpatialPoints object\nbbox &lt;- bbox(childcare_sp)\ncoords &lt;- coordinates(childcare_sp)\n# Define the observation window for the ppp object, usually as a rectangle or polygon encompassing all the points.\nwindow &lt;- owin(xrange = bbox[1, ], yrange = bbox[2, ])\n# Convert SpatialPoints object to ppp using ppp()\nchildcare_ppp &lt;- ppp(x = coords[, 1], y = coords[, 2], window = window)\n\nWarning: data contain duplicated points\n\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nWe plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nWe can see the subzone boundary is not shown and the points are displayed in overlapping points.\nThe summary statistics of the newly created ppp object is shown using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNote the warning message about duplicates. In spatial point pattern analysis, duplicates are a significant issue. The statistical methods used for spatial point pattern analysis often assume that the processes are simple, meaning that points should not overlap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#handle-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#handle-duplicated-points",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4 Handle duplicated points",
    "text": "5.4 Handle duplicated points\nWe can check if the ppp object contain any duplicated point using below code chunk.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nThe multiplicity() function can be used to count the number of co-incident points.\n\nmultiplicity(childcare_ppp)\n\nThe number of locations having more than one point event is counted using the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output indicates there are 128 duplicated point events.\nTo visualize the locations of these duplicate points, we plot the childcare data using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nNote: As alpha defines the transparency of the dots, locations with darker dots (less transparent) indicates duplication since it have multiple points overlaying the same spot.\nThere are three ways to address this issue of duplicated points:\n\nThe simplest method is to delete the duplicates, but this could result in losing valuable point events.\nThe second option is to use jittering, which adds a small perturbation to the duplicate points so they no longer occupy the exact same location.\nThe third approach is to make each point “unique” and attach duplicates as marks or attributes to these points. This requires using analytical techniques that consider these marks.\n\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nWe check again for duplication.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\nThe output is FALSE indicating there are no duplicated point in childcare_ppp_jit"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#create-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#create-owin-object",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5 Create owin object",
    "text": "5.5 Create owin object\nWhen analyzing spatial point patterns, it is important to limit the analysis to a specific geographical area, such as the boundary of Singapore. In spatstat, an object called owin is specifically designed to represent such polygonal regions.\nThe code chunk below converts the sg simple feature object into an owin object for use in spatstat.\n\nsg_owin &lt;- as.owin(sg_sf)\n\nPlot the output object using plot() function.\n\nplot(sg_owin)\n\n\n\n\n\n\n\n\nView the summary using summary() of Base R.\n\nsummary(sg_owin)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#combine-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#combine-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.6 Combine point events object and owin object",
    "text": "5.6 Combine point events object and owin object\nIn this final step of geospatial data wrangling, we use the below code chunk to extract childcare events that are located within Singapore boundary.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combines both the point and polygon features into a single ppp object class, as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nPlot the output object.\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#extract-study-areas",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex022.html#extract-study-areas",
    "title": "Hands-on Exercise 2.2: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7 Extract study areas",
    "text": "5.7 Extract study areas\nThe below code chunk is used to extract the 4 target planning areas.\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlot the target planning areas.\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\n\n\n\n\n5.7.1 Create owin object\nWe convert these sf objects into owin objects as required by spatstat.\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n5.7.2 Combine childcare points and the study area\nWe extract childcare centres within the selected regions for further analysis.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale.ppp() function is used to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2), mai = c(0.2,0.2,0.2,0.2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "",
    "text": "In this exercise, you explore how to compute spatial weights in R using below functions:\n\nImport geospatial data using functions from the sf package.\nImport a CSV file using the readr package.\nPerform relational joins with functions from the dplyr package.\nCompute spatial weights using the spdep package.\nCalculate spatially lagged variables with functions from the spdep package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#perform-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#perform-relational-join",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "4.1 Perform Relational Join",
    "text": "4.1 Perform Relational Join\nThe following code chunk uses left_join() from the dplyr package to update the attribute table of hunan’s SpatialPolygonsDataFrame by merging it with the attribute fields from the hunan2012 dataframe.\n\nhunan &lt;- left_join(hunan,hunan2012, by = \"County\" ) %&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.1 Compute (QUEEN) contiguity based neighbours",
    "text": "6.1 Compute (QUEEN) contiguity based neighbours\nThe code chunk below computes Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report indicates there are 88 area units in Hunan. The most connected unit has 11 neighbors, while two units have only one neighbor each.\nFor each polygon in our object, wm_q lists all neighboring polygons. To view the neighbors for the first polygon, use the following command:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The output numbers represent the polygon IDs in the hunan SpatialPolygonsDataFrame.\nWe can use the following code to retrieve the county name for Polygon ID 1:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output shows that Polygon ID 1 corresponds to Anxiang County.\nTo display the county names of the five neighboring polygons, we can use the following code.\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries using the below code chunk.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe above output reveals that GDP per capita (GDPPC) of the five nearest neighbors based on Queen’s method are: 20,981; 34,592; 24,473; 21,311; and 22,879 respectively.\nWe can use str() to view the complete weight matrix.\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nNote: The output might cut across several pages. Save the trees if you are going to print out the report."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#create-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#create-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.2 Create (ROOK) contiguity based neighbours",
    "text": "6.2 Create (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary output shows that there are 88 area units in Hunan. The most connected unit has 10 neighbours while there are 2 area units with only 1 neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#visualize-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#visualize-contiguity-weights",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "6.3 Visualize contiguity weights",
    "text": "6.3 Visualize contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. Since we are working with polygons, the centroids will serve as points for the connectivity graph. We will calculate these centroids and extract the latitude and longitude coordinates before moving on to the graphs.\nWe will use the sf package to calculate centroids and purrr package’s map_dbl function to extract the coordinates. Here’s the breakdown:\n\nCalculate Centroids: Use st_centroid() from the sf package to calculate the centroids of polygons.\nExtract Coordinates: Apply the st_centroid() function over the geometry column to get the longitude and latitude values.\nMapping Function: Use the map_dbl() function from the purrr package to extract only the first (longitude) and second (latitude) values of each centroid. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of hunan. Our function will be st_centroid().\n\nTo extract the longitude values from the centroids of polygons, we apply the st_centroid() function to the geometry column and access the first value (longitude) of each centroid. This is achieved using double bracket notation [[]] and 1 as below:\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nThe same can be done for latitude with one key difference: we access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNext we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n6.3.1 Plot Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n6.3.2 Plot Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n\n\n\n\n6.3.3 Plot both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.1 Determine the cut-off distance",
    "text": "7.1 Determine the cut-off distance\nThe below steps are used to determine the upper limit for a distance band:\n\nUse knearneigh() from spdep to get a matrix with the indices of points belonging to the set of k-nearest neighbors.\nConvert the returned knn object to a neighbors list of class nb with a list of integer vectors containing neighbor region’s ids using knn2nb().\nCalculate the distances between neighbors with nbdists(). This function returns the result in the units of the coordinates if the coordinates are projected, in kilometer otherwise.\nRemove the list structure with unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary output shows that the largest first nearest neighbour distance is 61.79 km. Using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.2 Compute fixed distance weight matrix",
    "text": "7.2 Compute fixed distance weight matrix\nNext we compute the distance weight matrix using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe Average number of links: 3.681818 means on average, each region has about 3.68 neighboring regions (connections) within the distance range from 0 to 62 km. If this number is small, it suggests sparse connections between regions, whereas a larger number would indicate more densely connected regions.\nNext, we use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to use a combination of the table() and card()functionof spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n7.2.1 Plot fixed distance weight matrix\nWe plot the distance weight matrix by using below code chunk.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines indicate 1st nearest neighbor links, while the black lines represent neighbors within 62 km. Alternatively, both can be plotted side by side using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex041.html#compute-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 4: Spatial Weights and Applications",
    "section": "7.3 Compute adaptive distance weight matrix",
    "text": "7.3 Compute adaptive distance weight matrix\nIn a fixed-distance weight matrix, densely populated areas (typically urban) tend to have more neighbors, while sparsely populated areas (typically rural) have fewer. More neighbors smooth the relationships. You can control the number of neighbors directly using k-nearest neighbors, allowing either asymmetric or symmetric neighbors, as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNote: each county has exactly 6 neighbours.\n\n7.3.1 Plot distance based neighbours\nThe weight matrix is plotted using below code chunk.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#master-plan-2014-subzone-boundary",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#master-plan-2014-subzone-boundary",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "2.1 Master Plan 2014 Subzone Boundary",
    "text": "2.1 Master Plan 2014 Subzone Boundary\nImport Master Plan 2014 Subzone Boundary in shapefile and kml format\n\nShapefileKML\n\n\n\nmpsz14_shp = st_read(dsn = 'data', layer = 'MP14_SUBZONE_WEB_PL')\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nmpsz14_kml = st_read(\"data/MasterPlan2014SubzoneBoundaryWebKML.kml\")\n\nAs the kml file downloaded is corrupted, we can write the shapefile back as kml format using below code chunk.\n\nst_write(mpsz14_shp,\n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#master-plan-2019-subzone-boundary",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#master-plan-2019-subzone-boundary",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "2.2 Master Plan 2019 Subzone Boundary",
    "text": "2.2 Master Plan 2019 Subzone Boundary\nNext we load the master plan 2019 in shapefile and kml.\n\nShapefileKML format\n\n\n\nmpsz19_shp = st_read(dsn = \"data\", layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nThe shapefile is in geographic coordinate system wgs84. This is commonly used in maps application on phone, as it’s useful to recognize a location. However, this is not appropriate to be used in geospatial analysis as wgs84 reflects the degree of the lat-long, impacting the distance measurement. For this purpose, projected coordinate system should be used.\n\n\n\nmpsz19_kml = st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#pre-school-location",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#pre-school-location",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "2.3 Pre-school Location",
    "text": "2.3 Pre-school Location\nWe import the pre-school location in KML and Geojson format\nImport KML file\n\npreschool_kml = st_read(\"data/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nImport Geojson file\n\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\") \n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#transform-coordinate-system",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#transform-coordinate-system",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "3.1 Transform coordinate system",
    "text": "3.1 Transform coordinate system\nWe import Master Plan Sub-zone 2019 and Pre-school location again and reproject from geodetic CRS to projected coordinate system using below code chunk.\nImport Master Plan Sub-zone 2019\n\nmpsz19_shp = st_read(dsn = \"data\",\n                     layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\nImport Pre-school location\n\npreschool &lt;- st_read(\"data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#point-in-polygon-count",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#point-in-polygon-count",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "4.1 Point-in-polygon count",
    "text": "4.1 Point-in-polygon count\nThe number of pre-school in each planning subzone can be counted using below code chunk.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#compute-density",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#compute-density",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "4.2 Compute Density",
    "text": "4.2 Compute Density\nCalculate the area of each subzone and compute the density of pre-school per square kilometers in at planning subzone level.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`Area` = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-wrangling",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-wrangling",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.1 Data Wrangling",
    "text": "6.1 Data Wrangling\nThe below code chunk prepare a data.frame showing population by Planning Area and Planning subzone.\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#data-processing",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.2 Data Processing",
    "text": "6.2 Data Processing\nThe below code chunk code chunk derives a tibble data.framewith the following fields PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY whereby:\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group.\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#join-the-population-data-and-master-planning-subzone-2019",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#join-the-population-data-and-master-planning-subzone-2019",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.3 Join the Population Data and Master Planning Subzone 2019",
    "text": "6.3 Join the Population Data and Master Planning Subzone 2019\nBefore performing the georelational join, we convert the values in PA and SZ fields to uppercase, as the original values in these fields are made up of upper and lowercase, while SUBZONE_N and PLN_AREA_N values are in uppercase.\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\nUse mpsz19_shp as left table.\n\nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nUse popdata2023 as left table.\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#choropleth-map-of-dependency-ratio-by-planning-subzone",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.4 Choropleth Map of Dependency Ratio by Planning Subzone",
    "text": "6.4 Choropleth Map of Dependency Ratio by Planning Subzone\n\ntm_shape(mpsz_pop2023)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE,\n            bg.color = \"bisque\") +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\",\n             position = c(\"left\", \"bottom\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#percentile-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#percentile-map",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.5 Percentile Map",
    "text": "6.5 Percentile Map\nA percentile map is a specific type of quantile map with six categories: 0-1%, 1-10%, 10-50%, 50-90%, 90-99%, and 99-100%. The breakpoints for these categories can be determined using the base R quantile() function, with a vector of cumulative probabilities specified as c(0, .01, .1, .5, .9, .99, 1). Ensure to include both the beginning and end points.\nFirst we exclude records with NA using below code chunk.\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\n\nNext we define a function to get the input data and field to be used for creating the percentile map.\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nThe code chunk below creates a function for computing and plotting the percentile map.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\nThe defined function is used to plot the percentile map.\n\npercentmap(\"DEPENDENCY\", mpsz_pop2023)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#box-map",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#box-map",
    "title": "In-class Exercise 1: Geospatial Data Science with R",
    "section": "6.6 Box Map",
    "text": "6.6 Box Map\nA box map is an enhanced quartile map that includes additional lower and upper categories. If there are lower outliers, the breaks start with the minimum value, followed by the lower fence. If there are no lower outliers, the breaks start at the lower fence, with the second break at the minimum value. In this case, no observations will fall between the lower fence and the minimum value.\nFirst we define below function to create break points for a box map.\nArguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nOutput:\n\nbb: vector with 7 break points computed quartile and fences\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\nNext get.var function is defined to extract a variable as a vector out of an sf data frame.\nArguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nReturns:\n\nv: vector with values (without a column name)\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\nFinally, the boxmap function is defined to create a box map.\nArguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nReturns:\n\na tmap-element (plots a map)\n\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\nPlotting a box map on DEPENDENCY.\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\n\n\n\nPlot the box map in view mode\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "",
    "text": "Network Constrained Spatial Point Patterns Analysis (NetSPAA) is a set of methods specifically designed to analyze spatial point events that occur on or alongside a network, such as traffic accidents or childcare centers along road or river networks.\nIn this hands-on exercise, we explore how to use the spNetwork package to:\n\nDerive network kernel density estimation (NKDE).\nPerform network G-function and K-function analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#prepare-the-lixels-objects",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#prepare-the-lixels-objects",
    "title": "In-class Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.1 Prepare the lixels objects",
    "text": "6.1 Prepare the lixels objects\nBefore computing NKDE, the SpatialLines object needs to be divided into lixels (line pixels) with a specified minimum distance. This can be done using the lixelize_lines() function from the spNetwork package, as shown in the code chunk below.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 350)\n\nThe followings are observed from the above code chunk.\n\nThe length of each lixel (lx_length) is set to 700 meters. This is a reasonable walking distance for parents/grandparents to walk their kids to the childcare centre.\nThe minimum length of a lixel (mindist) is set to 350 meters.\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is merged with the previous lixel. If mindist = NULL, then it defaults to maxdist/10. Segments that are already shorter than the minimum distance are left unmodified.\nNote: The lixelize_lines.mc() function offers multicore support for this process."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#generate-line-centre-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#generate-line-centre-points",
    "title": "In-class Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.2 Generate line centre points",
    "text": "6.2 Generate line centre points\nNext, lines_center() of spNetwork is used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels) \n\nThe points are located at center of the line based on the length of the line.\nPlotting the lixel and sampling points\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels) +\n  tm_lines() +\ntm_shape(samples) +\n  tm_dots(size = 0.01)\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#perform-nkde",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#perform-nkde",
    "title": "In-class Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.3 Perform NKDE",
    "text": "6.3 Perform NKDE\nThe NKDE is computed using below code chunk.\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nNote: Some of the key arguments given above code chunk:\n\nThe kernel_name argument indicates that the quartic kernel is being used. Other kernel methods supported by spNetwork include: triangle, gaussian, scaled gaussian, tricube, cosine, triweight, epanechnikov, or uniform.\nThe method argument specifies that the simple method is used for NKDE calculation. There are three supported methods in spNetwork:\n\nmethod=simple: Proposed by Xie et al. (2008), this method adapts the kernel formula for network distances and calculates density over a linear unit instead of an areal unit.\nmethod=discontinuous: Suggested by Okabe et al. (2008), this method divides mass density equally at intersections of lixels.\nmethod=continuous: Also proposed by Okabe et al. (2008), this version adjusts the density before intersections to create a continuous function while still dividing mass at intersections.\n\n\nIt is recommended to read the spNetwork package user guide for a deeper understanding of the various parameters available for calibrating the NKDE model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "Thematic mapping uses map symbols to represent specific characteristics of geographic features that are not naturally visible, such as population, temperature, crime rates, and property prices. This allows us to visualize data that would otherwise remain unseen.\nOn the other hand, geovisualization provides graphical representations to make places, phenomena, or processes more understandable. It leverages the power of spatial cognition associated with our eye-brain vision system, enhancing our ability to process and interpret spatial information.\nIn this chapter, we explore how to create accurate and meaningful choropleth maps using the tmap package in R."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-acquisition",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.1 Data Acquisition",
    "text": "3.1 Data Acquisition\n\nMaster Plan 2014 Subzone Boundary (Web) (MP14_SUBZONE_WEB_PL) from data.gov.sg: this geospatial data is in ESRI shapefile format, which consists of the geographical boundary of Singapore at the planning subzone level. The data is based on the URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 (respopagesextod2011to2020.csv) from Department of Statistics, Singapore: this is aspatial data in csv format. Although it does not contain any coordinates values, its PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#import-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#import-geospatial-data-into-r",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.2 Import Geospatial Data into R",
    "text": "3.2 Import Geospatial Data into R\nMP14_SUBZONE_WEB_PL shapefile: st_read() function of sf package is used to import this shapefile into R as a simple feature data frame called mpsz.\n\nmpsz = st_read(dsn = \"data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can quickly examine the content of mpsz using below code.\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nNote: only the first 10 records are shown, as this is the default display of R to minimize resource usage and avoid overwhelming user. To specify the number of rows to be shown, head() function with n arguments can be used instead. For example, head(mpsz, n = 15) shows the first 15 rows of the mpsz data frame ."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#import-attribute-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#import-attribute-data-into-r",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "3.3 Import Attribute Data into R",
    "text": "3.3 Import Attribute Data into R\nrespopagsex2011to2020.csv file: the aspatial data file is imported into R as a dataframe named popdata using read_csv() function of readr package as below.\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-wrangling",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.1 Data Wrangling",
    "text": "4.1 Data Wrangling\nThe data table is prepared following below steps:\n\nfilter(), group_by(): filter for records in year 2020 and group by PA, SZ, AG columns.\nsummarise(): for each combination of PA, SZ, AG, calculates the total population (POP) by summing up the values in the Pop column.\nungroup(): removes the grouping, making the data available for further manipulation without any group context.\npivot_wider(): reshapes the data from long to wide format. It creates new columns for each unique value in the AG (age group) column, and the values in these new columns are populated with the corresponding POP values.\nmutate(): calculates the assigned variable by summing the values from respective columns. For example, total population of YOUNG age group is calculated by summing the values in columns 3 to 6 and column 12.\nselect(): selects the final columns to include in the result popdata2020 data frame.\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#join-the-attribute-data-and-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#join-the-attribute-data-and-geospatial-data",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "4.2 Join the Attribute Data and Geospatial Data",
    "text": "4.2 Join the Attribute Data and Geospatial Data\nBefore performing the georelational join, we convert the values in PA and SZ fields to uppercase, as the original values in these fields are made up of upper and lowercase, while SUBZONE_N and PLN_AREA_N values are in uppercase. The below code converts the values to upper case and filter for records where the population in ECONOMY ACTIVE column is more than 0.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, left_join() of dplyr is used to join the geographical data and attribute table using planning subzone name e.g. SUBZONE_N and SZ as the common identifier.\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nNote: left_join() of dplyr package is used with mpsz simple feature data frame as the left data table to ensure that the output will be a simple features data frame.\nLastly, write_rds() is used to write the combined data frame into an RDS file. Ensure the respective folders are available before running the below code.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#plot-a-choropleth-map-quickly-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#plot-a-choropleth-map-quickly-using-qtm",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.1 Plot a Choropleth Map quickly using qtm()",
    "text": "5.1 Plot a Choropleth Map quickly using qtm()\nThe easiest and quickest way to draw a choropleth map with tmap is using qtm(). It provides a concise default visualisation in many cases.\nThe below code chunk plots a cartographic standard choropleth map.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used define the attribute to plot on the map (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#create-a-choropleth-map-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#create-a-choropleth-map-using-tmaps-elements",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.2 Create a Choropleth Map using tmap’s elements",
    "text": "5.2 Create a Choropleth Map using tmap’s elements\nAlthough using qtm() is fast and easy, it makes aesthetics of individual layers harder to control. tmap’s drawing elements are used to draw a high quality cartographic choropleth map as shown in below figure.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn the following sub-sections, we explore different tmap functions that can be used to plot these elements.\n\nBase map (tm_shape())tm_polygons()tm_fill() and tm_border()\n\n\nThe basic building block of tmap is tm_shape(), followed by one or more layer elemments like tm_fill() and tm_polygons().\nIn the below code chunk, tm_shape() is used to define the input data (mpsz_pop2020) while tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\nA choropleth map showing the geographical distribution of a selected variable by planning subzone can be drawn using tm_polygons() as in below code, where the coloring is based on DEPENDENCY values.\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn:\n\nThe default interval binning used to draw a choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 5.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. We explore more color scheme in sub-section 5.4.\nMissing value is shaded in grey by default.\n\n\n\ntm_polygons() is a wrapper of tm_fill() and tm_border(). tm_fill() shades the polygons using the default colour scheme and tm_borders() adds the borders from the shapefile to the choropleth map.\nThe below code chunk draws a choropleth map by using tm_fill() only.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nWe can see that the planning subzones are shaded according to their DEPENDENCY values, but no border is plotted.\nTo add the boundary of planning subzones, tm_borders is added as shown in below code chunk.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nKey arguments in tm_borders():\n\nalpha: define transparency of the line. It takes in a number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\ncol: define border colour\nlwd: define border line width. The default value is 1.\nlty: define border line type. The default value is “solid”."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.3 Data classification methods of tmap",
    "text": "5.3 Data classification methods of tmap\nMost choropleth maps provide different data classification methods to organize a large number of observations into specific ranges or classes.\nThe tmap package offers ten data classification methods: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo select a data classification method, use the style argument in tm_fill() or tm_polygons().\n\n5.3.1 Built-in classification methods\nThe below tabs shows the choropleth maps drawn using different data classification methods with the same number of classes as 5 (n=5).\n\nquantileequalprettyjenkssdhclustfisherbclustkmeans\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIt is clear that different data classification methods result in significantly different coloring pattern. Certain methods like pretty, equal, sd are more sensitive to outliers. These methods are more likely to give result with only a few areas having different colors if the data contains large outliers. Whereas methods like quantile, jenks, kmeans give a more evenly distributed coloring in the choropleth map.\nHence it is important to select the appropriate classification method based on the values distribution of the given dataset to avoid having misleading representation of the data in choropleth map.\nThe below tabs show choropleth maps drawn using the same classification method (kmeans) but with different numbers of classes (2, 6, 10, 20)\n\nn=2n=6n=10n=20\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\nIt is obvious that using different number of classes of the same data classification method also impact the coloring of the output map. When n=2, the output map is impacted by outliers, as only 1 area has different color. For higher number of classes, the data is distributed more evenly.\n\n\n5.3.2 Custom break data classification\nFor all built-in methods, category breaks are calculated automatically. However, we can override these defaults by specifying custom breakpoints using the breaks argument in tm_fill(). In tmap, the breakpoints must include both the minimum and maximum values. This means if you want to create n categories, you need to provide n+1 breakpoints in increasing order.\nBefore setting custom breakpoints, it’s a good practice to examine descriptive statistics for the variable. The code snippet below calculates and displays the descriptive statistics for the DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nBased on the above results, we set breakpoints at 0.60, 0.70, 0.80, and 0.90. We include a minimum and maximum values, which is at 0 and 1.00 respectively. Hence our breaks is c(0, 0.60, 0.70, 0.80, 0.90, 1.00).\nNext, we plot the choropleth map using the code snippet below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#color-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#color-scheme",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.4 Color Scheme",
    "text": "5.4 Color Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\n\n5.4.1 ColourBrewer palette\nTo change the colour, we assign the preferred colour to palette argument of tm_fill() as shown in the below code chunk.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the colour shading, we add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe color scheme is reversed in above map, where the areas with lower DEPENDENCY values have darker colors."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#map-layouts",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.5 Map Layouts",
    "text": "5.5 Map Layouts\nMap layout is the arrangement of all map elements, such as the mapped objects, title, scale bar, compass, margins, and aspect ratios, to create a cohesive map. Color settings and data classification methods, like palettes and breakpoints, influence the map’s appearance.\n\nMap LegendMap StyleCartographic Furniture\n\n\nIn tmap, several legend options are provided to change the placement, format and appearance of the legend.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\ntmap allows a wide variety of layout settings to be changed using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\n\n\n\n\n\n\n\nIn addition to map styling, tmap also offers options to add other map elements, such as a compass, scale bar and grid lines.\nIn the code snippet below, tm_compass(), tm_scale_bar(), and tm_grid() are used to add a compass, scale bar, and grid lines to the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below reset the map to default style.\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#draw-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#draw-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.6 Draw Small Multiple Choropleth Maps",
    "text": "5.6 Draw Small Multiple Choropleth Maps\nSmall multiple maps, also known as facet maps, consist of several maps arranged side by side or stacked vertically. They are useful for visualizing how spatial relationships change in relation to another variable, such as time.\nIn tmap, there are three ways to create small multiple maps:\n\nAssign multiple values to at least one aesthetic argument.\nUse tm_facets() to define a group-by variable.\nUse tmap_arrange() to combine multiple stand-alone maps.\n\n\nAssign multiple values to at least one aesthetic argumentDefine a group-by variable in tm_facets()Create multiple stand-alone maps with tmap_arrange()\n\n\nThe below code snippet creates small multiple choropleth maps by defining ncols in tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example, small multiple choropleth maps are created by assigning multiple values to at least one of the aesthetic arguments (style, palette, legend position).\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\nMultiple small choropleth maps can be created using tm_facets(). The below code snipped creates multiple maps splitted by REGION_N field.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nIn this example, multiple small choropleth maps are created from multiple stand-alone maps on the same row using tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#map-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex012.html#map-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 1.2: Thematic Mapping and GeoVisualisation with R",
    "section": "5.7 Map Spatial Object Meeting a Selection Criterion",
    "text": "5.7 Map Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, we can use selection funtion to map spatial objects meeting the selection criterion. The below code chunk draws the map for REGION_N = CENTRAL REGION\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#setting-the-scene",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "According to the World Health Organization (WHO) report, road traffic accidents cause 1.19 million deaths annually, with most fatalities occurring in low- and middle-income countries. Vulnerable road users, including pedestrians and motorcyclists, account for over half of these deaths, and road injuries are the leading cause of death for ages 5–29. The economic impact is severe, costing countries 3% of their GDP.\nThailand’s roads are the deadliest in Southeast Asia, with about 20,000 deaths annually. Between 2014 and 2021, Thailand saw a notable rise in accident frequencies. 19% of all accidents occurs on national highways, with most accidents happening on straight roads and at intersections."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#objectives",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "Road traffic accidents are largely influenced by behavioral factors (driver behavior and performance) and environmental factors (weather and road conditions). While studies using Spatial Point Patterns Analysis (SPPA) have explored these factors, they often overlook temporal elements like season, day in the week, or time during the day.\nThis study will focus on discovering factors affecting road traffic accidents in the Bangkok Metropolitan Region (BMR) - one of the most populated metropolitan regions in Thailand, using different spatio-temporal point pattern analysis techniques:\n\nVisualize the spatio-temporal dynamics of traffic accidents in BMR using appropriate statistical graphics and geovisualization methods.\nPerform spatial analysis of traffic accidents using appropriate Network Spatial Point Patterns Analysis methods.\nConduct spatio-temporal analysis using appropriate Temporal Network Spatial Point Patterns Analysis methods."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "",
    "text": "For the purpose of this study, 3 data sets are used:\n\nThailand Road Accident [2019-2022] on Kaggle: provides statistics on recorded accidents in Thailand from 2019 to 2022. This dataset is in csv format.\nThailand Roads (OpenStreetMap Export) on HDX: road network in Thailand in ESRI shapefile format.\nThailand - Subnational Administrative Boundaries on HDX: boundaries at different administrative levels in Thailand in ESRI shapefile format.\n\nAll these dataset should be downloaded and store in data/rawdata folder under the same folder path with the Quarto document."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import-and-preparation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-import-and-preparation",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.1 Data Import and Preparation",
    "text": "3.1 Data Import and Preparation\n\nTraffic AccidentThailand Subnational Administrative BoundariesThailand Bangkok Metropolitan Region Road\n\n\nThe below code chunk carries out these transformation steps on thai_road_accident_2019_2022.csv:\n\nread_csv(): import csv file and assign data to a tibble data frame.\nselect(): select relevant columns from the tibble data frame\nfilter(): exclude records with invalid longitude or latitude value\nmutate(): create additional month/day/time columns from incident_datetime\nst_as_sf(): convert tible data frame into simple feature data frame\nst_transform(): reprojected the sf data frame to Thailand Projected coordinate system. EPSG is referred from epsg.io.\n\n\nrdacc_sf = read_csv(\"data/rawdata/thai_road_accident_2019_2022.csv\") %&gt;%\n  select(-c(\"province_th\", \"route\", \"report_datetime\",\"agency\")) %&gt;% # remove irrelevant columns\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  mutate(month_no = month(incident_datetime)) %&gt;%\n  mutate(month_fac = month(incident_datetime,\n                       label = TRUE, abbr = TRUE)) %&gt;%\n  mutate(dayofweek = wday(incident_datetime, week_start = 1)) %&gt;%\n  mutate(dayofyear = yday(incident_datetime)) %&gt;%\n  mutate(hourofday = hour(incident_datetime)) %&gt;%\n  mutate(year = year(incident_datetime)) %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"),\n           crs = 4326) %&gt;%\n  st_transform(crs = 32647)\n\nNext we write the result sf data frame to rds format to avoid repeating the initial transformations.\n\nwrite_rds(rdacc_sf, \"data/rds/acc.rds\")\n\nThe below code chunk uses read_rds() to read in the rds file and filter for accidents in Bangkok Metropolitan Region. The output is assigned to bmr_acc.\n\nbmr_acc = read_rds(\"data/rds/acc.rds\") %&gt;%\n  filter(province_en %in% c(\"Bangkok\",\"Nakhon Pathom\", \"Pathum Thani\",\"Nonthaburi\", \"Samut Prakan\", \"Samut Sakhon\"))\n\nNext we check the content and CRS of the simple features object and observe the following:\n\nThe event object bmr_acc is already in POINT geometry type with dimension XY, which satisfies the requirement for further Kernel Density Estimate (KDE) analysis.\nCRS is set to EPSG 32647 as expected.\n\n\nbmr_acc\n\nSimple feature collection with 12986 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 12,986 × 19\n   acc_code incident_datetime   province_en   vehicle_type        presumed_cause\n *    &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;         &lt;chr&gt;               &lt;chr&gt;         \n 1   571882 2019-01-01 02:25:00 Nakhon Pathom motorcycle          speeding      \n 2   600001 2019-01-01 03:00:00 Nonthaburi    private/passenger … speeding      \n 3   605043 2019-01-01 03:00:00 Samut Prakan  private/passenger … running red l…\n 4   629691 2019-01-01 03:05:00 Bangkok       other               other         \n 5   571887 2019-01-01 04:30:00 Nakhon Pathom motorcycle          speeding      \n 6   599234 2019-01-01 04:45:00 Samut Prakan  motorcycle          driving under…\n 7   599990 2019-01-01 05:30:00 Samut Sakhon  motorcycle          speeding      \n 8   612045 2019-01-01 05:30:00 Nonthaburi    private/passenger … cutting in cl…\n 9   629689 2019-01-01 05:42:00 Bangkok       other               other         \n10   607046 2019-01-01 06:30:00 Pathum Thani  private/passenger … speeding      \n# ℹ 12,976 more rows\n# ℹ 14 more variables: accident_type &lt;chr&gt;, number_of_vehicles_involved &lt;dbl&gt;,\n#   number_of_fatalities &lt;dbl&gt;, number_of_injuries &lt;dbl&gt;,\n#   weather_condition &lt;chr&gt;, road_description &lt;chr&gt;, slope_description &lt;chr&gt;,\n#   month_no &lt;dbl&gt;, month_fac &lt;ord&gt;, dayofweek &lt;dbl&gt;, dayofyear &lt;dbl&gt;,\n#   hourofday &lt;int&gt;, year &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\nst_crs(bmr_acc)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\nWe check if the data contains any duplicated accident records. The return index is 0 indicates there is no duplicated records.\n\nanyDuplicated(bmr_acc)\n\n[1] 0\n\n\nAs the Thailand Roads shapefile from OpenStreetMap contains various road types in Thailand, we visualize the frequency of accidents involving different vehicle types to decide which road types to be included for the scope of this analysis.\n\nggplot(data = bmr_acc, aes(x = fct_infreq(vehicle_type))) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +  # Bar plot with colored bars\n  labs(title = \"Frequency of Different Vehicle Types\", \n       x = \"Vehicle Type\", \n       y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) \n\n\n\n\n\n\n\n\nThe above chart shows that the majority of the accidents were caused by motor vehicles, only 0.39 % were caused by bicycle, pedestrian, motorized tricycle and agricultural vehicle as calculated below.\nFor the scope of this analysis, we will focus on motor vehicles related accident and road types that allow motor vehicles access only.\n\n# Filter the records where vehicle_type is either 'pedestrian' or 'bicycle'\nsubset_vehicle &lt;- bmr_acc[bmr_acc$vehicle_type %in% c(\"pedestrian\", \"bicycle\",\"motorized tricycle\",\"tractor/agricultural vehicle\"), ]\n\n# Calculate the percentage & print the result\npercentage &lt;- (nrow(subset_vehicle) / nrow(bmr_acc)) * 100\nprint(paste(\"Percentage of pedestrian and bicycle records:\", round(percentage, 2), \"%\"))\n\n[1] \"Percentage of pedestrian and bicycle records: 0.39 %\"\n\n\n\n\nThe below code chunk uses st_read() to imports the administrative boundaries at province level (level 1) and filter for provinces in Bangkok Metropolitan Region.\n\nbmr_prov = st_read(dsn = \"data/rawdata\",layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  filter(ADM1_EN %in% c(\"Bangkok\",\"Nakhon Pathom\", \"Pathum Thani\",\"Nonthaburi\", \"Samut Prakan\", \"Samut Sakhon\"))\n\nThe output is written to rds file to avoid repeating initial transformation steps.\n\nwrite_rds(bmr_prov, \"data/rds/bmr_prov.rds\")\n\nNext we read from rds file using read_rds().\n\nbmr_prov = read_rds(\"data/rds/bmr_prov.rds\")\n\nand reproject to Thailand projected coordinate system using st_transform(). The output is assigned to bmr_boundary.\n\nbmr_boundary = st_transform(bmr_prov, crs = 32647)\n\nChecking the content and CRS of this sf data frame yields the below:\n\nThe event object bmr_boundary is in POLYGON geometry type with dimension XY, which is as expected for boundary object.\nCRS is set to EPSG 32647 as expected.\n\n\nbmr_boundary\n\nSimple feature collection with 6 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 587893.5 ymin: 1484414 xmax: 712440.5 ymax: 1579076\nProjected CRS: WGS 84 / UTM zone 47N\n  Shape_Leng Shape_Area       ADM1_EN      ADM1_TH ADM1_PCODE ADM1_REF\n1   2.417227 0.13133873       Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n2   1.695100 0.07926199  Samut Prakan   สมุทรปราการ       TH11     &lt;NA&gt;\n3   1.251111 0.05323766    Nonthaburi        นนทบุรี       TH12     &lt;NA&gt;\n4   1.884945 0.12698345  Pathum Thani       ปทุมธานี       TH13     &lt;NA&gt;\n5   2.463030 0.17891420 Nakhon Pathom       นครปฐม       TH73     &lt;NA&gt;\n6   1.566369 0.07155983  Samut Sakhon     สมุทรสาคร       TH74     &lt;NA&gt;\n  ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH ADM0_PCODE\n1       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n2       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n3       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n4       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n5       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n6       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n        date    validOn    validTo                       geometry\n1 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((674339.8 15...\n2 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((687139.8 15...\n3 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((644817.9 15...\n4 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((704086 1575...\n5 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((631987.6 15...\n6 2019-02-18 2022-01-22 -001-11-30 MULTIPOLYGON (((641549.1 15...\n\nst_crs(bmr_boundary)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\nWe use tmap to plot the output and can see the 6 provinces of BMR has been plotted correctly.\n\ntm_shape(bmr_boundary) +\n  tm_polygons() +\n  tm_text(\"ADM1_EN\", size = 0.5)\n\n\n\n\n\n\n\n\n\n\nThe below code chunk carries out the following steps:\n\nst_read(): read in the shapefile exported from OpenStreetMap\nst_set_crs(): as the original datataset CRS is NA, we use st_set_crs() to assign to EPSG 4326 of WGS84 geodetic coordinate system\nst_intersection(): filter for roads inside BMR boundary only.\n\n\nbmr_road = st_read(dsn = \"data/rawdata\",layer = \"hotosm_tha_roads_lines_shp\") %&gt;%\n  st_set_crs(4326) %&gt;%\n  st_intersection(bmr_prov)\n\nWe write the output into rds file using below code chunk.\n\nwrite_rds(bmr_road, \"data/rds/bmr_road.rds\")\n\nAs the OSM data include exhaustive road types (under column highway), we will filter for road types that allow motor vehicles access only. According to WikiProject Thailand, we filter for the below highway classification where motorcycle and car can access.\nThe below code chunk uses:\n\nread_rds() to read from rds file\nfilter(): filter for relevant road types\nst_transform(): reproject to Thailand Projected CRS.\n\n\nbmr_road_ft = read_rds(\"data/rds/bmr_road.rds\") %&gt;%\n  filter(highway %in% c(\"motorway\", \"motorway_link\", \"trunk\",\"trunk_link\",\"primary\",\"primary_link\",\"secondary\",\"secondary_link\",\"tertiary\",\"tertiary_link\", \"unclassified\",\"living_street\", \"road\", \"residential\")) %&gt;%\n  st_transform(crs = 32647)\n\nWe rrite the transformed road data to rds file using write_rds().\n\nwrite_rds(bmr_road_ft, \"data/rds/network.rds\")\n\nNext we read from rds file using read_rds() and assigned the output to network object.\n\nnetwork = read_rds(\"data/rds/network.rds\")\n\nWe use tm_shape() and tm_lines() to plot the road network for a quick view.\n\ntm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\n\n\nThe network is still too dense to be observable. The frequency of different highway classification is plotted as below for further investigation.\n\nggplot(data = network, aes(x = fct_infreq(highway))) +\n  geom_bar(fill = \"skyblue\", color = \"black\") +  # Bar plot with colored bars\n  labs(title = \"Frequency of Different Highway Classes\", \n       x = \"Highway Class\", \n       y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) \n\n\n\n\n\n\n\n\nIt can be seen that residential class takes up the majority number of records. As defined in WikiProject Thailand, residential class includes roads “within a residential area that gives the public access to one or multiple residences. Also used for roads within a gated housing estate (add access=private). Residential roads are typically short in length and often named.” As these roads are inside residential area and usually short, we assume the number of traffic accidents happening on this type of road is small.\nWe exclude highway=residential from the network sf object using below code chunk.\n\nnetwork = filter(network, ! highway %in% c(\"residential\"))\n\nChecking the content and CRS of network sf data frame yields the below:\n\nThe object is in GEOMETRY geometry type with dimension XY, while NKDE analysis requires LINESTRING geometry type.\nCRS is set to EPSG 32647 as expected.\n\n\nnetwork\n\nSimple feature collection with 33100 features and 30 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 590124.8 ymin: 1484506 xmax: 712235 ymax: 1579041\nProjected CRS: WGS 84 / UTM zone 47N\nFirst 10 features:\n                 name                name_en        highway  surface smoothness\n1          ถนนฉลองกรุง     Chalong Krung Road      secondary    paved       &lt;NA&gt;\n3                &lt;NA&gt;                   &lt;NA&gt; secondary_link     &lt;NA&gt;       &lt;NA&gt;\n5          ถนนฉลองกรุง     Chalong Krung Road      secondary concrete       &lt;NA&gt;\n869  ถนนประชาสงเคราะห์   Pracha Songkhro Road       tertiary  asphalt       &lt;NA&gt;\n1030             &lt;NA&gt;                   &lt;NA&gt; secondary_link     &lt;NA&gt;       &lt;NA&gt;\n1099     ถนนวิภาวดีรังสิต Vibhavadi Rangsit Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n1101         ถนนดินแดง         Din Daeng Road        primary     &lt;NA&gt;       &lt;NA&gt;\n1104     ถนนวิภาวดีรังสิต Vibhavadi Rangsit Road      secondary     &lt;NA&gt;       &lt;NA&gt;\n1106         ถนนดินแดง         Din Daeng Road        primary     &lt;NA&gt;       &lt;NA&gt;\n1108             &lt;NA&gt;                   &lt;NA&gt;   primary_link     &lt;NA&gt;       &lt;NA&gt;\n     width lanes oneway bridge layer source          name_th     osm_id\n1     &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;       ถนนฉลองกรุง 1125681229\n3     &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;             &lt;NA&gt;  472283206\n5     &lt;NA&gt;     2    yes    yes     1   Bing       ถนนฉลองกรุง  116847248\n869   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt; ถนนประชาสงเคราะห์   25933535\n1030  &lt;NA&gt;  &lt;NA&gt;    yes    yes     1   Bing             &lt;NA&gt;   97092142\n1099  &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;     ถนนวิภาวดีรังสิต  835519345\n1101  &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         ถนนดินแดง 1055365750\n1104  &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;     ถนนวิภาวดีรังสิต 1306889182\n1106  &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;         ถนนดินแดง 1306889184\n1108  &lt;NA&gt;  &lt;NA&gt;    yes   &lt;NA&gt;  &lt;NA&gt;   &lt;NA&gt;             &lt;NA&gt; 1306889186\n      osm_type Shape_Leng Shape_Area ADM1_EN      ADM1_TH ADM1_PCODE ADM1_REF\n1    ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n3    ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n5    ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n869  ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1030 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1099 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1101 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1104 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1106 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n1108 ways_line   2.417227  0.1313387 Bangkok กรุงเทพมหานคร       TH10     &lt;NA&gt;\n     ADM1ALT1EN ADM1ALT2EN ADM1ALT1TH ADM1ALT2TH  ADM0_EN   ADM0_TH ADM0_PCODE\n1          &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n3          &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n5          &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n869        &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1030       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1099       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1101       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1104       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1106       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n1108       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt;       &lt;NA&gt; Thailand ประเทศไทย         TH\n           date    validOn    validTo                       geometry\n1    2019-02-18 2022-01-22 -001-11-30 LINESTRING (693686.1 151979...\n3    2019-02-18 2022-01-22 -001-11-30 LINESTRING (692949.1 151886...\n5    2019-02-18 2022-01-22 -001-11-30 LINESTRING (692810.8 151863...\n869  2019-02-18 2022-01-22 -001-11-30 LINESTRING (668360.2 152245...\n1030 2019-02-18 2022-01-22 -001-11-30 LINESTRING (652536.6 152423...\n1099 2019-02-18 2022-01-22 -001-11-30 LINESTRING (667716.6 152278...\n1101 2019-02-18 2022-01-22 -001-11-30 LINESTRING (667485.1 152210...\n1104 2019-02-18 2022-01-22 -001-11-30 LINESTRING (667822.4 152298...\n1106 2019-02-18 2022-01-22 -001-11-30 LINESTRING (667418.7 152214...\n1108 2019-02-18 2022-01-22 -001-11-30 LINESTRING (667434.6 152210...\n\nst_crs(network)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\nThe below code chunk converts the the geometry type to LINESTRING using st_cast().\n\nnetwork = st_cast(network, \"LINESTRING\")\n\nWe check if data contains any duplicated record using anyDuplicated() . The return index is 0 indicating there is no duplicated records in network sf data frame.\n\nanyDuplicated(network)\n\n[1] 0"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "3.2 Data Wrangling",
    "text": "3.2 Data Wrangling\nAs stated in the Objective section, road traffic accidents are generally caused by two main factors: behavioral and environmental. Behavioral factors, which are often the primary cause, can be divided into driver behavior (driving style) and driver performance (driving skills) (Elander, West, & French, 1993). Environmental factors include conditions like poor visibility due to weather (e.g., heavy rain or fog) and hazardous road features such as sharp bends, slippery slopes, or blind spots.\nIn this section, we perform additional mapping on the columns relevant to these factors in bmr_acc sf data frame.\n\nAccident Presumed CauseAccident Weather ConditionRoad and Slope Condition of Accident\n\n\nFirst we check the frequency of different accident presume causes using below code chunk:\n\ngroup_by(): group the records by presumed_cause column\nsummarise(): returns 1 row representing the count of records under each presumed cause.\n\n\ncause_counts &lt;- bmr_acc %&gt;%\n  group_by(presumed_cause) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup()\ncause_counts\n\nSimple feature collection with 40 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 40 × 3\n   presumed_cause                                count                  geometry\n   &lt;chr&gt;                                         &lt;int&gt;            &lt;GEOMETRY [m]&gt;\n 1 abrupt lane change                               59 MULTIPOINT ((603057.8 15…\n 2 brake/anti-lock brake system failure              7 MULTIPOINT ((665762 1511…\n 3 cutting in closely by people/vehicles/animals   621 MULTIPOINT ((595540.6 15…\n 4 dangerous curve                                  14 MULTIPOINT ((640057.9 15…\n 5 debris/obstruction on the road                   29 MULTIPOINT ((640235.4 15…\n 6 disabled vehicle without proper signals           1  POINT (639212.7 1509212)\n 7 disabled vehicle without proper signals/signs     3 MULTIPOINT ((654036.8 15…\n 8 driving in the wrong lane                         6 MULTIPOINT ((623601.1 14…\n 9 driving under the influence of alcohol          118 MULTIPOINT ((607471.8 15…\n10 failure to signal enter/exit parking              5 MULTIPOINT ((622165.9 15…\n# ℹ 30 more rows\n\n\nAs there are many causes with a small counts, the below code chunk is used to map all causes with records count smaller than or equal to 50 to other cause to avoid crowding the visualization with too many insignificant variables later. The modified mapping is save in presumed_cause_rd column.\n\n# Identify causes with less than 50 records\nrare_causes &lt;- cause_counts %&gt;%\n  filter(count &lt;= 50) %&gt;%\n  pull(presumed_cause)\n\n# Map those rare causes to \"other cause\"\nbmr_acc &lt;- bmr_acc %&gt;%\n  mutate(presumed_cause_rd = ifelse(presumed_cause %in% rare_causes, \"other cause\", presumed_cause))\n\nWe check the cause count again.\n\ncause_counts_rd &lt;- bmr_acc %&gt;%\n  group_by(presumed_cause_rd) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup()\ncause_counts_rd\n\nSimple feature collection with 11 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 11 × 3\n   presumed_cause_rd                             count                  geometry\n   &lt;chr&gt;                                         &lt;int&gt;          &lt;MULTIPOINT [m]&gt;\n 1 abrupt lane change                               59 ((603057.8 1533623), (63…\n 2 cutting in closely by people/vehicles/animals   621 ((595540.6 1542724), (59…\n 3 driving under the influence of alcohol          118 ((607471.8 1545956), (61…\n 4 falling asleep                                  221 ((597876.3 1547500), (60…\n 5 other                                           957 ((624456.5 1494214), (63…\n 6 other cause                                     270 ((599469.8 1542071), (60…\n 7 running red lights/traffic signals               96 ((610783.1 1530716), (61…\n 8 speeding                                      10143 ((593843.8 1550868), (59…\n 9 tailgating                                       83 ((622420.1 1491733), (64…\n10 unfamiliarity with the route/unskilled drivi…    53 ((591277.5 1545514), (62…\n11 vehicle equipment failure                       365 ((606366 1562577), (6066…\n\n\nWe can see the individual rare causes are mapped to other cause already.\n\n\nFirst we check the frequency of different weather conditions using below code chunk:\n\ngroup_by(): group the records by weather_condition column\nsummarise(): returns 1 row representing the count of records under each weather condition.\n\n\nweather_counts &lt;- bmr_acc %&gt;%\n  group_by(weather_condition) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup()\nweather_counts\n\nSimple feature collection with 7 features and 2 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 7 × 3\n  weather_condition count                                               geometry\n  &lt;chr&gt;             &lt;int&gt;                                         &lt;GEOMETRY [m]&gt;\n1 clear             11711 MULTIPOINT ((591277.5 1545514), (593843.8 1550868), (…\n2 dark                 81 MULTIPOINT ((629588.3 1507077), (644784.6 1533981), (…\n3 foggy                 4 MULTIPOINT ((655920.3 1511008), (666583.8 1509141), (…\n4 land slide            1                               POINT (666736.7 1509549)\n5 natural disaster      1                               POINT (650910.3 1540963)\n6 other                22 MULTIPOINT ((639624 1552092), (649315 1550117), (6494…\n7 rainy              1166 MULTIPOINT ((604435.1 1525464), (604930.8 1525557), (…\n\n\nWe can see that 90% of accidents (over total 12,986 records) happened under clear weather and 7.7% happened under rainy weather. This signifies majority of road accidents in BMR may not be due to weather.\nAs other weather condition has relative small counts, we map all these conditions to other condition using below code chunk. The modified mapping is saved in weather_rd column.\n\nweather_other &lt;- c(\"dark\", \"foggy\", \"land slide\", \"natural disaster\", \"other\")\n\n# Map those rare condition to \"other condition\"\nbmr_acc &lt;- bmr_acc %&gt;%\n  mutate(weather_rd = ifelse(weather_condition %in% weather_other, \"other condition\", weather_condition))\n\n# Check the count again\nweather_counts_rd &lt;- bmr_acc %&gt;%\n  group_by(weather_rd) %&gt;%\n  summarise(count = n())\nweather_counts_rd\n\nSimple feature collection with 3 features and 2 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 3 × 3\n  weather_rd      count                                                 geometry\n  &lt;chr&gt;           &lt;int&gt;                                         &lt;MULTIPOINT [m]&gt;\n1 clear           11711 ((591277.5 1545514), (593843.8 1550868), (595042.2 1550…\n2 other condition   109 ((629588.3 1507077), (639624 1552092), (644784.6 153398…\n3 rainy            1166 ((604435.1 1525464), (604930.8 1525557), (604978 152556…\n\n\nWe can see the remaining conditions are mapped to other condition already.\n\n\nFirst we check the frequency of different road and slope description combination using below code chunk:\n\ngroup_by(): group the records by road_descroption and slope_description columns\nsummarise(): returns 1 row representing the count of records under each combination.\n\n\n# Count the occurrences of each road and slope description combination\nroad_counts &lt;- bmr_acc %&gt;%\n  group_by(road_description, slope_description) %&gt;%\n  summarise(count = n()) %&gt;%\n  ungroup()\n\n`summarise()` has grouped output by 'road_description'. You can override using\nthe `.groups` argument.\n\n# Calculate the percentage of occurrences\ntotal_count &lt;- sum(road_counts$count)\nroad_counts &lt;- road_counts %&gt;%\n  mutate(percentage = round((count / total_count) * 100,2))\n\n# View the result\nroad_counts\n\nSimple feature collection with 19 features and 4 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 19 × 5\n   road_description slope_description count                  geometry percentage\n * &lt;chr&gt;            &lt;chr&gt;             &lt;int&gt;          &lt;MULTIPOINT [m]&gt;      &lt;dbl&gt;\n 1 connecting to p… other                 8 ((595545.3 1542719), (61…       0.06\n 2 connecting to p… other                43 ((606712.6 1557002), (60…       0.33\n 3 connecting to s… other                 4 ((646878.1 1550240), (66…       0.03\n 4 four-way inters… other                 6 ((616900.4 1556213), (62…       0.05\n 5 grade-separated… other               150 ((654173 1525967), (6560…       1.16\n 6 merge lane       other                11 ((665780.8 1524036), (66…       0.08\n 7 other            other              1004 ((604914.7 1548870), (60…       7.73\n 8 roundabout       other                 3 ((614608.3 1523654), (65…       0.02\n 9 sharp curve      no slope              9 ((627908.6 1522233), (63…       0.07\n10 sharp curve      slope area           32 ((621201.3 1498072), (62…       0.25\n11 straight road    no slope          10221 ((591277.5 1545514), (59…      78.7 \n12 straight road    other               712 ((603057.8 1533623), (61…       5.48\n13 straight road    slope area          151 ((642026.9 1499283), (65…       1.16\n14 t-intersection   other                66 ((599469.8 1542071), (61…       0.51\n15 u-turn area      other                 5 ((641181.3 1509733), (66…       0.04\n16 wide curve       no slope            347 ((605960.9 1537813), (60…       2.67\n17 wide curve       other                90 ((655680.3 1506877), (65…       0.69\n18 wide curve       slope area           51 ((652382.4 1524279), (65…       0.39\n19 y-intersection   other                73 ((629514.6 1526365), (62…       0.56\n\n\nAs there are many road and slope condition combination with small counts, we map all these combinations with records count percentage over total number of cases smaller than 1% to other condition keep the focus on the conditions that presented in the majority of the accidents only.\nThe below code chunk use mutate() to create road_rd column , which has value = other conditions for accidents under conditions with small counts and value = road_description-slope_description otherwise.\n\n# Identify conditions with records percentage less than 1%\nrare_conditions &lt;- road_counts %&gt;%\n  filter(percentage &lt; 1) %&gt;%\n  mutate(road_condition = paste(road_description, slope_description, sep = \"-\")) %&gt;%\n  pull(road_condition)\n\n# Map those rare causes to \"other cause\"\nbmr_acc &lt;- bmr_acc %&gt;%\n  mutate(road_condition = paste(road_description, slope_description, sep = \"-\")) %&gt;%\n  mutate(road_rd = ifelse(road_condition %in% rare_conditions, \"other conditions\", road_condition))\n\nWe check the count and percentage in road_rd column using below code chunk.\n\n# Count the occurrences of each road and slop description combination\nroad_counts_rd &lt;- bmr_acc %&gt;%\n  group_by(road_rd) %&gt;%\n  summarise(count = n())\n\n# Calculate the percentage of occurrences\ntotal_count &lt;- sum(road_counts_rd$count)\nroad_counts_rd &lt;- road_counts_rd %&gt;%\n  mutate(percentage = round((count / total_count) * 100,2))\n\n# View the result\nroad_counts_rd\n\nSimple feature collection with 7 features and 3 fields\nGeometry type: MULTIPOINT\nDimension:     XY\nBounding box:  xmin: 591277.5 ymin: 1486846 xmax: 710166.1 ymax: 1576520\nProjected CRS: WGS 84 / UTM zone 47N\n# A tibble: 7 × 4\n  road_rd                             count                  geometry percentage\n* &lt;chr&gt;                               &lt;int&gt;          &lt;MULTIPOINT [m]&gt;      &lt;dbl&gt;\n1 grade-separated intersection/ramps…   150 ((654173 1525967), (6560…       1.16\n2 other conditions                      401 ((595545.3 1542719), (59…       3.09\n3 other-other                          1004 ((604914.7 1548870), (60…       7.73\n4 straight road-no slope              10221 ((591277.5 1545514), (59…      78.7 \n5 straight road-other                   712 ((603057.8 1533623), (61…       5.48\n6 straight road-slope area              151 ((642026.9 1499283), (65…       1.16\n7 wide curve-no slope                   347 ((605960.9 1537813), (60…       2.67\n\n\nWe can see all the rare combinations have been mapped to other-conditions already."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-the-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-the-geospatial-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.1 Visualize the Geospatial Data",
    "text": "4.1 Visualize the Geospatial Data\nFirst we plot the map of traffic accidents in BMR with overlaying road network using different function of tmap package:\n\ntm_polygons(): plot the area boundaries\ntm_dots(): plot each accident as a red dot (col = ‘red’) on the map\ntm_lines(): plot the lines to represent the road network in BMR\n\n\ntm_shape(bmr_boundary) + \n  tm_polygons() +\n  tm_shape(bmr_acc) +\n  tm_dots(col = \"red\") +\n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\n\n\nThe above map shows most of the accidents points already lie on the network. Although there are a few points still lying off the network, this number is trivial. We can confirm the network sf data frame cover majority of the accident points and can be used for the remaining analysis."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-traffic-accidents-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-traffic-accidents-data",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "4.2 Visualize Traffic Accidents Data",
    "text": "4.2 Visualize Traffic Accidents Data\nIn this section, we deep dive into traffic accidents data to understand the trend, severity and related cause of traffic accidents in Bangkok Metropolitan Region from 2019 to 2022.\n\nTraffic Accident TrendTraffic Accident by ProvinceDistance to Nearest Neighbor\n\n\nTo understand if there is any seasonal factor impacting occurence of traffic accidents in BMR, the below code chunk is uses ggplot() to plot the monthly traffic accidents trend by month by year.\n\n# Group data by year and month, and count the number of accidents\naccidents_by_month &lt;- bmr_acc %&gt;%\n  group_by(year, month_no) %&gt;%\n  summarise(num_accidents = n())\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n# Plot the data\nggplot(accidents_by_month, aes(x = month_no, y = num_accidents, color = factor(year), group = year)) +\n  geom_line() +\n  labs(title = \"Number of Accidents by Month for Each Year\",\n       x = \"Month No\",\n       y = \"Number of Accidents\",\n       color = \"Year\") +\n  scale_x_continuous(breaks = 1:12, labels = month.abb) + # Label months as Jan, Feb, etc.\n  theme_minimal()\n\n\n\n\n\n\n\n\nWe can observe some similarities in the trend across the 4 years:\n\nApril was the month with the highest number of accident in year 2019 and 2021, and second highest in 2022. This may be due to the Songkran festival in April, which is the largest festival in Thailand. The dip in 2020 can be attributed towards travel restriction during Covid.\nFebruary-March and May-June were the months with lower number of accidents throughout the year.\nThe number of accidents had an increasing trend from June to December.\n\nAs 2022 is the most recent year with available data and the number of accidents shows a concerning increase towards the end of the year, for the scope of this study we will focus on accidents happening in 2022 only.\nThe below code chunk uses filter() to filter for accidents recorded in 2022.\n\nbmr_acc = bmr_acc |&gt;\n  filter(year == 2022)\n\n\n\nTo understand the geopraphic distribution of traffic accidents in BMR, we use ggplot() to plot the number of accidents by province as in below code chunk.\n\n# Group by province and count the number of accidents\naccidents_by_province &lt;- bmr_acc %&gt;%\n  group_by(province_en) %&gt;%\n  summarise(accident_count = n()) %&gt;%\n  ungroup()\n\n# Create a column chart\nggplot(accidents_by_province, aes(x = reorder(province_en, -accident_count), y = accident_count)) +\n  geom_col(fill = \"skyblue\") +\n  geom_text(aes(label = accident_count), vjust = -0.5, color = \"black\", size = 3.5) +  # Add data labels\n  labs(title = \"Number of Accidents by Province\", \n       x = \"Province\", \n       y = \"Number of Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))  # Rotate x-axis labels for readability\n\n\n\n\n\n\n\n\nThe column chart shows the first 4 provinces already account for 91% of the total number of accidents in 2022. For the remaining analysis we will focus on these 4 provinces only.\nThe below code chunk filter for these 4 provinces and select the relevant columns using select().\n\nnetwork = network |&gt;\n  filter(ADM1_EN %in% c(\"Bangkok\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\")) |&gt;\n  select(c(\"name_en\",\"highway\",\"osm_id\",\"ADM1_EN\"))\n\nThe same filter is applied for the bmr_acc and bmr_boundary sf dataframe as below.\n\n# Traffic accident data frame\nbmr_acc = bmr_acc |&gt;\n  filter(province_en %in% c(\"Bangkok\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\n\n# Region boundaries data frame\nbmr_boundary = bmr_boundary |&gt;\n  filter(ADM1_EN %in% c(\"Bangkok\", \"Pathum Thani\", \"Samut Prakan\", \"Samut Sakhon\"))\n\nWe plot the map again using functions of tmap and can see the 2 provinces Nontha Buri and Nakhon Pathom are properly excluded.\n\ntm_shape(bmr_boundary) +\n  tm_polygons() +\ntm_shape(bmr_acc) +\n  tm_dots(col = 'red') +\ntm_shape(network) +\n  tm_lines()\n\n\n\n\n\n\n\n\n\n\nNow we want to understand the spread of accident points along the network. We snap the points to the network and calculate the distance of each point to its nearest neighbor on the network.\nFirst we aggregate the events that are within 30 meters to each other using aggregate_points().\nNote: for the distance calculation to work, we need to ensure no point shares the exact same location on the network. Hence the points close to each other needs to be aggregated before proceeding further.\n\nbmr_acc$weight &lt;- 1\nbmr_acc_agg &lt;- bmr_acc |&gt;\n  aggregate_points(30 ,weight = \"weight\")\n\nNext the distance of each even to its nearest neighbor on the network is calculated using network_knn().\n\nknn_dists &lt;- network_knn(origins = bmr_acc_agg, \n                         lines = network, \n                         k = 1,\n                         maxdistance = 2000,\n                         line_weight = \"length\",\n                         digits = 2, tol = 0.1, verbose = FALSE)\n\nWe plotting the result using ggplot().\n\nggplot() + \n  geom_histogram(aes(x = knn_dists$distances), fill = \"skyblue\", color = \"black\", bins = 50) + \n  labs(x = \"distance to nearest neighbour (in meters)\")\n\nWarning: Removed 57 rows containing non-finite outside the scale range\n(`stat_bin()`).\n\n\n\n\n\n\n\n\n\nThe above histogram shows that there are a few points that are very far from its nearest neighbor. We remove the records with distance larger than 5000 meters and plot the result again using below code chunk.\n\ndistances = knn_dists$distances\ndistance_ft = distances[distances &lt; 5000]\n# Plot the histogram\nggplot() + \n  geom_histogram(aes(x = distance_ft), fill = \"skyblue\", color = \"black\", bins = 50) + \n  labs(x = \"Distance to nearest neighbour (in meters)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe histogram is right skewed with 85.3% of events (after aggregating events within 30 meters) falls within 1 kilometers from its nearest neighbors. This indicates there are certain hot spots on BMR road network where traffic accidents occur frequently. We will examine these hot spots in the following TNKDE and NKDE analysis.\n\n# Calculate percentage of accidents with nearest neighbor distance lower than 1 kilometer over all accidents in 2022\nlength(distances[distances &lt; 1000])/length(distances)\n\n[1] 0.8528873"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-geographic-distribution-of-traffic-accident-by-month",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#visualize-geographic-distribution-of-traffic-accident-by-month",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.1 Visualize geographic distribution of traffic accident by month",
    "text": "5.1 Visualize geographic distribution of traffic accident by month\nAs we observe some seasonality in the number of traffic accidents by month in the previous section, we further investigate if there is any difference in the location of those accidents by month.\nThe below code chunk uses multiple functions of tmap to plot the accidents by month. Each accident is represented by a red dot and each province boundary is filled by a different color.\n\ntm_shape(bmr_boundary)+\n  tm_fill(col = \"ADM1_EN\", palette = 'Pastel2') +\n  tm_legend(width = 0.5, height = 0.5) +\ntm_shape(network) +\n  tm_lines(alpha = 0.5) +\ntm_shape(bmr_acc) +\n  tm_dots(size = 0.1, col = 'red') +\ntm_facets(by=\"month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\nThe above maps show that the locations of accidents resembles almost the same pattern across all the months, with many points clustered in these 3 parts of the road network:\n\nCenter of Bangkok\nAlong the vertical road connecting Pathum Thani, Bangkok and Samut Prakan province\nAlong the horizontal road connecting Samut Sakhon and Bangkok"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#compute-stkde-for-different-time-dimensions",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#compute-stkde-for-different-time-dimensions",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "5.2 Compute STKDE for different time dimensions",
    "text": "5.2 Compute STKDE for different time dimensions\nIn this section, we explore how to compute STKDE using spattemp.density()of sparr package.\nAs spattemp.density() requires the object in ppp class, first we create an owin object from bmr_boundary to define the observation window for the ppp object using below code chunk.\n\nacc_owin &lt;- as.owin(bmr_boundary)\nacc_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [611104.4, 712440.5] x [1484413.7, 1579076.3] units\n\n\nNext, class() of base R is used to confirm if the output is indeed an owin object.\n\nclass(acc_owin)\n\n[1] \"owin\"\n\n\n\nCompute STKDE by monthCompute STKDE by day of weekCompute STKDE by hour of day\n\n\n\n5.2.0.1 Create ppp object\nThe code chunk below select only the necessary fields (month_no) from the bmr_acc sf data frame and conver to ppp object using as.ppp(). This is because as.ppp() function only requires the mark field and geometry field from sf data frame.\n\nacc_month_ppp = bmr_acc |&gt;\n  select(month_no) |&gt;\n  as.ppp()\n\nNext we include owin object and check if the output acc_month_owin is in the correct object class. We can see the object is already in ppp class.\n\nacc_month_owin &lt;- acc_month_ppp[acc_owin]\nsummary(acc_month_owin)\n\nMarked planar point pattern:  3283 points\nAverage intensity 6.70773e-07 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    4.00    7.00    7.05   10.00   12.00 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 15150 vertices\nenclosing rectangle: [611104.4, 712440.5] x [1484413.7, 1579076.3] units\n                     (101300 x 94660 units)\nWindow area = 4894350000 square units\nFraction of frame area: 0.51\n\n\nplot() of base R is used to plot the owin object. The output map shows proper province boundaries and marked points of 12 months.\n\nplot(acc_month_owin)\n\n\n\n\n\n\n\n\n\n\n5.2.0.2 Compute Spatio-temporal KDE\nNext, spattemp.density() of sparr package is used to compute the STKDE.\n\nacc_month_stkde &lt;- spattemp.density(acc_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(acc_month_stkde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 3953.323 (spatial)\n  lambda = 0.0301 (temporal)\n\nNo. of observations\n  3283 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [611104.4, 712440.5] x [1484414, 1579076]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [3.272962e-25, 3.865178e-09]\n\n\nplot() of base R is used to plot the spatio-temporal KDE between January 2022 - December 2022 using below code chunk.\n\ntims &lt;- c(1,2,3,4,5,6,7,8,9,10,11,12)\npar(mfcol=c(4,3), mar = c(2, 2, 2, 2))\nfor(i in tims){ \n  plot(acc_month_stkde, i,\n       override.par=FALSE,\n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}\n\n\n\n\n\n\n\n\nWe can observe the highest density in December in Bangkok and Samut Sakhon area, followed by January. From August to November, the density spread more equally across the 4 provinces.\nThailand experiences 3 main seasons:\n\nThe wet season from May to October\nThe cool season from November to February\nThe hot season from March to May\n\nWe can observe that the hot and wet season have lower STKDE compared versus cool season (especially in January and December). This can be partly contributed to cool season being high season for travelling in those areas with high density.\n\n\n\n\n5.2.0.3 Create ppp object\nThe code chunk below select only the necessary fields (dayofweek) from the bmr_acc sf data frame and conver to ppp object using as.ppp(). This is because as.ppp() function only requires the mark field and geometry field from sf data frame.\n\nacc_day_ppp &lt;- bmr_acc |&gt; \n  select(dayofweek) |&gt;\n  as.ppp()\n\nNext we include owin object and check if the output acc_day_owin is in the correct object class. We can see the object is already in ppp class.\n\nacc_day_owin &lt;- acc_day_ppp[acc_owin]\nsummary(acc_day_owin)\n\nMarked planar point pattern:  3283 points\nAverage intensity 6.70773e-07 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   2.000   4.000   4.077   6.000   7.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 15150 vertices\nenclosing rectangle: [611104.4, 712440.5] x [1484413.7, 1579076.3] units\n                     (101300 x 94660 units)\nWindow area = 4894350000 square units\nFraction of frame area: 0.51\n\n\nplot() of base R is used to plot the owin object. The output map shows proper province boundaries and marked points of 7 days in a week.\n\nplot(acc_day_owin)\n\n\n\n\n\n\n\n\n\n\n5.2.0.4 Compute Spatio-temporal KDE\nNext, spattemp.density() of sparr package is used to compute the STKDE.\n\nacc_day_stkde &lt;- spattemp.density(acc_day_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(acc_day_stkde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 3953.323 (spatial)\n  lambda = 0.013 (temporal)\n\nNo. of observations\n  3283 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [611104.4, 712440.5] x [1484414, 1579076]\n\nTemporal bound\n  [1, 7]\n\nEvaluation\n  128 x 128 x 7 trivariate lattice\n  Density range: [1.848561e-24, 1.301055e-08]\n\n\nplot() of base R is used to plot the spatio-temporal KDE for each day in a week.\n\ntims &lt;- c(1,2,3,4,5,6,7)\nwdays &lt;- c(\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\")\npar(mfcol=c(3,3), mar = c(2, 2, 2, 2))\nfor(i in tims){ \n  plot(acc_day_stkde, i,\n       override.par=FALSE,\n       fix.range=TRUE, \n       main=paste(\"KDE on\",wdays[i]))\n}\n\n\n\n\n\n\n\n\nThe above maps show that all 4 provinces have areas with high density on Monday (highest in Bangkok), follow by Sunday where high density areas are more spread out. The density is lower during middle of the week (Tuesday to Thursday) and starts to pick up towards the weekend (Friday to Sunday).\n\n\n\n\n5.2.0.5 Create ppp object\nThe code chunk below select only the necessary fields (hourofday) from the bmr_acc sf data frame and conver to ppp object using as.ppp(). This is because as.ppp() function only requires the mark field and geometry field from sf data frame.\n\nacc_hr_ppp &lt;- bmr_acc |&gt; \n  select(hourofday) |&gt;\n  as.ppp()\n\nNext we include owin object and check if the output acc_hr_owin is in the correct object class. We can see the object is already in ppp class.\n\nacc_hr_owin &lt;- acc_hr_ppp[acc_owin]\nsummary(acc_hr_owin)\n\nMarked planar point pattern:  3283 points\nAverage intensity 6.70773e-07 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'integer'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    0.0     8.0    13.0    12.5    18.0    23.0 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 15150 vertices\nenclosing rectangle: [611104.4, 712440.5] x [1484413.7, 1579076.3] units\n                     (101300 x 94660 units)\nWindow area = 4894350000 square units\nFraction of frame area: 0.51\n\n\nplot() is used to plot the owin object to examine the correctness of the output object.The output map shows proper province boundaries and marked points of 24 hours in a day.\n\nplot(acc_hr_owin)\n\n\n\n\n\n\n\n\n\n\n5.2.0.6 Compute Spatio-temporal KDE\nNext, spattemp.density() of sparr package is used to compute the STKDE.\n\nacc_hr_stkde &lt;- spattemp.density(acc_hr_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(acc_hr_stkde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 3953.323 (spatial)\n  lambda = 0.0806 (temporal)\n\nNo. of observations\n  3283 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [611104.4, 712440.5] x [1484414, 1579076]\n\nTemporal bound\n  [0, 23]\n\nEvaluation\n  128 x 128 x 24 trivariate lattice\n  Density range: [1.091345e-26, 4.371593e-10]\n\n\nplot() of base R is used to plot the spatio-temporal KDE of the first half of the day (from 0 AM to 12 PM).\n\ntims &lt;- c(0,1,2,3,4,5,6,7,8,9,10,11)\npar(mfcol=c(4,3), mar = c(2, 2, 2, 2))\nfor(i in tims){ \n  plot(acc_hr_stkde, i,\n       override.par=FALSE,\n       fix.range=TRUE, \n       main=paste(\"KDE at hour\",i))\n}\n\n\n\n\n\n\n\n\nThe highest density can be observed at midnight ( around 0 AM) and from 8AM to 11:59AM.\nWe continue to use plot() of base R to plot the STKDE of the second half of the day.\n\ntims &lt;- c(12,13,14,15,16,17,18,19,20,21,22,23)\npar(mfcol=c(4,3), mar = c(2, 2, 2, 2))\nfor(i in tims){ \n  plot(acc_hr_stkde, i,\n       override.par=FALSE,\n       fix.range=TRUE, \n       main=paste(\"KDE at hour\",i))\n}\n\n\n\n\n\n\n\n\nFor the remainder of the day, high density can be observed during lunch time (12PM - 13PM), in the evening (16PM - 19PM) and late night (22PM -23PM)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#prepare-the-lixels-objects-and-generate-line-centre-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#prepare-the-lixels-objects-and-generate-line-centre-points",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "6.1 Prepare the lixels objects and generate line centre points",
    "text": "6.1 Prepare the lixels objects and generate line centre points\nBefore computing NKDE, the SpatialLines object needs to be divided into lixels (line pixels) with a specified minimum distance. This can be done using the lixelize_lines() function from the spNetwork package, as shown in the code chunk below.\nAccording to the nearest neighbor distance plotted above, the smallest network distance between 2 accident points is under 100 meters. The lixel length and mindist should be larger than 100 meters to ensure these cases can be captured.\n\nlixels &lt;- lixelize_lines(network, \n                         800, \n                         mindist = 400)\n\nThe followings are observed from the above code chunk.\n\nThe length of each lixel (lx_length) is set to 800 meters.\nThe minimum length of a lixel (mindist) is set to 400 meters.\n\nAfter cutting, if the length of the final lixel is shorter than the minimum distance, it is merged with the previous lixel. If mindist = NULL, then it defaults to maxdist/10. Segments that are already shorter than the minimum distance are left unmodified.\nNote: The lixelize_lines.mc() function offers multicore support for this process.\nNext, lines_center() of spNetwork is used to generate a SpatialPointsDataFrame (i.e. samples) with line centre points as shown in the code chunk below.\n\nsamples &lt;- lines_center(lixels)\n\nThese points are located at center of the lixel based on the length of the lixel."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#perform-nkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#perform-nkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "6.2 Perform NKDE",
    "text": "6.2 Perform NKDE\nNKDE is computed using below code chunk, using the following key arguments:\n\nkernel_name = “quartic”: ensure no negative value returned.\nmethod = “simple”: for faster calculation given the data size. Since the network contains many intersections, we acknowledge this simple method may overestimate the density at road intersections.\nadaptive = FALSE and bw = 500: use fixed bandwidth of 500 meters\nagg = 30: aggregate accident points within 30 meters of each other\n\n\n# Calculate NKDE\ndensities &lt;- nkde(network, \n                  events = bmr_acc,\n                  w = rep(1, nrow(bmr_acc)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 500,\n                  adaptive = FALSE,\n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(2,2), \n                  max_depth = 8,\n                  agg = 30, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nThe below code chunk performs the following steps:\n\nAssign the calculated densities to column density in samples sf data frame and multiply by 1000 to convert to density by km.\nPlot the density value for each lixel centre using multiple functions of tmap.\n\n\nsamples$density &lt;- densities\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\n\nsamples2 &lt;- samples[order(samples$density),]\n\ncolorRamp &lt;- brewer.pal(n = 10, name = \"Spectral\")\ncolorRamp &lt;- rev(colorRamp)\n\ntitle &lt;- paste0(\"Traffic accident density by km in 2022,\",\n                \"\\nwithin a radius of 500 metres\")\n\ntm_shape(bmr_boundary) +\n  tm_polygons() +\ntm_shape(network) + \n  tm_lines(\"black\") + \n  tm_shape(samples2) + \n  tm_dots(\"density\", style = \"cont\", palette = colorRamp, n = 5, size = 0.1) + \n  tm_layout(legend.outside = TRUE, \n            main.title = title , main.title.size = 1)\n\n\n\n\n\n\n\n\nWe can see from the above map accidents density is higher across certain roads:\n\nThe vertical road connecting Samut Prakan, Bangkok and Pathum Thani.\nThe horizontal roads connecting Samut Sakhon, Bangkok and Samut Prakan. There are some hot spot on the road in Samut Prakan province as well."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-g--and-k-function-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#network-constrained-g--and-k-function-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "6.3 Network Constrained G- and K-Function Analysis",
    "text": "6.3 Network Constrained G- and K-Function Analysis\nIn this section, we perform complete spatial randomness (CSR) test using kfunctions() of spNetwork package. The null hypothesis is defined as:\nH0: The observed spatial point events (i.e traffic accidents) are randomly distributed over the street network in the 4 provinces in BMR.\nThe CSR test assumes a binomial point process, meaning the centres are randomly and independently distributed. If rejected, it indicates the centres are spatially dependent and form nonrandom patterns.\n\nkfun_acc &lt;- kfunctions(network, \n                             bmr_acc,\n                             start = 0, \n                             end = 1500, \n                             step = 100, \n                             width = 500,\n                             agg = 30,\n                             nsim = 29, \n                             resolution = 50,\n                             verbose = FALSE, \n                             conf_int = 0.05)\n\nNote: 9 key arguments used in above code chunk:\n\nlines: A feature collection of linestrings representing the underlying network. The geometries must be simple Linestrings.\npoints: A sf data frame representing points on the network. These points will be snapped on their nearest line.\nstart: A double, the start value for evaluating the k and g functions.\nend: A double, the last value for evaluating the k and g functions.\nstep: A double, specifying the interval between evaluations of the k and g functions.\nwidth: The width of each donut for the g-function.\nnsim: An integer for the number of Monte Carlo simulations. Typically, more than 50 simulations are needed for inference.\nresolution: A value to reduce calculation time when simulating random points by splitting edges and selecting vertices.\nconf_int: A double for setting the confidence interval (default is 0.05).\n\nFor more details on these arguments, refer to the spNetwork user guide.\nThe output of kfunctions() is a list containing:\n\nplotkA: A ggplot2 object representing the k-function values.\nplotgA: A ggplot2 object representing the g-function values.\nvaluesA: A DataFrame containing the data used to generate the plots.\n\nFor example, the ggplot2 object of k-function can be visualized using the following code chunk.\n\nkfun_acc$plotk\n\n\n\n\n\n\n\n\nThe blue line is the empirical network K-function of traffic accidents in the 4 provinces in BMR. The gray envelop represents the results of the 30 simulations in the confidence interval 2.5% - 97.5%. Since the blue line segment is way above the gray area, we can infer that the accidents are more clustered than what can be expected from a random distribution.\nThe below code chunk is used to plot the G function.\n\nkfun_acc$plotg\n\n\n\n\n\n\n\n\nThe G-function also demonstrates a clustered distribution. For distance lower than 1 kilometer, a local maximum is observed between 250 to 350 meters. This is consistent with the observations that certain part of the road networks have significantly higher density compared to others."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analyze-accidents-at-high-nkde-lixels",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#analyze-accidents-at-high-nkde-lixels",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "6.4 Analyze Accidents at high NKDE lixels",
    "text": "6.4 Analyze Accidents at high NKDE lixels\nFirst we assign the calculated NKDE to lixel sf data frame and multiply by 1000 to convert to density per km using below code chunk.\n\nlixels$density = densities*1000\n\nNext we use summary() to check the quantile distribution of density column.\n\nsummary(lixels$density)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.0000000 0.0000000 0.0000000 0.0009879 0.0000000 0.1394524 \n\n\nIn this section, we will focus on accidents happening at lixels with density higher than the mean. This is to understand which factors contribute to those parts of the road with above average accident density.\nWe remove the geometry column from lixels and create a new data frame lixels_df for easier data frame manipulation later on.\n\nlixels_df = st_drop_geometry(lixels)\n\nThe below code chunk performs the following steps:\n\nSnaps accident points to the nearest lixel within 50 meters using snapPointsToLines2() and return the respective lineID of the closest lixel.\nleft_join() with lixels_df to bring in the density values and other road attributes.\nFilter for accidents snapped to lixels with density above average.\n\n\nsnapped_accidents = snapPointsToLines2(\n  bmr_acc,\n  lixels,\n  idField = \"lineID\",\n  snap_dist = 50) |&gt;\n  left_join(lixels_df, by = c(\"nearest_line_id\" = \"lineID\")) |&gt;\n  filter(density &gt; 0.0009879)\n\n\n6.4.1 Environmental Factors\nThe environmental factors: road type, weather condition and road condition are visualized using ggplot() as in below code chunks.\n\nRoad TypeWeather ConditionRoad Condition\n\n\n\n# Group by road type and count the number of accidents\naccidents_by_road_type &lt;- snapped_accidents %&gt;%\n  group_by(highway) %&gt;%\n  summarise(accident_count = n()) %&gt;%\n  ungroup()\n\n# Create a column chart\nggplot(accidents_by_road_type, aes(x = reorder(highway, -accident_count), y = accident_count)) +\n  geom_col(fill = \"skyblue\") +\n  geom_text(aes(label = accident_count), vjust = -0.5, color = \"black\", size = 3.5) +  # Add data labels\n  labs(title = \"Number of Accidents by Road Type\", \n       x = \"Road Type\", \n       y = \"Number of Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe plot shows more than half of the accidents in 2022 happened on the motorway.\n\n\n\n# Group by condition and count the number of accidents\naccidents_by_weather &lt;- snapped_accidents %&gt;%\n  group_by(weather_rd) %&gt;%\n  summarise(accident_count = n()) %&gt;%\n  ungroup()\n\n# Create a column chart\nggplot(accidents_by_weather, aes(x = reorder(weather_rd, -accident_count), y = accident_count)) +\n  geom_col(fill = \"skyblue\") +\n  geom_text(aes(label = accident_count), vjust = -0.5, color = \"black\", size = 3.5) +  # Add data labels\n  labs(title = \"Number of Accidents by Weather Condition\", \n       x = \"Weather Condition\", \n       y = \"Number of Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe above plot shows that 90% of the accidents in 2022 happened under clear weather.\n\n\n\n# Group by condition and count the number of accidents\naccidents_by_road &lt;- snapped_accidents %&gt;%\n  group_by(road_rd) %&gt;%\n  summarise(accident_count = n()) %&gt;%\n  ungroup()\n\n# Create a column chart\nggplot(accidents_by_road, aes(x = reorder(road_rd, -accident_count), y = accident_count)) +\n  geom_col(fill = \"skyblue\") +\n  geom_text(aes(label = accident_count), vjust = -0.5, color = \"black\", size = 3.5) +  # Add data labels\n  labs(title = \"Number of Accidents by Road Condition\", \n       x = \"Road Condition\", \n       y = \"Number of Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe chart shows that 72.4% of the accidents happened on straight road with no slope.\n\n\n\n\n\n6.4.2 Behavioural Factors\nThe behavioral factors from presumed cause are visualized using ggplot() as in below code chunk.\n\n# Group by condition and count the number of accidents\naccidents_by_cause &lt;- snapped_accidents %&gt;%\n  group_by(presumed_cause_rd) %&gt;%\n  summarise(accident_count = n()) %&gt;%\n  ungroup()\n\n# Create a column chart\nggplot(accidents_by_cause, aes(x = reorder(presumed_cause_rd, -accident_count), y = accident_count)) +\n  geom_col(fill = \"skyblue\") +\n  geom_text(aes(label = accident_count), vjust = -0.5, color = \"black\", size = 3.5) +  # Add data labels\n  labs(title = \"Number of Accidents by Presumed Cause\", \n       x = \"Presumed Cause\", \n       y = \"Number of Accidents\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe chart shows 72% of accidents was due to speeding."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-dimension",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-dimension",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "7.1 Temporal Dimension",
    "text": "7.1 Temporal Dimension\nFirst we derive the start of each month for year 2022 to use as label for the later maps.\n\nstart &lt;- as.POSIXct(\"2022/01/01\", format = \"%Y/%m/%d\")\nmonths &lt;- as.character(1:12)\nmonths &lt;- ifelse(nchar(months)==1, paste0(\"0\", months), months)\nmonths_starts_labs &lt;- paste(\"2022/\",months,\"/01\", sep = \"\")\nmonths_starts_num &lt;- as.POSIXct(months_starts_labs, format = \"%Y/%m/%d\")\nmonths_starts_num &lt;- difftime(months_starts_num, start, units = \"days\")\nmonths_starts_num &lt;- as.numeric(months_starts_num)\nmonths_starts_labs &lt;- gsub(\"2022/\", \"\", months_starts_labs, fixed = TRUE)\n\nNext we calculate the kernel density values in time for several bandwidths using below code chunk.\n\nw &lt;- rep(1,nrow(bmr_acc))\nsamples_t &lt;- seq(0, max(bmr_acc$dayofyear), 1)\n\ntime_kernel_values &lt;- data.frame(\n  bw_10 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 10, kernel_name = \"quartic\"),\n  bw_20 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 20, kernel_name = \"quartic\"),\n  bw_30 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 30, kernel_name = \"quartic\"),\n  bw_40 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 40, kernel_name = \"quartic\"),\n  bw_50 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 50, kernel_name = \"quartic\"),\n  bw_60 = tkde(bmr_acc$dayofyear, w = w, samples = samples_t, bw = 60, kernel_name = \"quartic\"),\n  time = samples_t\n)\n\ndf_time &lt;- reshape2::melt(time_kernel_values,id.vars = \"time\")\ndf_time$variable &lt;- as.factor(df_time$variable)\n\nggplot(data = df_time) + \n  geom_line(aes(x = time, y = value)) +\n  scale_x_continuous(breaks = months_starts_num, labels = months_starts_labs) +\n  facet_wrap(vars(variable), ncol=2, scales = \"free\") + \n  theme(axis.text = element_text(size = 5))\n\n\n\n\n\n\n\n\nWe can see that a bandwidth between 30 and 40 days can capture the fluctuations and the trend in traffic accidents throughout 2022: the increase in traffic accident during mid of April (Songkran festival), followed by a decrease until Jun, before the number of accidents starts to increase until the end of the year."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-temporal-bandwidth-selection",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-temporal-bandwidth-selection",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "7.2 Spatial Temporal Bandwidth Selection",
    "text": "7.2 Spatial Temporal Bandwidth Selection\nThe cross validation likelihood of different network and time bandwiths are calculated using bw_tnkde_cv_likelihood_calc() as in below code chunk.\n\ncv_scores &lt;- bw_tnkde_cv_likelihood_calc(\n  bws_net = seq(500,1000,100),\n  bws_time = seq(20,60,10),\n  lines = network,\n  events = bmr_acc,\n  time_field = \"dayofyear\",\n  w = rep(1, nrow(bmr_acc)),\n  kernel_name = \"quartic\",\n  method = \"simple\",\n  diggle_correction = FALSE,\n  study_area = NULL,\n  max_depth = 8,\n  digits = 2,\n  tol = 0.1,\n  agg = 30,\n  sparse=TRUE,\n  grid_shape=c(1,1),\n  sub_sample=1,\n  verbose = FALSE)\n\n\ncv_scores\n\n            20        30        40        50        60\n500  -394.7186 -334.0445 -299.0691 -274.7406 -252.7279\n600  -374.2905 -313.2305 -277.8549 -254.1699 -232.1701\n700  -353.0463 -293.8778 -258.3238 -235.6832 -213.6953\n800  -333.0546 -275.9970 -239.6473 -218.0638 -196.2973\n900  -316.8013 -261.2312 -222.6306 -201.8828 -182.2077\n1000 -300.9982 -251.6730 -213.0711 -192.3536 -172.2757\n\n\nAccording to this “leave one out cross validation” method, the bandwidths of 1000 metres and 60 days has the lowest cross validation score and are chosen to be the optimal bandwidth for further density calculation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#perform-temporal-network-kernel-density-estimate-tnkde",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#perform-temporal-network-kernel-density-estimate-tnkde",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "7.3 Perform Temporal Network Kernel Density Estimate (TNKDE)",
    "text": "7.3 Perform Temporal Network Kernel Density Estimate (TNKDE)\nThe TNKDE is calculated using below code chunk.\n\n# choosing sample in times (every 30 days)\nsample_time &lt;- seq(0, max(bmr_acc$dayofyear), 30)\n\n# calculating densities\ntnkde_densities &lt;- tnkde(lines = network,\n                   events = bmr_acc,\n                   time_field = \"dayofyear\",\n                   w = rep(1, nrow(bmr_acc)), \n                   samples_loc = samples,\n                   samples_time = sample_time, \n                   kernel_name = \"quartic\",\n                   bw_net = 1000, bw_time = 60,\n                   method = \"simple\",\n                   div = \"bw\", max_depth = 8,\n                   digits = 2, tol = 0.01,\n                   agg = 30, grid_shape = c(2,2), \n                   verbose  = FALSE)\n\nWe add the TNKDE of every 30 days to the samples sf data frame\n\nsamples$tnkde_30 = tnkde_densities[,2]\nsamples$tnkde_60 = tnkde_densities[,3]\nsamples$tnkde_90 = tnkde_densities[,4]\nsamples$tnkde_120 = tnkde_densities[,5]\nsamples$tnkde_150 = tnkde_densities[,6]\nsamples$tnkde_180 = tnkde_densities[,7]\nsamples$tnkde_210 = tnkde_densities[,8]\nsamples$tnkde_240 = tnkde_densities[,9]\nsamples$tnkde_270 = tnkde_densities[,10]\nsamples$tnkde_300 = tnkde_densities[,11]\nsamples$tnkde_330 = tnkde_densities[,12]\nsamples$tnkde_360 = tnkde_densities[,13]\n\nWe use different functions of tmap to plot the map for each sample in time.\n\n# Extract the last 12 columns' names\ncols_to_plot &lt;- tail(colnames(samples), 12)\n# Plot the map for each column\ntm_shape(bmr_boundary) +\n    tm_polygons() +\n  tm_shape(samples) + \n    tm_dots(col = cols_to_plot, style = \"kmeans\", palette = \"Reds\",  n=10, size = 0.05) + \n  tm_layout(legend.show = FALSE, \n            title = cols_to_plot , title.size = 1)\n\nWarning: The value range of the variable \"tnkde_90\" is less than 1e-9\n\n\nWarning: The value range of the variable \"tnkde_120\" is less than 1e-9\n\n\nWarning: The value range of the variable \"tnkde_210\" is less than 1e-9\n\n\nWarning: The value range of the variable \"tnkde_360\" is less than 1e-9\n\n\n\n\n\n\n\n\n\nThe location of many of the hotspots stay along the same roads across different points in time:\n\nSeveral hotspots detected along the vertical road connecting Samut Prakan, Bangkok and Pathum Thani province. Refer to the maps on TNKDE at 60 days, 150 to 180 days, 240 to 300 days.\nSeveral hotspots detected along the horizontal road connecting Bangkok and Samut Sakhon province. Refer to the maps on TNKDE at 240 to 330 days."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#factors-affecting-traffic-accidents",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#factors-affecting-traffic-accidents",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "8.1 Factors affecting Traffic Accidents",
    "text": "8.1 Factors affecting Traffic Accidents\nThe above analysis highlights a few key factors affecting road traffic accidents in the 4 provinces of BMR:\n\nEnvironmental factors: do not seem to play an important role as majority of the accidents happened under clear weather (90%) and on straigh road with no slope (72%).\nDriver behaviors: is an important factor as 72% of the accidents recorded was due to speeding.\nSpatial factor: Network Constrained G- and K-Function results confirm the clustered distribution of accidents in BMR.\n\nOn Spatial temporal factors\n\nMonth in year: High STKDE in in December in Bangkok and Samut Sakhon area, followed by January. From August to November, the density spread more equally across the 4 provinces. Cool season (especially in January and December) has the highest density, this can be partly due to this season being high season for tourism in Thailand.\nDay in week: All 4 provinces have areas with high density on Monday (highest in Bangkok), followed by Sunday where high density areas are more spread out. The density is lower during middle of the week (Tuesday to Thursday) and starts to pick up towards the weekend (Friday to Sunday).\nHour of day: The highest density can be observed at late night (22PM to 0 AM of the next day) and from 8AM to 11:59AM. For the remainder of the day, high density can be observed during lunch time (12PM - 13PM) and in the evening (16PM - 19PM).\nThe TNKDE maps show many of the hotspots stay along the same roads across different points in time: the vertical road connecting Samut Prakan, Bangkok and Pathum Thani province and the horizontal road connecting Bangkok and Samut Sakhon province."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#future-improvement",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#future-improvement",
    "title": "Take-home Exercise 1: Geospatial Analytics for Public Good",
    "section": "8.2 Future Improvement",
    "text": "8.2 Future Improvement\nAs I encountered certain computational capacity constraint given the data size, the below improvements can be done on the analysis of the accidents spatial temporal distribution in BMR:\n\nAs the accidents distribution is clustered, using adaptive bandwith instead of fixed bandwidth for KDE methods may avoid underestimating the density of areas with lower number of accidents.\nUser method = “continuous” instead of “simple” since the road network in BMR contains many intersections.\nUse cross validation method for bandwidth selection to allow for a more data-driven approach when selecting bandwidth.\nIncrease the number of simulations to calculate network constrained G and K functions for a more comprehensive range of comparison."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise, we explore how to compute Global Measures of Spatial Autocorrelation (GMSA) using the spdep package. By the end of this exercise, you will be able to:\n\nImport geospatial data using functions from the sf package.\nImport a CSV file using the readr package.\nPerform relational joins with the dplyr package.\nCompute Global Spatial Autocorrelation (GSA) statistics using spdep functions.\nPlot a Moran scatterplot.\nCompute and visualize a spatial correlogram.\nProvide a statistically sound interpretation of GSA statistics."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#the-analytical-question",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, one of the main objectives for local governments and planners is to ensure the equitable distribution of development across a province. In this study, we aim to apply appropriate spatial statistical methods to determine whether development is evenly distributed geographically.\nIf development is not evenly distributed, the next question will be: “Is there evidence of spatial clustering?” If the answer is yes, we will then explore “Where are these clusters located?”\nFor this case study, we will examine the spatial pattern of a specific development indicator, GDP per capita, for Hunan Province in the People’s Republic of China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan province administrative boundary layer at county level. This geospatial data set is in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#set-the-analytical-tools",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#set-the-analytical-tools",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "2.3 Set the Analytical Tools",
    "text": "2.3 Set the Analytical Tools\nBefore starting, ensure the spdep, sf, tmap, and tidyverse packages are installed:\n\nsf: for importing and handling geospatial data,\ntidyverse: for data wrangling,\nspdep: for spatial weights and autocorrelation statistics,\ntmap: for creating cartographic-quality choropleth maps.\n\nThe code below performs the following:\n\nCreates a list of required packages,\nChecks for missing packages and installs them if needed,\nLoads the packages into the R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into r environment",
    "text": "3.1 Import shapefile into r environment\nThe code chunk below uses st_read()of sf package to import Hunan shapefile into R. The imported shapefile will be in simple features object.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into r environment",
    "text": "3.2 Import csv file into r environment\nNext, we import Hunan_2012.csv into R by using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#perform-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#perform-relational-join",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.3 Perform relational join",
    "text": "3.3 Perform relational join\nThe code below updates the attribute table of Hunan’s SpatialPolygonsDataFrame by merging it with the attribute fields of the hunan2012 dataframe, using the left_join() function from the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-regional-development-indicator",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "3.4 Visualize Regional Development Indicator",
    "text": "3.4 Visualize Regional Development Indicator\nNow, we will create a basemap and a choropleth map to display the distribution of GDPPC in 2012 using the qtm() function from the tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "4.1 Compute Contiguity Spatial Weights",
    "text": "4.1 Compute Contiguity Spatial Weights\nBefore computing global spatial autocorrelation statistics, we need to create spatial weights for the study area. Spatial weights define neighborhood relationships between geographical units, such as counties.\nIn the code below, the poly2nb() function from the spdep package computes contiguity weight matrices. It generates a neighbors list based on regions with shared boundaries. By default, the Queen contiguity rule is applied (neighboring regions share at least one point). You can specify queen = FALSE to use a different criterion, but without this argument, it defaults to the Queen method.\nThe code below calculates a Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report indicates that Hunan has 88 area units. The most connected unit has 11 neighbors, while two units have only one neighbor each."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nTo assign weights to each neighboring polygon, we’ll use equal weights (style = “W”). This approach gives each neighboring polygon a weight of 1 divided by the number of neighbors, then sums the weighted income values. While simple and intuitive, this method may misrepresent spatial autocorrelation, especially for edge polygons with fewer neighbors. For now, we’ll stick with style = “W,” but more robust alternatives like style = “B” are available.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nNote:\nThe nb2listw() function in R converts a neighbors list (an object of class nb) into a spatial weights object. It has two main arguments:\n\nstyle: This defines how weights are assigned. The options include:\n\n“B”: Basic binary coding (neighbors = 1, non-neighbors = 0).\n“W”: Row-standardized (weights sum to 1 for each row/neighborhood).\n“C”: Globally standardized (weights sum to 1 across all regions).\n“U”: Like “C” but scaled by the number of neighbors.\n“S”: Variance-stabilizing scheme (Tiefelsdorf et al. 1999).\n\nzero.policy: If TRUE, regions without neighbors are assigned zero weights, ensuring that their lagged values are zero."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#morans-i-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#morans-i-test",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.1 Moran’s I test",
    "text": "5.1 Moran’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.2 Compute Monte Carlo Moran’s I",
    "text": "5.2 Compute Monte Carlo Moran’s I\nThe following R code chunk conducts a permutation test for Moran’s I statistic using the moran.mc() function from the spdep package. A total of 1000 simulations will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-monte-carlo-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-monte-carlo-morans-i",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "5.3 Visualize Monte Carlo Moran’s I",
    "text": "5.3 Visualize Monte Carlo Moran’s I\nIt’s beneficial to closely examine the simulated Moran’s I test statistics. This can be done by plotting their distribution as a histogram using the code chunk below, which employs the hist() and abline() functions from R Graphics.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\n\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\n\n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#gearys-c-test",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#gearys-c-test",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.1 Geary’s C test",
    "text": "6.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.2 Compute Monte Carlo Geary’s C",
    "text": "6.2 Compute Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-the-monte-carlo-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#visualize-the-monte-carlo-gearys-c",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "6.3 Visualize the Monte Carlo Geary’s C",
    "text": "6.3 Visualize the Monte Carlo Geary’s C\nNext, we use the code chunk below to plot a histogram and reveal the distribution of the simulated values.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\n\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\n\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\n\n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-morans-i-correlogram",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "7.1 Compute Moran’s I correlogram",
    "text": "7.1 Compute Moran’s I correlogram\nThe below code chunk uses sp.correlogram() of spdep package to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used is Moran’s I. plot() of base Graph is used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nPlotting the output alone may not provide a complete interpretation since not all autocorrelation values are statistically significant. Therefore, it’s crucial to examine the full analysis report by printing the analysis results using the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-gearys-c-correlogram-and-plot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex051.html#compute-gearys-c-correlogram-and-plot",
    "title": "Hands-on Exercise 5.1: Global Measures of Spatial Autocorrelation",
    "section": "7.2 Compute Geary’s C correlogram and plot",
    "text": "7.2 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() from the spdep package computes a 6-lag spatial correlogram of GDPPC using Geary’s C for global spatial autocorrelation. The plot() function from base Graph is then used to visualize the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "Local Measures of Spatial Autocorrelation (LMSA) examine the relationships between each observation and its surroundings, rather than summarizing these relationships across the entire map. They provide scores that reveal the spatial structure in the data. The intuition behind LMSA metrics is similar to global ones, and some are mathematically connected, such as Local Indicators of Spatial Association (LISA). Additionally, Getis-Ord’s Gi-statistics offer complementary insights for geographically referenced data.\nIn this hands-on exercise, we explore how to compute LMSA using the spdep package, including the below:\n\nImport geospatial data using the sf package.\nImport CSV files using the readr package.\nPerform relational joins using the dplyr package.\nCompute LISA statistics for detecting clusters and outliers with the spdep package.\nCompute Getis-Ord’s Gi-statistics for identifying hot and cold spots with the spdep package.\nVisualize the analysis output using the tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#the-analytical-question",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "2.1 The analytical question",
    "text": "2.1 The analytical question\nIn spatial policy, a key objective for local governments and planners is to ensure equitable development distribution within a province. This study aims to apply spatial statistical methods to determine if development is geographically even. If not, we will investigate whether there is spatial clustering and, if so, identify the locations of these clusters.\nThis case study focuses on examining the spatial pattern of GDP per capita in Hunan Province, China."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#the-study-area-and-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#the-study-area-and-data",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "2.2 The Study Area and Data",
    "text": "2.2 The Study Area and Data\nTwo data sets will be used in this hands-on exercise:\n\nHunan province administrative boundary layer at county level. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#set-the-analytical-tools",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#set-the-analytical-tools",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "2.3 Set the Analytical Tools",
    "text": "2.3 Set the Analytical Tools\nBefore starting, ensure the spdep, sf, tmap, and tidyverse packages are installed:\n\nsf: for importing and handling geospatial data,\ntidyverse: for data wrangling,\nspdep: for spatial weights and autocorrelation statistics,\ntmap: for creating cartographic-quality choropleth maps.\n\nThe code below performs the following:\n\nCreates a list of required packages,\nChecks for missing packages and installs them if needed,\nLoads the packages into the R environment.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "3.1 Import shapefile into R environment",
    "text": "3.1 Import shapefile into R environment\nThe code chunk below uses st_read()of sf package to import Hunan shapefile into R. The imported shapefile will be in simple features object.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "3.2 Import csv file into r environment",
    "text": "3.2 Import csv file into r environment\nNext, we import Hunan_2012.csv into R by using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#perform-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#perform-relational-join",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "3.3 Perform relational join",
    "text": "3.3 Perform relational join\nThe code below updates the attribute table of Hunan’s SpatialPolygonsDataFrame by merging it with the attribute fields of the hunan2012 dataframe, using the left_join() function from the dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#visualize-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#visualize-regional-development-indicator",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "3.4 Visualize Regional Development Indicator",
    "text": "3.4 Visualize Regional Development Indicator\nNow, we will create a basemap and a choropleth map to display the distribution of GDPPC in 2012 using the qtm() function from the tmap package.\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#compute-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#compute-contiguity-spatial-weights",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "4.1 Compute Contiguity Spatial Weights",
    "text": "4.1 Compute Contiguity Spatial Weights\nBefore computing global spatial autocorrelation statistics, we need to create spatial weights for the study area. Spatial weights define neighborhood relationships between geographical units, such as counties.\nIn the code below, the poly2nb() function from the spdep package computes contiguity weight matrices. It generates a neighbors list based on regions with shared boundaries. By default, the Queen contiguity rule is applied (neighboring regions share at least one point). You can specify queen = FALSE to use a different criterion, but without this argument, it defaults to the Queen method.\nThe code below calculates a Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report indicates that Hunan has 88 area units. The most connected unit has 11 neighbors, while two units have only one neighbor each."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "4.2 Row-standardised weights matrix",
    "text": "4.2 Row-standardised weights matrix\nTo assign weights to each neighboring polygon, we’ll use equal weights (style = “W”). This approach gives each neighboring polygon a weight of 1 divided by the number of neighbors, then sums the weighted income values. While simple and intuitive, this method may misrepresent spatial autocorrelation, especially for edge polygons with fewer neighbors. For now, we’ll stick with style = “W,” but more robust alternatives like style = “B” are available.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nNote:\nThe nb2listw() function in R converts a neighbors list (an object of class nb) into a spatial weights object. It has two main arguments:\n\nstyle: This defines how weights are assigned. The options include:\n\n“B”: Basic binary coding (neighbors = 1, non-neighbors = 0).\n“W”: Row-standardized (weights sum to 1 for each row/neighborhood).\n“C”: Globally standardized (weights sum to 1 across all regions).\n“U”: Like “C” but scaled by the number of neighbors.\n“S”: Variance-stabilizing scheme (Tiefelsdorf et al. 1999).\n\nzero.policy: If TRUE, regions without neighbors are assigned zero weights, ensuring that their lagged values are zero."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#compute-local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#compute-local-morans-i",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "4.3 Compute local Moran’s I",
    "text": "4.3 Compute local Moran’s I\nTo compute local Moran’s I, we’ll use the localmoran() function from the spdep package. This function calculates Ii values based on a set of zi values and a listw object that provides neighbor weighting information for the polygons associated with the zi values.\nThe code chunks below demonstrate how to compute local Moran’s I for GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nThe localmoran() function returns a matrix with the following columns:\n\nIi: Local Moran’s I statistics\nE.Ii: Expectation of local Moran statistic under the randomization hypothesis\nVar.Ii: Variance of local Moran statistic under the randomization hypothesis\nZ.Ii: Standard deviate of local Moran statistic\nPr(): P-value of local Moran statistic\n\nThe code chunk below lists the contents of the local Moran matrix using printCoefmat().\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\n4.3.1 Map the local Moran’s I\nBefore mapping the local Moran’s I, it’s advisable to append the local Moran’s I dataframe (localMI) to the hunan SpatialPolygonDataFrame. The code chunks below perform this task, resulting in a SpatialPolygonDataFrame called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n4.3.2 Map local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values using the code chunk below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.3 Map local Moran’s I p-values\nThe choropleth indicates both positive and negative Ii values. However, it’s important to consider the p-values for these values.\nThe code chunks below use the tmap package to produce a choropleth map of Moran’s I p-values.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n4.3.4 Map both local Moran’s I values and p-values\nTo effectively interpret the results, it’s best to plot both the local Moran’s I values map and the corresponding p-values map side by side.\nThe code chunk below will help create this visualization.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plotting-moran-scatterplot",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plotting-moran-scatterplot",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "5.1 Plotting Moran scatterplot",
    "text": "5.1 Plotting Moran scatterplot\nThe Moran scatterplot illustrates the relationship between the values of a chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below uses moran.plot() from the spdep package to plot the Moran scatterplot for GDPPC 2012.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is divided into four quadrants. The top right quadrant represents areas with high GDPPC surrounded by areas with average GDPPC, known as high-high locations."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plot-moran-scatterplot-with-standardised-variable",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plot-moran-scatterplot-with-standardised-variable",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "5.2 Plot Moran scatterplot with standardised variable",
    "text": "5.2 Plot Moran scatterplot with standardised variable\nFirst, we’ll use scale() to center and scale the variable. Centering is done by subtracting the mean (excluding NAs) from the corresponding columns, and scaling is achieved by dividing the centered variable by its standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nAdding as.vector() ensures the output is a vector, which integrates neatly into our dataframe.\nNow, we’re ready to plot the Moran scatterplot again using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#prepare-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#prepare-lisa-map-classes",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "5.3 Prepare LISA map classes",
    "text": "5.3 Prepare LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nAll the steps can be combined into one code chunk as shown below.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plot-lisa-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#plot-lisa-map",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "5.4 Plot LISA map",
    "text": "5.4 Plot LISA map\nNow, we can build the LISA map using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nIt is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other for more effective interpretation.\nThe code chunk below is used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "6.1 Getis and Ord’s G-Statistics",
    "text": "6.1 Getis and Ord’s G-Statistics\nGetis and Ord’s G-statistics identify spatial anomalies by examining neighbors within a defined proximity to find clusters of high or low values. Statistically significant hot spots are areas with high values surrounded by other high-value areas.\nThe analysis involves three steps:\n\nDeriving a spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#derive-distance-based-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#derive-distance-based-weight-matrix",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "6.2 Derive distance-based weight matrix",
    "text": "6.2 Derive distance-based weight matrix\nUnlike spatial autocorrelation, which considers units sharing borders, Getis-Ord defines neighbors based on distance. There are two types of distance-based proximity matrices:\n\nFixed distance weight matrix\nAdaptive distance weight matrix\n\n\n6.2.1 Derive the centroid\nWe need points associated with each polygon to create a connectivity graph. This involves using a mapping function to apply st_centroid() to the geometry column of us.bound. The map_dbl function from the purrr package helps extract longitude values, ensuring they are in a separate data frame. For more details, refer to the map documentation.\nTo get longitude values, map the st_centroid() function over the geometry column of us.bound and access the longitude value using double bracket notation [[]] and 1. This retrieves only the longitude, the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n6.2.2 Determine the cut-off distance\nFirst, we need to determine the upper limit for the distance band using the following steps:\n\nUse knearneigh() from the spdep package to return a matrix with the indices of points belonging to the set of the k nearest neighbors.\nConvert the knn object returned by knearneigh() into a neighbors list of class nb, containing neighbor region number IDs, using knn2nb().\nUse nbdists() from spdep to return the length of neighbor relationship edges. The function returns distances in the units of the coordinates if projected, otherwise in kilometers.\nRemove the list structure of the returned object using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n6.2.3 Compute fixed distance weight matrix\nNext we compute the distance weight matrix using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw ."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "6.3 Computing adaptive distance weight matrix",
    "text": "6.3 Computing adaptive distance weight matrix\nA fixed distance weight matrix often results in more densely settled areas (urban areas) having more neighbors, while less densely settled areas (rural counties) have fewer neighbors. This smooths neighbor relationships across more neighbors.\nYou can control the number of neighbors directly using k-nearest neighbors, either accepting asymmetric neighbors or imposing symmetry, as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nnb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#gi-statistics-using-fixed-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#gi-statistics-using-fixed-distance",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "7.1 Gi statistics using fixed distance",
    "text": "7.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe localG() function outputs a vector of G or Gstar values, with attributes “gstari” (TRUE or FALSE), “call” (the function call), and class “localG”. The Gi statistics are represented as Z-scores, where higher values indicate greater clustering intensity, and the direction (positive or negative) indicates high or low clusters.\nNext, we’ll join the Gi values to the corresponding hunan sf data frame using the code chunk below:\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nThis code chunk performs three tasks:\n\nConverts the output vector (gi.fixed) into an R matrix object using as.matrix().\nUses cbind() to join hunan and the gi.fixed matrix, creating a new SpatialPolygonDataFrame called hunan.gi.\nRenames the field of the Gi values to gstat_fixed using rename()."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#map-gi-values-with-fixed-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#map-gi-values-with-fixed-distance-weights",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "7.2 Map Gi values with fixed distance weights",
    "text": "7.2 Map Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using a fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#gi-statistics-using-adaptive-distance",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#gi-statistics-using-adaptive-distance",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "7.3 Gi statistics using adaptive distance",
    "text": "7.3 Gi statistics using adaptive distance\nThe code chunk computes the Gi values for GDPPC2012 using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#map-gi-values-with-adaptive-distance-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex052.html#map-gi-values-with-adaptive-distance-weights",
    "title": "Hands-on Exercise 5.2: Local Measures of Spatial Autocorrelation",
    "section": "7.4 Map Gi values with adaptive distance weights",
    "text": "7.4 Map Gi values with adaptive distance weights\nNow, let’s visualize the locations of hot spots and cold spots. We’ll use the choropleth mapping functions from the tmap package to map the Gi values.\nThe code chunk below demonstrates how to map the Gi values derived using a fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualize-nkde",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualize-nkde",
    "title": "In-class Exercise 3: Network Constrained Spatial Point Patterns Analysis",
    "section": "6.4 Visualize NKDE",
    "text": "6.4 Visualize NKDE\nBefore visualizing the NKDE values, the code chunk below inserts the computed density values (densities) into the samples and lixels objects as a new density field.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\n\nSince svy21 projection system is in meter, the computed density values are very small (e.g., 0.0000005). The code chunk below rescales the density values from events per meter to events per kilometer.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\n\nThe code below uses appropriate functions of tmap package to prepare interactive and high cartographic quality map visualisation.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nThe interactive map above effectively reveals road segments with relatively higher density of childcare centres (darker color) than road segments with relatively lower density of childcare centres (lighter color)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "",
    "text": "For this exercise, sfdep will be used. sfdep creates an sf and tidyverse-friendly interface that adds new functionality not found in spdep. It uses list columns extensively to achieve this.\n\npacman::p_load(sf, tmap, tidyverse, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-shapefile-into-r-environment",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-shapefile-into-r-environment",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "3.1 Import shapefile into R environment",
    "text": "3.1 Import shapefile into R environment\nThe code chunk below uses st_read()of sf package to import Hunan shapefile into R. The imported shapefile will be in simple features object.\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex05\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-csv-file-into-r-environment",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#import-csv-file-into-r-environment",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "3.1 Import csv file into r environment",
    "text": "3.1 Import csv file into r environment\nNext, we import Hunan_2012.csv into R by using read_csv() of readr package. The output is in R data frame class.\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perform-relational-join",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perform-relational-join",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "3.2 Perform relational join",
    "text": "3.2 Perform relational join\nThe code below updates the attribute table of Hunan’s SpatialPolygonsDataFrame by merging it with the attribute fields of the hunan2012 dataframe, using the left_join() function from the dplyr package.\n\nhunan_GDPPC &lt;- left_join(hunan,hunan2012) %&gt;%\n  select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`\n\n\n:::"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#step-1-derive-queens-contiguity-weights-sfdep-methods",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#step-1-derive-queens-contiguity-weights-sfdep-methods",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "5.1 Step 1: Derive Queen’s contiguity weights: sfdep methods",
    "text": "5.1 Step 1: Derive Queen’s contiguity weights: sfdep methods\n\nwm_q = hunan_GDPPC |&gt;\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) # insert to before column 1 instead of inserting at the back\n\nst_weights() provide 3 arguments:\n\nnb: a neighbor list object created by st_neighbors()\nstyle: This defines how weights are assigned. The options include:\n\n“B”: Basic binary coding (neighbors = 1, non-neighbors = 0).\n“W”: Row-standardized (weights sum to 1 for each row/neighborhood).\n“C”: Globally standardized (weights sum to 1 across all regions).\n“U”: Like “C” but scaled by the number of neighbors.\n“S”: Variance-stabilizing scheme (Tiefelsdorf et al. 1999).\n\nallow_zero: If TRUE, regions without neighbors are assigned zero weights, ensuring that their lagged values are zero."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-global-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-global-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "5.2 Compute Global Moran’s I",
    "text": "5.2 Compute Global Moran’s I\nThe below code chunk uses global_moran() function to compute the Moran I’s value. This function returns the output in a tibble data.frame.\n\nmoranI &lt;- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nIn general, Moran’s I test should be performed instead of just computing the Moran’s I statistics. With sfdep package, Moran’s I test can be performed using global_moran_test() as shown in the code chunk below.\n\nglobal_moran_test(wm_q$GDPPC,\n                      wm_q$nb,\n                      wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nAs the p-value is smaller than 0.05, we can reject the null hypothesis. Since Moran I statistic is larger than 0, the distribution show sign of clustering."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perform-global-morani-permutation-test",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#perform-global-morani-permutation-test",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "5.3 Perform Global Moran’I permutation test",
    "text": "5.3 Perform Global Moran’I permutation test\nIn practice, Monte Carlo simulation should be used to perform the statistics test. The below code chunk perform permutation test using global_moran_perm() from sfdep package.\n\nStep 1Step 2\n\n\nSet the seed to ensure the computation is reproducible\n\nset.seed(1234)\n\n\n\nNext global_moran_perm() is used to run perform Monte Carlo simulation and run permutation test.\n\nglobal_moran_perm(wm_q$GDPPC,\n                  wm_q$nb,\n                  wm_q$wt,\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nThe statistical report indicates a p-value smaller than the alpha value of 0.05, providing enough evidence to reject the null hypothesis that the spatial distribution of GDP per capita is random. Since Moran’s I statistic is greater than 0, we can infer clustering in the spatial distribution.\nNote: The number of simulations is always equal to nsim + 1. For nsim = 99, this means 100 simulations will be performed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualizing-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "9.1 Visualizing Gi*",
    "text": "9.1 Visualizing Gi*\n\nHCSA_sig = HCSA |&gt;\n  filter(p_sim &lt; 0.05)\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") +\n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this exercise, we explore how to delineate homogeneous regions using geographically referenced multivariate data through two analyses:\n\nHierarchical cluster analysis\nSpatially constrained cluster analysis.\n\nThe below techniques will be covered in this exercise:\n\nConvert GIS polygon data to R’s simple feature data.frame using the sf package.\nConvert simple feature data.frame to R’s SpatialPolygonDataFrame object using sf.\nPerform cluster analysis with hclust() in Base R.\nConduct spatially constrained cluster analysis with skater() in Base R.\nVisualize analysis output using ggplot2 and tmap."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#the-analytical-question",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#the-analytical-question",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.1 The Analytical Question",
    "text": "2.1 The Analytical Question\nIn geobusiness and spatial policy, it’s common to delineate areas into homogeneous regions using multivariate data. This exercise focuses on delineating Shan State, Myanmar, using multiple ICT measures: Radio, Television, Landline phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#the-data",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.2 The data",
    "text": "2.2 The data\nTwo datasets will be used:\n\nMyanmar Township Boundary Data: GIS data in ESRI shapefile format with township boundary information.\nShan-ICT.csv: Extract from the 2014 Myanmar Population and Housing Census at the township level.\n\nBoth datasets are from the Myanmar Information Management Unit (MIMU)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#install-and-load-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#install-and-load-r-packages",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "2.3 Install and Load R Packages",
    "text": "2.3 Install and Load R Packages\nWe install and load the necessary R packages using below code chunk:\n\nSpatial data handling: sf, rgdal, spdep\nAttribute data handling: tidyverse (includes readr, ggplot2, dplyr)\nChoropleth mapping: tmap\nMultivariate data visualization and analysis: corrplot, ggpubr, heatmaply\nCluster analysis: cluster, ClustGeo\n\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#derive-queens-contiguity-weights-sfdep-methods",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#derive-queens-contiguity-weights-sfdep-methods",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "5.1 Derive Queen’s contiguity weights: sfdep methods",
    "text": "5.1 Derive Queen’s contiguity weights: sfdep methods\n\nwm_q = hunan_GDPPC |&gt;\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1) # insert to before column 1 instead of inserting at the back\n\nst_weights() provide 3 arguments:\n\nnb: a neighbor list object created by st_neighbors()\nstyle: This defines how weights are assigned. The options include:\n\n“B”: Basic binary coding (neighbors = 1, non-neighbors = 0).\n“W” (default option): Row-standardized (weights sum to 1 for each row/neighborhood).\n“C”: Globally standardized (weights sum to 1 across all regions).\n“U”: Like “C” but scaled by the number of neighbors.\n“S”: Variance-stabilizing scheme (Tiefelsdorf et al. 1999).\n\nallow_zero: If TRUE, regions without neighbors are assigned zero weights, ensuring that their lagged values are zero.\n\n\nwm_q\n\nSimple feature collection with 88 features and 8 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\nFirst 10 features:\n                               nb\n1                 2, 3, 4, 57, 85\n2               1, 57, 58, 78, 85\n3                     1, 4, 5, 85\n4                      1, 3, 5, 6\n5                     3, 4, 6, 85\n6                4, 5, 69, 75, 85\n7                  67, 71, 74, 84\n8       9, 46, 47, 56, 78, 80, 86\n9           8, 66, 68, 78, 84, 86\n10 16, 17, 19, 20, 22, 70, 72, 73\n                                                                            wt\n1                                                      0.2, 0.2, 0.2, 0.2, 0.2\n2                                                      0.2, 0.2, 0.2, 0.2, 0.2\n3                                                       0.25, 0.25, 0.25, 0.25\n4                                                       0.25, 0.25, 0.25, 0.25\n5                                                       0.25, 0.25, 0.25, 0.25\n6                                                      0.2, 0.2, 0.2, 0.2, 0.2\n7                                                       0.25, 0.25, 0.25, 0.25\n8  0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571, 0.1428571\n9             0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667, 0.1666667\n10                      0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125\n     NAME_2  ID_3    NAME_3   ENGTYPE_3    County GDPPC\n1   Changde 21098   Anxiang      County   Anxiang 23667\n2   Changde 21100   Hanshou      County   Hanshou 20981\n3   Changde 21101    Jinshi County City    Jinshi 34592\n4   Changde 21102        Li      County        Li 24473\n5   Changde 21103     Linli      County     Linli 25554\n6   Changde 21104    Shimen      County    Shimen 27137\n7  Changsha 21109   Liuyang County City   Liuyang 63118\n8  Changsha 21110 Ningxiang      County Ningxiang 62202\n9  Changsha 21111 Wangcheng      County Wangcheng 70666\n10 Chenzhou 21112     Anren      County     Anren 12761\n                         geometry\n1  POLYGON ((112.0625 29.75523...\n2  POLYGON ((112.2288 29.11684...\n3  POLYGON ((111.8927 29.6013,...\n4  POLYGON ((111.3731 29.94649...\n5  POLYGON ((111.6324 29.76288...\n6  POLYGON ((110.8825 30.11675...\n7  POLYGON ((113.9905 28.5682,...\n8  POLYGON ((112.7181 28.38299...\n9  POLYGON ((112.7914 28.52688...\n10 POLYGON ((113.1757 26.82734..."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.1 LISA Map",
    "text": "6.1 LISA Map\nLISA map is a categorical map showing outliers and clusters. There are two types of outliers: High-Low and Low-High, and two types of clusters: High-High and Low-Low. It combines local Moran’s I values and their p-values to interpret geographical areas."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.2 Compute Local Moran’s I",
    "text": "6.2 Compute Local Moran’s I\nIn this section, we explore how to use local_moran() to compute Local Moran’s I of GDPPC at county level.\n\nlisa = wm_q |&gt;\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) |&gt;\n      unnest(local_moran)\n\nThe output of local_moran() is an sf data frame with the following columns:\n\nii: Local Moran statistic\neii: Expectation of local Moran statistic; for local_moran_perm, the permutation sample means\nvar_ii: Variance of local Moran statistic; for local_moran_perm, the permutation sample standard deviations\nz_ii: Standard deviate of local Moran statistic; for local_moran_perm, based on permutation sample means and standard deviations\np_ii: P-value of local Moran statistic using pnorm(); for local_moran_perm, using standard deviates based on permutation sample means and standard deviations\np_ii_sim: For local_moran_perm(), rank() and punif() of observed statistic rank for [0, 1] p-values using alternative=\np_folded_sim: The simulation folded [0, 0.5] range ranked p-value\nskewness: For local_moran_perm, the output of e1071::skewness() for the permutation samples underlying the standard deviates\nkurtosis: For local_moran_perm, the output of e1071::kurtosis() for the permutation samples underlying the standard deviates"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.3 Visualize Local Moran’s I",
    "text": "6.3 Visualize Local Moran’s I\nThe code chunk below use tmap functions to plot a choropleth map using value in the ii field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-p-value-of-local-morans-i",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.4 Visualize p-value of local Moran’s I",
    "text": "6.4 Visualize p-value of local Moran’s I\nThe code chunk below use tmap function to plot a choropleth map using p_ii_sim field.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha = 0.5) +\n   tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-morans-i-and-p-value",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.5 Visualize local Moran’s I and p-value",
    "text": "6.5 Visualize local Moran’s I and p-value\nWe can plot both maps together for effective comparison.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-lisa-map",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-lisa-map",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "6.6 Visualize LISA map",
    "text": "6.6 Visualize LISA map\nIn the lisa sf data frame, three fields contain the LISA categories: mean, median, and pysal. Generally, the mean classification is used, as shown in the code chunk below.\n\nlisa_sig &lt;- lisa  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(lisa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-local-gi-statistics",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#compute-local-gi-statistics",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "7.1 Compute Local Gi statistics",
    "text": "7.1 Compute Local Gi statistics\nAs usual, we will need to derive a spatial weight matrix before we can compute local Gi* statistics. The below code chunk derives a spatial weight matrix using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wts = st_inverse_distance(nb, \n                              geometry, \n                              scale = 1,\n                              alpha = 1),\n         .before = 1)\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wts = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nNote:\n\nGi* and local Gi* are distance-based spatial statistics. Hence, distance methods instead of contiguity methods should be used to derive the spatial weight matrix.\nSince we are going to compute Gi* statistics, include_self()is used.\n\nNext compute the local Gi* by using the code chunk below.\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wts, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n    gi_star cluster     e_gi  var_gi std_dev p_value p_sim p_folded_sim skewness\n      &lt;dbl&gt; &lt;fct&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.261   Low     0.00126  1.07e-7  0.283  7.78e-1  0.66         0.33    0.783\n 2 -0.276   Low     0.000969 4.76e-8 -0.123  9.02e-1  0.98         0.49    0.713\n 3  0.00573 High    0.00156  2.53e-7 -0.0571 9.54e-1  0.78         0.39    0.972\n 4  0.528   High    0.00155  2.97e-7  0.321  7.48e-1  0.56         0.28    0.942\n 5  0.466   High    0.00137  2.76e-7  0.386  7.00e-1  0.52         0.26    1.32 \n 6 -0.445   High    0.000992 7.08e-8 -0.588  5.57e-1  0.68         0.34    0.692\n 7  2.99    High    0.000700 4.05e-8  3.13   1.74e-3  0.04         0.02    0.975\n 8  2.04    High    0.00152  1.58e-7  1.77   7.59e-2  0.16         0.08    1.26 \n 9  4.42    High    0.00130  1.18e-7  4.22   2.39e-5  0.02         0.01    1.20 \n10  1.21    Low     0.00175  1.25e-7  1.49   1.36e-1  0.18         0.09    0.408\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-gi",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-gi",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "7.2 Visualize Gi*",
    "text": "7.2 Visualize Gi*\nThe code chunk below uses tmap functions to plot the local Gi* (i.e. gi_star) at the province level.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-p-value-of-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "7.3 Visualize p-value of HCSA",
    "text": "7.3 Visualize p-value of HCSA\nThe code chunk below uses tmap functions to plot the p-values of local Gi* (i.e. p_sim) at the province level.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") + \n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-hcsa",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-local-hcsa",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "7.4 Visualize local HCSA",
    "text": "7.4 Visualize local HCSA\nBoth maps can be plotted next to each other for effective comparison as below.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\nVariable(s) \"gi_star\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-hot-spot-and-cold-spot-areas",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualize-hot-spot-and-cold-spot-areas",
    "title": "In-class Exercise 5: Global and Local Measures of Spatial Autocorrelation - sfdep method",
    "section": "7.5 Visualize hot spot and cold spot areas",
    "text": "7.5 Visualize hot spot and cold spot areas\nNow, we are ready to plot the significant (i.e. p-values less than 0.05) hot spot and cold spot areas using appropriate tmap functions as shown below.\n\nHCSA_sig &lt;- HCSA  %&gt;%\n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(HCSA_sig) +\n  tm_fill(\"cluster\") + \n  tm_borders(alpha = 0.4)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\n\n\n\n\n\n\n\n\n\nNote: The figure above reveals that there is one hot spot area and two cold spot areas. Interestingly, the hot spot areas coincide with the High-high cluster identifies by using local Moran’s I method in the earlier sub-section."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#import-geospatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#import-geospatial-data-into-r-environment",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.1 Import geospatial data into R environment",
    "text": "3.1 Import geospatial data into R environment\nIn this section, you’ll import Myanmar Township Boundary GIS data and its attribute table into the R environment.\nThe data, in ESRI shapefile format, will be imported using the st_read() function from the sf package.\n\nshan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object, named shan_sf, is saved as a simple feature data frame. We can view its content using the below code chunk.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNote that sf data frames conform to Hadley Wickham’s tidy framework, allowing us to use glimpse() to reveal the data types of its fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#importing-aspatial-data-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#importing-aspatial-data-into-r-environment",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.2 Importing aspatial data into R environment",
    "text": "3.2 Importing aspatial data into R environment\nThe csv file is imported using read_csv function of readr package.\n\nict &lt;- read_csv (\"data/aspatial/Shan-ICT.csv\")\n\nRows: 55 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): District Pcode, District Name, Township Pcode, Township Name\ndbl (7): Total households, Radio, Television, Land line phone, Mobile phone,...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict and saved in R tibble data.frame format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the result tibble data.frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#derive-new-variables-using-dplyr-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#derive-new-variables-using-dplyr-package",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "3.3 Derive new variables using dplyr package",
    "text": "3.3 Derive new variables using dplyr package\nThe values are measured by the number of households. Using these values directly can be biased due to varying total household numbers. Typically, townships with more households will also have more households owning radios, TVs, etc.\nTo address this, we will calculate the penetration rate for each ICT variable using the code below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.1 EDA using statistical graphics",
    "text": "4.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution).\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we plot the distribution of the newly derived variables (i.e. Radio penetration rate) using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nWe can see that the distribution of RADIO_PR (radio penetration rate) is lesses skewed and have fewer outliers than the original variable RADIO .\nThe below code chunks is used to plot several historgrams together to examine the distribution of selected variables in the ict_derived data.frame. First the individual histograms are created as below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, ggarrange() of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#eda-using-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#eda-using-choropleth-map",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "4.2 EDA using choropleth map",
    "text": "4.2 EDA using choropleth map\n\n4.2.1 Join geospatial data with aspatial data\nTo create a choropleth map, we need to merge the geospatial data object (shan_sf) with the aspatial data frame (ict_derived) using the left_join function from the dplyr package to create a single dataframe. The shan_sf data frame serves as the base, and ict_derived is the join table, with TS_PCODE as the unique identifier.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/rds/shan_sf.rds\")\n\nThe output message above shows that TS_CODE field is the common field used to perform the left-join.\nNote: This process updates shan_sf with fields from ict_derived without creating a new output data frame. The data fields from ict_derived data frame are now updated into the data frame of shan_sf as can be seen from below code chunk.\n\nshan_sf &lt;- read_rds(\"data/rds/shan_sf.rds\")\n\n\n\n4.2.2 Preparing a choropleth map\nTo quickly visualize the Radio penetration rate in Shan State at the township level, we will use the qtm() function from tmap package to plot a choropleth map.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nTo highlight the bias in the choropleth map due to the total number of households in each township, we will create two separate maps: one for the total number of households (TT_HOUSEHOLDS.map) and one for households with radios (RADIO.map) using the code below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nThe choropleth maps clearly indicate that townships with a larger number of households also exhibit higher radio ownership.\nNow, let’s plot the choropleth maps for the total number of households and the radio penetration rate using the code below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\nHere we can observe there are areas with lower number of households but have higher radio penetration."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#extract-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#extract-clustering-variables",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.1 Extract clustering variables",
    "text": "6.1 Extract clustering variables\nThe code chunk below is used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows index to township name instead of row number using the code chunk below.\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced by the township name.\nNext we delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#data-standardisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#data-standardisation",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.2 Data Standardisation",
    "text": "6.2 Data Standardisation\nCluster analysis often involves multiple variables with different value ranges. To prevent bias towards variables with larger values, it’s important to standardize the input variables before performing cluster analysis.\n\n6.2.1 Min-Max standardisation\nThe code chunk below uses normalize() function from the heatmaply package to standardize the clustering variables using Min-Max method. The summary() function then displays the summary statistics of standardized variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nWe can see the values of the Min-max standardised clustering variables are in the range 0-1 now.\n\n\n6.2.2 Z-score standardisation\nZ-score standardisation can be performed easily using scale() of Base R. The code chunk below is used to stadardize the clustering variables using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nWe can see the mean and standard deviation of the Z-score standardized clustering variables are 0 and 1, respectively.\nNote: The describe() function from the psych package is used instead of summary() from Base R because it provides the standard deviation.\nWarning: The Z-score standardization method should only be used if we assume all variables come from a normal distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-the-standardised-clustering-variables",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-the-standardised-clustering-variables",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.3 Visualize the standardised clustering variables",
    "text": "6.3 Visualize the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\nWe can see that after standardization, the variables distribution resemble more of a normal distribution with the number of values count increasing towards the mean.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-proximity-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-proximity-matrix",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.4 Compute proximity matrix",
    "text": "6.4 Compute proximity matrix\nIn R, many packages offer functions to calculate distance matrices. We will use the dist() function to compute the proximity matrix.\ndist() supports six distance calculations: Euclidean, maximum, Manhattan, Canberra, binary, and Minkowski. The default is Euclidean.\nThe code below computes the proximity matrix using the Euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nTo list the contents of proxmat for inspection, use the following code:\n\nproxmat\n\n             Mongmit   Pindaya   Ywangan  Pinlaung    Mabein     Kalaw\nPindaya    171.86828                                                  \nYwangan    381.88259 257.31610                                        \nPinlaung    57.46286 208.63519 400.05492                              \nMabein     263.37099 313.45776 529.14689 312.66966                    \nKalaw      160.05997 302.51785 499.53297 181.96406 198.14085          \nPekon       59.61977 117.91580 336.50410  94.61225 282.26877 211.91531\nLawksawk   140.11550 204.32952 432.16535 192.57320 130.36525 140.01101\nNawnghkio   89.07103 180.64047 377.87702 139.27495 204.63154 127.74787\nKyaukme    144.02475 311.01487 505.89191 139.67966 264.88283  79.42225\nMuse       563.01629 704.11252 899.44137 571.58335 453.27410 412.46033\nLaihka     141.87227 298.61288 491.83321 101.10150 345.00222 197.34633\nMongnai    115.86190 258.49346 422.71934  64.52387 358.86053 200.34668\nMawkmai    434.92968 437.99577 397.03752 398.11227 693.24602 562.59200\nKutkai      97.61092 212.81775 360.11861  78.07733 340.55064 204.93018\nMongton    192.67961 283.35574 361.23257 163.42143 425.16902 267.87522\nMongyai    256.72744 287.41816 333.12853 220.56339 516.40426 386.74701\nMongkaing  503.61965 481.71125 364.98429 476.29056 747.17454 625.24500\nLashio     251.29457 398.98167 602.17475 262.51735 231.28227 106.69059\nMongpan    193.32063 335.72896 483.68125 192.78316 301.52942 114.69105\nMatman     401.25041 354.39039 255.22031 382.40610 637.53975 537.63884\nTachileik  529.63213 635.51774 807.44220 555.01039 365.32538 373.64459\nNarphan    406.15714 474.50209 452.95769 371.26895 630.34312 463.53759\nMongkhet   349.45980 391.74783 408.97731 305.86058 610.30557 465.52013\nHsipaw     118.18050 245.98884 388.63147  76.55260 366.42787 212.36711\nMonghsat   214.20854 314.71506 432.98028 160.44703 470.48135 317.96188\nMongmao    242.54541 402.21719 542.85957 217.58854 384.91867 195.18913\nNansang    104.91839 275.44246 472.77637  85.49572 287.92364 124.30500\nLaukkaing  568.27732 726.85355 908.82520 563.81750 520.67373 427.77791\nPangsang   272.67383 428.24958 556.82263 244.47146 418.54016 224.03998\nNamtu      179.62251 225.40822 444.66868 170.04533 366.16094 307.27427\nMonghpyak  177.76325 221.30579 367.44835 222.20020 212.69450 167.08436\nKonkyan    403.39082 500.86933 528.12533 365.44693 613.51206 444.75859\nMongping   265.12574 310.64850 337.94020 229.75261 518.16310 375.64739\nHopong     136.93111 223.06050 352.85844  98.14855 398.00917 264.16294\nNyaungshwe  99.38590 216.52463 407.11649 138.12050 210.21337  95.66782\nHsihseng   131.49728 172.00796 342.91035 111.61846 381.20187 287.11074\nMongla     384.30076 549.42389 728.16301 372.59678 406.09124 260.26411\nHseni      189.37188 337.98982 534.44679 204.47572 213.61240  38.52842\nKunlong    224.12169 355.47066 531.63089 194.76257 396.61508 273.01375\nHopang     281.05362 443.26362 596.19312 265.96924 368.55167 185.14704\nNamhkan    386.02794 543.81859 714.43173 382.78835 379.56035 246.39577\nKengtung   246.45691 385.68322 573.23173 263.48638 219.47071  88.29335\nLangkho    164.26299 323.28133 507.78892 168.44228 253.84371  67.19580\nMonghsu    109.15790 198.35391 340.42789  80.86834 367.19820 237.34578\nTaunggyi   399.84278 503.75471 697.98323 429.54386 226.24011 252.26066\nPangwaun   381.51246 512.13162 580.13146 356.37963 523.44632 338.35194\nKyethi     202.92551 175.54012 287.29358 189.47065 442.07679 360.17247\nLoilen     145.48666 293.61143 469.51621  91.56527 375.06406 217.19877\nManton     430.64070 402.42888 306.16379 405.83081 674.01120 560.16577\nMongyang   309.51302 475.93982 630.71590 286.03834 411.88352 233.56349\nKunhing    173.50424 318.23811 449.67218 141.58836 375.82140 197.63683\nMongyawng  214.21738 332.92193 570.56521 235.55497 193.49994 173.43078\nTangyan    195.92520 208.43740 324.77002 169.50567 448.59948 348.06617\nNamhsan    237.78494 228.41073 286.16305 214.33352 488.33873 385.88676\n               Pekon  Lawksawk Nawnghkio   Kyaukme      Muse    Laihka\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk   157.51129                                                  \nNawnghkio  113.15370  90.82891                                        \nKyaukme    202.12206 186.29066 157.04230                              \nMuse       614.56144 510.13288 533.68806 434.75768                    \nLaihka     182.23667 246.74469 211.88187 128.24979 526.65211          \nMongnai    151.60031 241.71260 182.21245 142.45669 571.97975 100.53457\nMawkmai    416.00669 567.52693 495.15047 512.02846 926.93007 429.96554\nKutkai     114.98048 224.64646 147.44053 170.93318 592.90743 144.67198\nMongton    208.14888 311.07742 225.81118 229.28509 634.71074 212.07320\nMongyai    242.52301 391.26989 319.57938 339.27780 763.91399 264.13364\nMongkaing  480.23965 625.18712 546.69447 586.05094 995.66496 522.96309\nLashio     303.80011 220.75270 230.55346 129.95255 313.15288 238.64533\nMongpan    243.30037 228.54223 172.84425 110.37831 447.49969 210.76951\nMatman     368.25761 515.39711 444.05061 505.52285 929.11283 443.25453\nTachileik  573.39528 441.82621 470.45533 429.15493 221.19950 549.08985\nNarphan    416.84901 523.69580 435.59661 420.30003 770.40234 392.32592\nMongkhet   342.08722 487.41102 414.10280 409.03553 816.44931 324.97428\nHsipaw     145.37542 249.35081 176.09570 163.95741 591.03355 128.42987\nMonghsat   225.64279 352.31496 289.83220 253.25370 663.76026 158.93517\nMongmao    293.70625 314.64777 257.76465 146.09228 451.82530 185.99082\nNansang    160.37607 188.78869 151.13185  60.32773 489.35308  78.78999\nLaukkaing  624.82399 548.83928 552.65554 428.74978 149.26996 507.39700\nPangsang   321.81214 345.91486 287.10769 175.35273 460.24292 214.19291\nNamtu      165.02707 260.95300 257.52713 270.87277 659.16927 185.86794\nMonghpyak  190.93173 142.31691  93.03711 217.64419 539.43485 293.22640\nKonkyan    421.48797 520.31264 439.34272 393.79911 704.86973 351.75354\nMongping   259.68288 396.47081 316.14719 330.28984 744.44948 272.82761\nHopong     138.86577 274.91604 204.88286 218.84211 648.68011 157.48857\nNyaungshwe 139.31874 104.17830  43.26545 126.50414 505.88581 201.71653\nHsihseng   105.30573 257.11202 209.88026 250.27059 677.66886 175.89761\nMongla     441.20998 393.18472 381.40808 241.58966 256.80556 315.93218\nHseni      243.98001 171.50398 164.05304  81.20593 381.30567 204.49010\nKunlong    249.36301 318.30406 285.04608 215.63037 547.24297 122.68682\nHopang     336.38582 321.16462 279.84188 154.91633 377.44407 230.78652\nNamhkan    442.77120 379.41126 367.33575 247.81990 238.67060 342.43665\nKengtung   297.67761 209.38215 208.29647 136.23356 330.08211 258.23950\nLangkho    219.21623 190.30257 156.51662  51.67279 413.64173 160.94435\nMonghsu    113.84636 242.04063 170.09168 200.77712 633.21624 163.28926\nTaunggyi   440.66133 304.96838 344.79200 312.60547 250.81471 425.36916\nPangwaun   423.81347 453.02765 381.67478 308.31407 541.97887 351.78203\nKyethi     162.43575 317.74604 267.21607 328.14177 757.16745 255.83275\nLoilen     181.94596 265.29318 219.26405 146.92675 560.43400  59.69478\nManton     403.82131 551.13000 475.77296 522.86003 941.49778 458.30232\nMongyang   363.58788 363.37684 323.32123 188.59489 389.59919 229.71502\nKunhing    213.46379 278.68953 206.15773 145.00266 533.00162 142.03682\nMongyawng  248.43910 179.07229 220.61209 181.55295 422.37358 211.99976\nTangyan    167.79937 323.14701 269.07880 306.78359 736.93741 224.29176\nNamhsan    207.16559 362.84062 299.74967 347.85944 778.52971 273.79672\n             Mongnai   Mawkmai    Kutkai   Mongton   Mongyai Mongkaing\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai    374.50873                                                  \nKutkai      91.15307 364.95519                                        \nMongton    131.67061 313.35220 107.06341                              \nMongyai    203.23607 178.70499 188.94166 159.79790                    \nMongkaing  456.00842 133.29995 428.96133 365.50032 262.84016          \nLashio     270.86983 638.60773 289.82513 347.11584 466.36472 708.65819\nMongpan    178.09554 509.99632 185.18173 200.31803 346.39710 563.56780\nMatman     376.33870 147.83545 340.86349 303.04574 186.95158 135.51424\nTachileik  563.95232 919.38755 568.99109 608.76740 750.29555 967.14087\nNarphan    329.31700 273.75350 314.27683 215.97925 248.82845 285.65085\nMongkhet   275.76855 115.58388 273.91673 223.22828 104.98924 222.60577\nHsipaw      52.68195 351.34601  51.46282  90.69766 177.33790 423.77868\nMonghsat   125.25968 275.09705 154.32012 150.98053 127.35225 375.60376\nMongmao    188.29603 485.52853 204.69232 206.57001 335.61300 552.31959\nNansang     92.79567 462.41938 130.04549 199.58124 288.55962 542.16609\nLaukkaing  551.56800 882.51110 580.38112 604.66190 732.68347 954.11795\nPangsang   204.25746 484.14757 228.33583 210.77938 343.30638 548.40662\nNamtu      209.35473 427.95451 225.28268 308.71751 278.02761 525.04057\nMonghpyak  253.26470 536.71695 206.61627 258.04282 370.01575 568.21089\nKonkyan    328.82831 339.01411 310.60810 248.25265 287.87384 380.92091\nMongping   202.99615 194.31049 182.75266 119.86993  65.38727 257.18572\nHopong      91.53795 302.84362  73.45899 106.21031 124.62791 379.37916\nNyaungshwe 169.63695 502.99026 152.15482 219.72196 327.13541 557.32112\nHsihseng   142.36728 329.29477 128.21054 194.64317 162.27126 411.59788\nMongla     354.10985 686.88950 388.40984 411.06668 535.28615 761.48327\nHseni      216.81639 582.53670 229.37894 286.75945 408.23212 648.04408\nKunlong    202.92529 446.53763 204.54010 270.02165 299.36066 539.91284\nHopang     243.00945 561.24281 263.31986 273.50305 408.73288 626.17673\nNamhkan    370.05669 706.47792 392.48568 414.53594 550.62819 771.39688\nKengtung   272.28711 632.54638 279.19573 329.38387 460.39706 692.74693\nLangkho    174.67678 531.08019 180.51419 236.70878 358.95672 597.42714\nMonghsu     84.11238 332.07962  62.60859 107.04894 154.86049 400.71816\nTaunggyi   448.55282 810.74692 450.33382 508.40925 635.94105 866.21117\nPangwaun   312.13429 500.68857 321.80465 257.50434 394.07696 536.95736\nKyethi     210.50453 278.85535 184.23422 222.52947 137.79420 352.06533\nLoilen      58.41263 388.73386 131.56529 176.16001 224.79239 482.18190\nManton     391.54062 109.08779 361.82684 310.20581 195.59882  81.75337\nMongyang   260.39387 558.83162 285.33223 295.60023 414.31237 631.91325\nKunhing    110.55197 398.43973 108.84990 114.03609 238.99570 465.03971\nMongyawng  275.77546 620.04321 281.03383 375.22688 445.78964 700.98284\nTangyan    180.37471 262.66006 166.61820 198.88460 109.08506 348.56123\nNamhsan    218.10003 215.19289 191.32762 196.76188  77.35900 288.66231\n              Lashio   Mongpan    Matman Tachileik   Narphan  Mongkhet\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan    172.33279                                                  \nMatman     628.11049 494.81014                                        \nTachileik  311.95286 411.03849 890.12935                              \nNarphan    525.63854 371.13393 312.05193 760.29566                    \nMongkhet   534.44463 412.17123 203.02855 820.50164 217.28718          \nHsipaw     290.86435 179.52054 344.45451 576.18780 295.40170 253.80950\nMonghsat   377.86793 283.30992 313.59911 677.09508 278.21548 167.98445\nMongmao    214.23677 131.59966 501.59903 472.95568 331.42618 375.35820\nNansang    184.47950 144.77393 458.06573 486.77266 398.13308 360.99219\nLaukkaing  334.65738 435.58047 903.72094 325.06329 708.82887 769.06406\nPangsang   236.72516 140.23910 506.29940 481.31907 316.30314 375.58139\nNamtu      365.88437 352.91394 416.65397 659.56458 494.36143 355.99713\nMonghpyak  262.09281 187.85699 470.46845 444.04411 448.40651 462.63265\nKonkyan    485.51312 365.87588 392.40306 730.92980 158.82353 254.24424\nMongping   454.52548 318.47482 201.65224 727.08969 188.64567 113.80917\nHopong     345.31042 239.43845 291.84351 632.45718 294.40441 212.99485\nNyaungshwe 201.58191 137.29734 460.91883 445.81335 427.94086 417.08639\nHsihseng   369.00833 295.87811 304.02806 658.87060 377.52977 256.70338\nMongla     179.95877 253.20001 708.17595 347.33155 531.46949 574.40292\nHseni       79.41836 120.66550 564.64051 354.90063 474.12297 481.88406\nKunlong    295.23103 288.03320 468.27436 595.70536 413.07823 341.68641\nHopang     170.63913 135.62913 573.55355 403.82035 397.85908 451.51070\nNamhkan    173.27153 240.34131 715.42102 295.91660 536.85519 596.19944\nKengtung    59.85893 142.21554 613.01033 295.90429 505.40025 531.35998\nLangkho    115.18145  94.98486 518.86151 402.33622 420.65204 428.08061\nMonghsu    325.71557 216.25326 308.13805 605.02113 311.92379 247.73318\nTaunggyi   195.14541 319.81385 778.45810 150.84117 684.20905 712.80752\nPangwaun   362.45608 232.52209 523.43600 540.60474 264.64997 407.02947\nKyethi     447.10266 358.89620 233.83079 728.87329 374.90376 233.25039\nLoilen     268.92310 207.25000 406.56282 573.75476 354.79137 284.76895\nManton     646.66493 507.96808  59.52318 910.23039 280.26395 181.33894\nMongyang   209.33700 194.93467 585.61776 448.79027 401.39475 445.40621\nKunhing    255.10832 137.85278 403.66587 532.26397 281.62645 292.49814\nMongyawng  172.70139 275.15989 601.80824 432.10118 572.76394 522.91815\nTangyan    429.84475 340.39128 242.78233 719.84066 348.84991 201.49393\nNamhsan    472.04024 364.77086 180.09747 754.03913 316.54695 170.90848\n              Hsipaw  Monghsat   Mongmao   Nansang Laukkaing  Pangsang\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat   121.78922                                                  \nMongmao    185.99483 247.17708                                        \nNansang    120.24428 201.92690 164.99494                              \nLaukkaing  569.06099 626.44910 404.00848 480.60074                    \nPangsang   205.04337 256.37933  57.60801 193.36162 408.04016          \nNamtu      229.44658 231.78673 365.03882 217.61884 664.06286 392.97391\nMonghpyak  237.67919 356.84917 291.88846 227.52638 565.84279 315.11651\nKonkyan    296.74316 268.25060 281.87425 374.70456 635.92043 274.81900\nMongping   168.92101 140.95392 305.57166 287.36626 708.13447 308.33123\nHopong      62.86179 100.45714 244.16253 167.66291 628.48557 261.51075\nNyaungshwe 169.92664 286.37238 230.45003 131.18943 520.24345 257.77823\nHsihseng   136.54610 153.49551 311.98001 193.53779 670.74564 335.52974\nMongla     373.47509 429.00536 216.24705 289.45119 202.55831 217.88123\nHseni      231.48538 331.22632 184.67099 136.45492 391.74585 214.66375\nKunlong    205.10051 202.31862 224.43391 183.01388 521.88657 258.49342\nHopang     248.72536 317.64824  78.29342 196.47091 331.67199  92.57672\nNamhkan    382.79302 455.10875 223.32205 302.89487 196.46063 231.38484\nKengtung   284.08582 383.72138 207.58055 193.67980 351.48520 229.85484\nLangkho    183.05109 279.52329 134.50170  99.39859 410.41270 167.65920\nMonghsu     58.55724 137.24737 242.43599 153.59962 619.01766 260.52971\nTaunggyi   462.31183 562.88102 387.33906 365.04897 345.98041 405.59730\nPangwaun   298.12447 343.53898 187.40057 326.12960 470.63605 157.48757\nKyethi     195.17677 190.50609 377.89657 273.02385 749.99415 396.89963\nLoilen      98.04789 118.65144 190.26490  94.23028 535.57527 207.94433\nManton     359.60008 317.15603 503.79786 476.55544 907.38406 504.75214\nMongyang   267.10497 312.64797  91.06281 218.49285 326.19219 108.37735\nKunhing     90.77517 165.38834 103.91040 128.20940 500.41640 123.18870\nMongyawng  294.70967 364.40429 296.40789 191.11990 454.80044 336.16703\nTangyan    167.69794 144.59626 347.14183 249.70235 722.40954 364.76893\nNamhsan    194.47928 169.56962 371.71448 294.16284 760.45960 385.65526\n               Namtu Monghpyak   Konkyan  Mongping    Hopong Nyaungshwe\nPindaya                                                                \nYwangan                                                                \nPinlaung                                                               \nMabein                                                                 \nKalaw                                                                  \nPekon                                                                  \nLawksawk                                                               \nNawnghkio                                                              \nKyaukme                                                                \nMuse                                                                   \nLaihka                                                                 \nMongnai                                                                \nMawkmai                                                                \nKutkai                                                                 \nMongton                                                                \nMongyai                                                                \nMongkaing                                                              \nLashio                                                                 \nMongpan                                                                \nMatman                                                                 \nTachileik                                                              \nNarphan                                                                \nMongkhet                                                               \nHsipaw                                                                 \nMonghsat                                                               \nMongmao                                                                \nNansang                                                                \nLaukkaing                                                              \nPangsang                                                               \nNamtu                                                                  \nMonghpyak  346.57799                                                   \nKonkyan    478.37690 463.39594                                         \nMongping   321.66441 354.76537 242.02901                               \nHopong     206.82668 267.95563 304.49287 134.00139                     \nNyaungshwe 271.41464 103.97300 432.35040 319.32583 209.32532           \nHsihseng   131.89940 285.37627 383.49700 199.64389  91.65458  225.80242\nMongla     483.49434 408.03397 468.09747 512.61580 432.31105  347.60273\nHseni      327.41448 200.26876 448.84563 395.58453 286.41193  130.86310\nKunlong    233.60474 357.44661 329.11433 309.05385 219.06817  285.13095\nHopang     408.24516 304.26577 348.18522 379.27212 309.77356  247.19891\nNamhkan    506.32466 379.50202 481.59596 523.74815 444.13246  333.32428\nKengtung   385.33554 221.47613 474.82621 442.80821 340.47382  177.75714\nLangkho    305.03473 200.27496 386.95022 343.96455 239.63685  128.26577\nMonghsu    209.64684 232.17823 331.72187 158.90478  43.40665  173.82799\nTaunggyi   518.72748 334.17439 650.56905 621.53039 513.76415  325.09619\nPangwaun   517.03554 381.95144 263.97576 340.37881 346.00673  352.92324\nKyethi     186.90932 328.16234 400.10989 187.43974 136.49038  288.06872\nLoilen     194.24075 296.99681 334.19820 231.99959 124.74445  206.40432\nManton     448.58230 502.20840 366.66876 200.48082 310.58885  488.79874\nMongyang   413.26052 358.17599 329.39338 387.80686 323.35704  294.29500\nKunhing    296.43996 250.74435 253.74202 212.59619 145.15617  189.97131\nMongyawng  262.24331 285.56475 522.38580 455.59190 326.59925  218.12104\nTangyan    178.69483 335.26416 367.46064 161.67411 106.82328  284.14692\nNamhsan    240.95555 352.70492 352.20115 130.23777 132.70541  315.91750\n            Hsihseng    Mongla     Hseni   Kunlong    Hopang   Namhkan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla     478.66210                                                  \nHseni      312.74375 226.82048                                        \nKunlong    231.85967 346.46200 276.19175                              \nHopang     370.01334 147.02444 162.80878 271.34451                    \nNamhkan    492.09476  77.21355 212.11323 375.73885 146.18632          \nKengtung   370.72441 202.45004  66.12817 317.14187 164.29921 175.63015\nLangkho    276.27441 229.01675  66.66133 224.52741 134.24847 224.40029\nMonghsu     97.82470 424.51868 262.28462 239.89665 301.84458 431.32637\nTaunggyi   528.14240 297.09863 238.19389 471.29032 329.95252 257.29147\nPangwaun   433.06326 319.18643 330.70182 392.45403 206.98364 310.44067\nKyethi      84.04049 556.02500 388.33498 298.55859 440.48114 567.86202\nLoilen     158.84853 338.67408 227.10984 166.53599 242.89326 364.90647\nManton     334.87758 712.51416 584.63341 479.76855 577.52046 721.86149\nMongyang   382.59743 146.66661 210.19929 247.22785  69.25859 167.72448\nKunhing    220.15490 306.47566 206.47448 193.77551 172.96164 314.92119\nMongyawng  309.51462 315.57550 173.86004 240.39800 290.51360 321.21112\nTangyan     70.27241 526.80849 373.07575 268.07983 412.22167 542.64078\nNamhsan    125.74240 564.02740 411.96125 310.40560 440.51555 576.42717\n            Kengtung   Langkho   Monghsu  Taunggyi  Pangwaun    Kyethi\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho    107.16213                                                  \nMonghsu    316.91914 221.84918                                        \nTaunggyi   186.28225 288.27478 486.91951                              \nPangwaun   337.48335 295.38434 343.38498 497.61245                    \nKyethi     444.26274 350.91512 146.61572 599.57407 476.62610          \nLoilen     282.22935 184.10672 131.55208 455.91617 331.69981 232.32965\nManton     631.99123 535.95620 330.76503 803.08034 510.79265 272.03299\nMongyang   217.08047 175.35413 323.95988 374.58247 225.25026 453.86726\nKunhing    245.95083 146.38284 146.78891 429.98509 229.09986 278.95182\nMongyawng  203.87199 186.11584 312.85089 287.73864 475.33116 387.71518\nTangyan    429.95076 332.02048 127.42203 592.65262 447.05580  47.79331\nNamhsan    466.20497 368.20978 153.22576 631.49232 448.58030  68.67929\n              Loilen    Manton  Mongyang   Kunhing Mongyawng   Tangyan\nPindaya                                                               \nYwangan                                                               \nPinlaung                                                              \nMabein                                                                \nKalaw                                                                 \nPekon                                                                 \nLawksawk                                                              \nNawnghkio                                                             \nKyaukme                                                               \nMuse                                                                  \nLaihka                                                                \nMongnai                                                               \nMawkmai                                                               \nKutkai                                                                \nMongton                                                               \nMongyai                                                               \nMongkaing                                                             \nLashio                                                                \nMongpan                                                               \nMatman                                                                \nTachileik                                                             \nNarphan                                                               \nMongkhet                                                              \nHsipaw                                                                \nMonghsat                                                              \nMongmao                                                               \nNansang                                                               \nLaukkaing                                                             \nPangsang                                                              \nNamtu                                                                 \nMonghpyak                                                             \nKonkyan                                                               \nMongping                                                              \nHopong                                                                \nNyaungshwe                                                            \nHsihseng                                                              \nMongla                                                                \nHseni                                                                 \nKunlong                                                               \nHopang                                                                \nNamhkan                                                               \nKengtung                                                              \nLangkho                                                               \nMonghsu                                                               \nTaunggyi                                                              \nPangwaun                                                              \nKyethi                                                                \nLoilen                                                                \nManton     419.06087                                                  \nMongyang   246.76592 585.70558                                        \nKunhing    130.39336 410.49230 188.89405                              \nMongyawng  261.75211 629.43339 304.21734 295.35984                    \nTangyan    196.60826 271.82672 421.06366 249.74161 377.52279          \nNamhsan    242.15271 210.48485 450.97869 270.79121 430.02019  63.67613"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-hierarchical-clustering",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.5 Compute hierarchical clustering",
    "text": "6.5 Compute hierarchical clustering\nIn R, several packages offer hierarchical clustering functions. For this exercise, we will use hclust() from the R stats package.\nhclust() uses an agglomeration method to compute clusters and supports eight algorithms: ward.D, ward.D2, single, complete, average (UPGMA), mcquitty (WPGMA), median (WPGMC), and centroid (UPGMC).\nThe code below performs hierarchical cluster analysis using the ward.D method. The output is stored in an hclust object, which describes the clustering tree.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#select-the-optimal-clustering-algorithm",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#select-the-optimal-clustering-algorithm",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.6 Select the optimal clustering algorithm",
    "text": "6.6 Select the optimal clustering algorithm\nOne challenge in hierarchical clustering is identifying strong clustering structures. This can be addressed using the agnes() function from the cluster package. It functions similar to hclust(), but agnes() also provides the agglomerative coefficient, which measures the strength of the clustering structure (values closer to 1 indicate a stronger structure).\nThe code below computes the agglomerative coefficients for all hierarchical clustering algorithms:\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, for the subsequent analysis, only Ward’s method will be used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#determine-optimal-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#determine-optimal-clusters",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.7 Determine Optimal Clusters",
    "text": "6.7 Determine Optimal Clusters\nAnother challenge in clustering analysis is determining the optimal number of clusters to retain.\nThree commonly used methods to determine the number of clusters are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n6.7.1 Gap Statistic Method\nThe gap statistic compares the total within-cluster variation for different values of ( k ) with their expected values under a null reference distribution. The optimal number of clusters is the value that maximizes the gap statistic, indicating a clustering structure far from a random uniform distribution.\nTo compute the gap statistic, use the clusGap() function from the cluster package.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nThe gap statistic graph suggests retaining one cluster, which is not logical. By examining the graph, the 6-cluster solution provides the largest gap statistic and is the next best choice.\nNote: Apart from these commonly used approaches, The NbClust package (Charrad et al., 2014) offers 30 indices for determining the optimal number of clusters and recommends the best clustering scheme by varying combinations of cluster numbers, distance measures, and clustering methods."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#interpret-the-dendrograms",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#interpret-the-dendrograms",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.8 Interpret the dendrograms",
    "text": "6.8 Interpret the dendrograms\nIn the dendrogram, each leaf represents an observation. As you move up the tree, similar observations merge into branches, which then fuse at higher levels.\nThe vertical axis shows the height of the fusion, indicating the (dis)similarity between observations. Higher fusion heights mean less similarity. Note that the proximity of two observations can only be inferred from the height at which their branches first merge, not their horizontal distance.\nYou can also highlight selected clusters in the dendrogram using the rect.hclust() function from R stats, specifying border colors with the border argument.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visually-driven-hierarchical-clustering-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visually-driven-hierarchical-clustering-analysis",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.9 Visually-driven hierarchical clustering analysis",
    "text": "6.9 Visually-driven hierarchical clustering analysis\nIn this section, we explore how to perform visually-driven hiearchical clustering analysis using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n6.9.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to plot a heatmap.\nThe code chunk below is used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n6.9.2 Plot interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply()of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#map-the-clusters-formed",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#map-the-clusters-formed",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "6.10 Map the clusters formed",
    "text": "6.10 Map the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#convert-into-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#convert-into-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.1 Convert into SpatialPolygonsDataFrame",
    "text": "7.1 Convert into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into a SpatialPolygonsDataFrame because the SKATER function only supports sp objects like SpatialPolygonsDataFrame.\nThe code below uses as_Spatial() from the sf package to convert shan_sf into a SpatialPolygonsDataFrame called shan_sp:\n\nshan_sp &lt;- as_Spatial(shan_sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-neighbour-list",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-neighbour-list",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.2 Compute Neighbour List",
    "text": "7.2 Compute Neighbour List\nNext, poly2nd() of spdep package is used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nTo plot the neighbors list on shan_sp, we can overlay the community area boundaries on the map. The first plot command draws the boundaries, followed by plotting the neighbor list object. Coordinates from the original SpatialPolygonDataFrame (Shan state township boundaries) are used to extract the centroids of the polygons, serving as the nodes for the graph. We set the color to blue and use add=TRUE to overlay the network on the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\nNote: If you plot the network first and then the boundaries, some areas may be clipped because the plotting area is determined by the first plot. Since the boundary map extends further than the graph, we plot it first."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-minimum-spanning-tree",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-minimum-spanning-tree",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.3 Compute Minimum Spanning Tree",
    "text": "7.3 Compute Minimum Spanning Tree\n\n7.3.1 Calculate Edge Costs\nNext, use the nbcosts() function from spdep package to compute the cost of each edge, which is the distance between its nodes. This function calculates the distance using a data frame with observation vectors for each node.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighboring observation (from the neighbor list). This is essentially a generalized weight for a spatial weights matrix.\nNext, incorporate these costs into a weights object, similar to how we calculated the inverse of distance weights. Convert the neighbor list to a list weights object by specifying the computed lcosts as the weights.\nUse the nb2listw() function from the spdep package as shown below, specifying the style as “B” to ensure the cost values are not row-standardized.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-minimum-spanning-tree-1",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-minimum-spanning-tree-1",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.4 Compute minimum spanning tree",
    "text": "7.4 Compute minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\n\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote: the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]   54   48  47.79331\n[2,]   54   17 109.08506\n[3,]   54   45 127.42203\n[4,]   45   52 146.78891\n[5,]   52   13 110.55197\n[6,]   13   28  92.79567\n\n\nThe plot method for the Minimum Spanning Tree (MST) can display the observation numbers of the nodes along with the edges. As before, we will plot this together with the township boundaries. This allows us to see how the initial neighbor list is simplified to a single edge connecting each node, while still passing through all nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-spatially-constrained-clusters-using-skater-method",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#compute-spatially-constrained-clusters-using-skater-method",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.5 Compute spatially constrained clusters using SKATER method",
    "text": "7.5 Compute spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater()of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() function requires three mandatory arguments:\n\nThe first two columns of the MST matrix (excluding the cost),\nThe data matrix (to update the costs as units are grouped),\nThe number of cuts (one less than the number of clusters).\n\nThe result of skater() is an object of class skater. You can examine its contents using the following code.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 3 3 6 3 3 3 3 3 3 3 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 2 6 8 1 36 4 10 9 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 8 36 4 6 8 10 10 9 ...\n  .. ..$ ssw : num 1458\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting part of this list structure is the groups vector, which contains the cluster labels for each observation (the labels themselves are arbitrary). This is followed by a detailed summary for each cluster in the edges.groups list. Sum of squares measures are provided as ssto for the total and ssw to show the effect of each cut on the overall criterion.\nWe can check the cluster assignment using the code chunk below:\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 3 3 6 3 3 3 3 3 3 3 2 1 1 1 2 1 1 1 2 4 1 2 5 1 1 1 2 1 2 2 1 2 2 1 1 3 1 2\n[39] 2 2 2 2 2 4 1 3 2 1 1 1 2 1 2 1 1\n\n\nTo find out how many observations are in each cluster, use the table command. Alternatively, you can check the dimensions of each vector in the edges.groups list. For example, the first list has a node with a dimension of 12, which is the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n22 18 11  2  1  1 \n\n\nLastly, we can plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-the-clusters-in-choropleth-map",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-the-clusters-in-choropleth-map",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "7.6 Visualize the clusters in choropleth map",
    "text": "7.6 Visualize the clusters in choropleth map\nThe code chunk below plots the newly derived clusters using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nWe can plot both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other for easier comparison.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)\n\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them).\nWarning: One tm layer group has duplicated layer types, which are omitted. To\ndraw multiple layers of the same type, use multiple layer groups (i.e. specify\ntm_shape prior to each of them)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#about-the-clustgeo-package",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#about-the-clustgeo-package",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.1 About the ClustGeo Package",
    "text": "8.1 About the ClustGeo Package\nThe ClustGeo package is designed for spatially constrained cluster analysis. It provides a Ward-like hierarchical clustering algorithm called hclustgeo(), which includes spatial/geographical constraints.\nThe algorithm uses two dissimilarity matrices, ( D_0 ) and ( D_1 ), along with a mixing parameter ( \\alpha ) (a real number between 0 and 1). ( D_0 ) can be non-Euclidean, and the weights of the observations can be non-uniform, representing dissimilarities in the attribute/clustering variable space. ( D_1 ) represents dissimilarities in the constraint space. The criterion minimized at each stage is a combination of the homogeneity criteria calculated with ( D_0 ) and ( D_1 ).\nThe goal is to find an ( \\alpha ) value that increases spatial contiguity without significantly deteriorating the quality of the solution based on the variables of interest. The choicealpha() function helps determine this value."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#ward-like-hierarchical-clustering-with-clustgeo",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#ward-like-hierarchical-clustering-with-clustgeo",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.2 Ward-like Hierarchical Clustering with ClustGeo",
    "text": "8.2 Ward-like Hierarchical Clustering with ClustGeo\nThe ClustGeo package’s hclustgeo() function performs Ward-like hierarchical clustering similar to hclust().\nTo perform non-spatially constrained hierarchical clustering, provide the function with a dissimilarity matrix as shown below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, obtained using the dist() function. For a sample code chunk, refer to section 5.7.6 on computing the proximity matrix.\n\n8.2.1 Map the Clusters Formed\nSimilarly, we can plot the clusters on a categorical area shaded map using the steps learned in section 5.7.12 on mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#spatially-constrained-hierarchical-clustering",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#spatially-constrained-hierarchical-clustering",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "8.3 Spatially Constrained Hierarchical Clustering",
    "text": "8.3 Spatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix needs to be derived using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNote: as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the above graphs above, alpha = 0.3 will be used in the next step as shown below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.3)\n\nNext, cutree() is used to derive the cluster object.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe join back the group list with shan_sf polygon feature data frame using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-individual-clustering-variable",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#visualize-individual-clustering-variable",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.1 Visualize individual clustering variable",
    "text": "9.1 Visualize individual clustering variable\nThe code chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 has the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#multivariate-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex061.html#multivariate-visualisation",
    "title": "Hands-on Exercise 6.1: Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.2 Multivariate Visualisation",
    "text": "9.2 Multivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package is used.\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot shows that households in Cluster 4 townships have the highest ownership of TVs and mobile phones, while those in Cluster 5 have the lowest ownership of all five ICTs.\nThe scale argument in ggparcoord() offers several methods to scale clustering variables:\n\nstd: Subtract mean and divide by standard deviation.\nrobust: Subtract median and divide by median absolute deviation.\nuniminmax: Scale so the minimum is zero and the maximum is one.\nglobalminmax: No scaling; the range is defined by the global minimum and maximum.\ncenter: Standardize vertical height using uniminmax, then center each variable at a specified value.\ncenterObs: Standardize vertical height using uniminmax, then center each variable at the value of a specified observation.\n\nThere is no single best scaling method; choose the one that best suits your analysis needs.\nAdditionally, you can compute summary statistics (mean, median, standard deviation, etc.) to complement the visual interpretation.\nThe code below uses group_by() and summarise() from dplyr to derive mean values of the clustering variables:\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "",
    "text": "Emerging Hot Spot Analysis (EHSA) is a spatial-temporal analysis method to reveal and describe how hot spot and cold spot areas evolve over time. The analysis consist of 4 main steps:\n\nBuild a space-time cube\nCalculate Getis-Ord local Gi* statistics for each bin using and FDR correction\nEvaluate these hot and cold spot trends using Mann-Kendall trend test\nCategorize each study area location by referring to the result trend z-score and hot spot z-score and p-value for each bin."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#install-and-load-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#install-and-load-r-packages",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "2.1 Install and Load R packages",
    "text": "2.1 Install and Load R packages\np_load() of pacman package is used to install the necessary R packages.\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)\n\nNext we set the seed to ensure reproducibility of the result.\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#the-data",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "2.2 The Data",
    "text": "2.2 The Data\nThe code chunk below use st_read() of sf package to import Hunan shapefile into R\n\nhunan = st_read(dsn = \"data/geospatial\",\n                layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\nThe attribute table is loaded in using read_csv().\n\nGDPPC = read_csv(\"data/aspatial/Hunan_GDPPC.csv\")\n\nRows: 1496 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): County\ndbl (2): Year, GDPPC\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#derive-the-spatial-weights",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#derive-the-spatial-weights",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "4.1 Derive the spatial weights",
    "text": "4.1 Derive the spatial weights\nThe code chunk below is used to identify neighbors and derive an inverse distance weights.\n\nGDPPC_nb = GDPPC_st |&gt;\n  activate(\"geometry\") |&gt;\n  mutate(nb = include_self(\n    st_contiguity(geometry)),\n    wt = st_inverse_distance(nb,\n                              geometry,\n                              scale = 1,\n                              alpha = 1),\n                             .before = 1) |&gt;\n      set_nbs(\"nb\") |&gt;\n      set_wts(\"wt\")\n\n! Polygon provided. Using point on surface.\n\n\nWarning: There was 1 warning in `stopifnot()`.\nℹ In argument: `wt = st_inverse_distance(nb, geometry, scale = 1, alpha = 1)`.\nCaused by warning in `st_point_on_surface.sfc()`:\n! st_point_on_surface may not give correct results for longitude/latitude data\n\n\nIn the above code chunk: The activate() function from the dplyr package is used to switch to the geometry context, while mutate() creates two new columns, nb and wt. Afterward, the data context is reactivated, and the nb and wt columns are copied to each time slice using set_nbs() and set_wts(). It’s important not to change the row order after using these functions.\nNote that this dataset now has neighbors and weights for each time-slice."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#compute-gi-1",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#compute-gi-1",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "4.2 Compute Gi*",
    "text": "4.2 Compute Gi*\nWe use these new columns to manually calculate the local Gi* for each location. This is done using group_by Year and local_gstar_perm() of sfdep package. Afterwards, unnest() is used to unnest gi_star column of the newly created gi_stars data.frame.\n\ngi_stars = GDPPC_nb |&gt;\n  group_by(Year) |&gt;\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt)) |&gt;\n  tidyr::unnest(gi_star)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#interactive-mann-kendall-plot",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#interactive-mann-kendall-plot",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "5.1 Interactive Mann-Kendall plot",
    "text": "5.1 Interactive Mann-Kendall plot\nNext we plot the result using ggplot2 functions.\n\nggplot(data = cbg,\n       aes(x = Year,\n           y = gi_star)) +\n  geom_line() +\n  theme_light()\n\n\n\n\n\n\n\n\nWe can also create an interactive plot using ggplotly() of plotly package.\n\np = ggplot(data = cbg,\n           aes(x = Year,\n               y = gi_star)) +\n  geom_line() +\n  theme_light()\n\nggplotly(p)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#print-mann-kendall-test-report",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#print-mann-kendall-test-report",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "5.2 Print Mann-Kendall test report",
    "text": "5.2 Print Mann-Kendall test report\n\ncbg |&gt;\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) |&gt;\n  tidyr::unnest_wider(mk)\n\n# A tibble: 1 × 5\n    tau      sl     S     D  varS\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 0.485 0.00742    66  136.  589.\n\n\nIn the above output, sl is the p-value. As the p-value is smaller than 0.05, we reject the null hypothesis and infer that a slight upward trend is present."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test-data.frame",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#mann-kendall-test-data.frame",
    "title": "In-class Exercise 6: Emerging Hot Spot Analysis (EHSA)",
    "section": "5.3 Mann-Kendall test data.frame",
    "text": "5.3 Mann-Kendall test data.frame\nWe can replicate this for each location using group_by() of dplyr package.\n\nehsa = gi_stars |&gt;\n  group_by(County) |&gt;\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) |&gt;\n  tidyr::unnest_wider(mk)\nhead(ehsa)\n\n# A tibble: 6 × 6\n  County        tau        sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Anhua      0.191  0.303        26  136.  589.\n2 Anren     -0.294  0.108       -40  136.  589.\n3 Anxiang    0      1             0  136.  589.\n4 Baojing   -0.691  0.000128    -94  136.  589.\n5 Chaling   -0.0882 0.650       -12  136.  589.\n6 Changning -0.750  0.0000318  -102  136.  589.\n\n\nWe can also sort to show significant emerging hot/cold spots.\n\nemerging &lt;- ehsa %&gt;% \n  arrange(sl, abs(tau)) %&gt;% \n  slice(1:10)\nhead(emerging)\n\n# A tibble: 6 × 6\n  County        tau         sl     S     D  varS\n  &lt;chr&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Shuangfeng  0.868 0.00000143   118  136.  589.\n2 Xiangtan    0.868 0.00000143   118  136.  589.\n3 Xiangxiang  0.868 0.00000143   118  136.  589.\n4 Chengbu    -0.824 0.00000482  -112  136.  589.\n5 Dongan     -0.824 0.00000482  -112  136.  589.\n6 Wugang     -0.809 0.00000712  -110  136.  589."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Tourism is one of Thailand’s largest industries, contributing to around 20% to the gross domestic product (GDP). In 2019, it generated 90 billion USD, but due to COVID-19, this revenue has dropped to 24 billion in 2020.\nUsing the statistics obtained from The Official Ministry of Tourism and Sports Statistics of Thailand, we can see that the tourism revenue has gradually recovery since September 2021. It is notable that the tourism economy in Thailand is largely concentrated in certain provinces.\n\n\n\nThis analysis aims to deliver 2 objectives:\n\nExamine if the key indicators of Thailand’s tourism economy are independent from space and space and time using appropriate statistical testing.\nIf the key indicators are spatial and spatio-temporal dependent, then detection of clusters and outliers, and emerging hot spots/cold spots will be carried out to further understand the association.\n\n\n\n\n2 datasets will be used for the purpose of this analysis:\n\nThailand Domestic Tourism Statistics at Kaggle. We will use the updated version 2 of the data set.\nThailand - Subnational Administrative Boundaries at HDX. The boundary dataset at province level (level 1) will be used."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#setting-the-scene",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "Tourism is one of Thailand’s largest industries, contributing to around 20% to the gross domestic product (GDP). In 2019, it generated 90 billion USD, but due to COVID-19, this revenue has dropped to 24 billion in 2020.\nUsing the statistics obtained from The Official Ministry of Tourism and Sports Statistics of Thailand, we can see that the tourism revenue has gradually recovery since September 2021. It is notable that the tourism economy in Thailand is largely concentrated in certain provinces."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#objectives",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "This analysis aims to deliver 2 objectives:\n\nExamine if the key indicators of Thailand’s tourism economy are independent from space and space and time using appropriate statistical testing.\nIf the key indicators are spatial and spatio-temporal dependent, then detection of clusters and outliers, and emerging hot spots/cold spots will be carried out to further understand the association."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#the-data",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "",
    "text": "2 datasets will be used for the purpose of this analysis:\n\nThailand Domestic Tourism Statistics at Kaggle. We will use the updated version 2 of the data set.\nThailand - Subnational Administrative Boundaries at HDX. The boundary dataset at province level (level 1) will be used."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-r-packages",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "2.1 Import R packages",
    "text": "2.1 Import R packages\nThe below code chunk uses p_load() of pacman package to install and load relevant packages into R environment.\n\npacman::p_load(sf, sfdep, tmap, tidyverse, corrplot)\n\n\ntmap for visualizing geospatial data\nsf for handling geospatial data\ntidyverse for handling aspatial data\nsfdep facilitate spatial dependence analysis with and sf and tidyverse friendly interface\ncorrplot for correlation matrix visualization"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-thailand-province-boundaries",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-thailand-province-boundaries",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "3.1 Import Thailand province boundaries",
    "text": "3.1 Import Thailand province boundaries\nThe below code chunk uses st_read() to imports the administrative boundaries at province level of Thailand to thailand_raw sf dataframe.\n\nthailand_raw = st_read(dsn = \"data/rawdata\",layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\n\nNext we cast the dataframe from MULTIPOLYGON to POLYGON geometry type using the below code chunk to facilitate future spatial neighbor and spatial weights calculation. For provinces with multiple polygons (small islands), only the polygon with the largest area will be kept.\n\nthailand &lt;- thailand_raw |&gt;\n  st_cast(\"POLYGON\") |&gt;\n  mutate(area = st_area(geometry)) |&gt; # Calculate the area of each polygon\n  group_by(ADM1_EN) |&gt; # Group by province\n  filter(area == max(area)) |&gt; # Keep the record with the largest area for each province\n  ungroup() |&gt; # Ungroup after filtering\n  select(c(\"ADM1_EN\"))\n\nWarning in st_cast.sf(thailand_raw, \"POLYGON\"): repeating attributes for all\nsub-geometries for which they may not be constant\n\n# change column name\ncolnames(thailand)[1] = \"province_eng\"\n\nWe check if the data contain any duplicate using below code chunk. The output returns 0 meaning there is no duplicate.\n\nanyDuplicated(thailand)\n\n[1] 0\n\n\nNext we use tmap to plot the thailand sf dataframe and can see all the provinces of Thailand has been plotted properly. For provinces with small islands, only the mainland parts with the largest area are kept.\n\ntm_shape(thailand) +\n  tm_polygons() +\n  tm_text(\"province_eng\", size = 0.2)\n\n\n\n\n\n\n\n\nThe below code is used to check thailand sf dataframe again, which shows the geometry type is already POLYGON. This sf dataframe will be used to define the province boundaries for the remaining analysis.\n\nthailand\n\nSimple feature collection with 77 features and 1 field\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 2\n   province_eng                                                         geometry\n   &lt;chr&gt;                                                           &lt;POLYGON [°]&gt;\n 1 Bangkok                  ((100.6139 13.95462, 100.6143 13.95442, 100.6149 13…\n 2 Samut Prakan             ((100.7306 13.71713, 100.7307 13.71681, 100.7313 13…\n 3 Nonthaburi               ((100.3415 14.10079, 100.3415 14.10001, 100.3415 14…\n 4 Pathum Thani             ((100.8916 14.24576, 100.8916 14.24365, 100.8916 14…\n 5 Phra Nakhon Si Ayutthaya ((100.5131 14.6563, 100.5132 14.65629, 100.5135 14.…\n 6 Ang Thong                ((100.3332 14.79853, 100.3334 14.79811, 100.3335 14…\n 7 Lop Buri                 ((101.3453 15.75254, 101.3457 15.75224, 101.3466 15…\n 8 Sing Buri                ((100.3691 15.0894, 100.3697 15.0891, 100.3708 15.0…\n 9 Chai Nat                 ((100.1199 15.41243, 100.121 15.41234, 100.1229 15.…\n10 Saraburi                 ((101.3994 15.07373, 101.3995 15.07373, 101.3998 15…\n# ℹ 67 more rows"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-domestic-tourism-statistics",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#import-domestic-tourism-statistics",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "3.2 Import Domestic Tourism Statistics",
    "text": "3.2 Import Domestic Tourism Statistics\nThe below code chunk read in thailand_domestic_tourism_2019_2023_ver2.csv using read_csv() and remove the columns in Thai language.\n\ntourism_raw = read_csv(\"data/rawdata/thailand_domestic_tourism_2019_2023_ver2.csv\") |&gt;\n  select(-c(\"province_thai\",\"region_thai\")) # exclude column in Thai language\n\nRows: 30800 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (5): province_thai, province_eng, region_thai, region_eng, variable\ndbl  (1): value\ndate (1): date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe tourism_raw tible dataframe includes the below columns and variables:\n\ndate: The month and year in which the statistics were recorded. The dataset covers the years 2019-2023.\nprovince_eng:The name of the province in English.\nregion_eng:The name of the region in Thailand to which the province belongs, in English.\nvalue: value of the data being recorded\nvariables:The 8 type of data being recorded as follows:\n\nratio_tourist_stay: ratio of tourist stay over-night (total rooms booked/total available rooms)\nno_tourist_stay: The number of tourists who stay over-night\nno_tourist_all: The total number of domestic tourists who visited the province\nno_tourist_thai: The number of Thai tourists who visited the province\nno_tourist_foreign: The number of foreign tourists who visited the province\nrevenue_all: The revenue generated by the tourism industry in the province, in Thai Baht\nrevenue_thai: The revenue generated by Thai tourists in the province, in Thai Baht\nrevenue_foreign: The revenue generated by foreign tourists in the province, in Thai Baht\n\n\nThe below code chunks pivots the dataframe from thin format to wide format using pivot_wider() and add in these additional columns:\n\nrevenue_per_tourist: revenue generated per tourist (= revenue_all / no_tourist_all)\nrevenue_per_thai_tourist: revenue generated per Thai tourist (= revenue_thai/no_tourist_thai)\nrevenue_per_foreign_tourist: revenue generated per foreign tourist (= revenue_foreign/no_tourist_foreign)\nforeign_thai_tourist: ratio of foreign tourist to Thai tourist (= no_tourist_foreign/no_tourist_thai)\nyear_month: derive from date value in YYYYMM format and convert to integer type\n\n\ntourism &lt;- tourism_raw %&gt;%\n  pivot_wider(names_from = variable, values_from = value) |&gt;\n  mutate(revenue_per_tourist = ifelse(no_tourist_all == 0, 0, revenue_all / no_tourist_all)) |&gt;\n  mutate(revenue_per_thai_tourist = ifelse(no_tourist_thai == 0,0,revenue_thai/no_tourist_thai)) |&gt;\n  mutate(revenue_per_foreign_tourist = ifelse(no_tourist_foreign == 0,0,revenue_foreign/no_tourist_foreign)) |&gt;\n  mutate(foreign_thai_tourist = ifelse(no_tourist_thai == 0,0, 100*no_tourist_foreign/no_tourist_thai)) |&gt;\n  mutate(month_no = month(date)) %&gt;%\n  mutate(month_fac = month(date,\n                       label = TRUE, abbr = TRUE)) %&gt;%\n  mutate(year = year(date)) |&gt;\n  mutate(year_month = as.integer(format(as.Date(date), \"%Y%m\")))\n\n\n# View the result\nglimpse(tourism)\n\nRows: 3,850\nColumns: 19\n$ date                        &lt;date&gt; 2019-01-01, 2019-01-01, 2019-01-01, 2019-…\n$ province_eng                &lt;chr&gt; \"Bangkok\", \"Lopburi\", \"Phra Nakhon Si Ayut…\n$ region_eng                  &lt;chr&gt; \"central\", \"central\", \"central\", \"central\"…\n$ ratio_tourist_stay          &lt;dbl&gt; 93.37, 61.32, 73.37, 67.33, 79.31, 71.70, …\n$ no_tourist_stay             &lt;dbl&gt; 3334971, 51858, 117052, 89850, 27141, 1186…\n$ no_tourist_all              &lt;dbl&gt; 5959075, 268664, 730329, 207236, 79073, 29…\n$ no_tourist_thai             &lt;dbl&gt; 3534061, 266301, 561553, 201400, 78514, 28…\n$ no_tourist_foreign          &lt;dbl&gt; 2425014, 2363, 168776, 5836, 559, 11699, 2…\n$ revenue_all                 &lt;dbl&gt; 81926490000, 457240000, 1438730000, 347790…\n$ revenue_thai                &lt;dbl&gt; 29742580000, 451830000, 1054250000, 336190…\n$ revenue_foreign             &lt;dbl&gt; 52183910000, 5410000, 384480000, 11600000,…\n$ revenue_per_tourist         &lt;dbl&gt; 13748.189, 1701.903, 1969.975, 1678.232, 1…\n$ revenue_per_thai_tourist    &lt;dbl&gt; 8415.978, 1696.689, 1877.383, 1669.265, 12…\n$ revenue_per_foreign_tourist &lt;dbl&gt; 21519.014, 2289.463, 2278.049, 1987.663, 1…\n$ foreign_thai_tourist        &lt;dbl&gt; 68.6183402, 0.8873418, 30.0552219, 2.89771…\n$ month_no                    &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ month_fac                   &lt;ord&gt; Jan, Jan, Jan, Jan, Jan, Jan, Jan, Jan, Ja…\n$ year                        &lt;dbl&gt; 2019, 2019, 2019, 2019, 2019, 2019, 2019, …\n$ year_month                  &lt;int&gt; 201901, 201901, 201901, 201901, 201901, 20…"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#tourism-indicators-trend",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#tourism-indicators-trend",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "4.1 Tourism Indicators Trend",
    "text": "4.1 Tourism Indicators Trend\n\n4.1.1 Total Revenue\nThe below code chunk uses ggplot to plot the line chart depicting tourism revenue trends in Thailand over time, segmented into total revenue (revenue_all), revenue from Thai tourist (revenue_thai) and revenue from foreign tourist (revenue_foreign).\n\nsf_long &lt;- tourism %&gt;%\n  group_by(year_month) |&gt;\n  summarize(revenue_all = sum(revenue_all),\n            revenue_thai = sum(revenue_thai),\n            revenue_foreign = sum(revenue_foreign)) |&gt;\n  pivot_longer(cols = c(revenue_all, revenue_thai, revenue_foreign), \n               names_to = \"revenue_type\", \n               values_to = \"revenue\")\n\n# Create the line plot\nggplot(sf_long, aes(x = factor(year_month), y = revenue, color = revenue_type, group = revenue_type)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Tourism Revenue Over Time\",\n       x = \"Year-Month\",\n       y = \"Revenue\",\n       color = \"Revenue Type\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nKey observations frome the above chart:\n\nSharp Decline in Early 2020: All revenue categories plummet in early 2020, coinciding with the onset of the COVID-19 pandemic. Foreign tourism (revenue_foreign) drops to nearly zero, while domestic revenue (revenue_thai) remains slightly above zero.\nSlow Recovery Starting Mid-2021: Starting in September 2021, revenues begin to recover. Domestic revenue (revenue_thai) shows a more gradual and consistent rebound, while foreign revenue recovers at a slower pace but picks up by 2022.\nPost-2021 Recovery Trends: Foreign tourism begins to recover more noticeably after 2022, with a sharp rise in revenues.\nDependence on Foreign Tourism: The gap between revenue_all and revenue_thai highlights the significant contribution of foreign tourists to total tourism revenue. Pre-2020, foreign tourism was a major driver of revenue, and its slower recovery delayed overall recovery until mid-2022.\n\nOverall, while tourism revenues have been recovering since 2021, we can see the industry was severely impacted by the pandemic, with foreign tourism showing the steepest decline and the slowest rebound. Domestic tourism played a key role in stabilizing the economy before foreign tourism recovered. Below is an illustration on Covid timeline in Thailand in 2020 for your reference.\n\n\n\n4.1.2 Number of Tourists\nNext we look at the monthly trend of spend per tourist\n\nsf_long_tourist &lt;- tourism %&gt;%\n  group_by(year_month) |&gt;\n  summarize(no_tourist_all = sum(no_tourist_all),\n            no_tourist_thai = sum(no_tourist_thai),\n            no_tourist_foreign = sum(no_tourist_foreign)) |&gt;\n  pivot_longer(cols = c(no_tourist_all, no_tourist_thai, no_tourist_foreign), \n               names_to = \"tourist_type\", \n               values_to = \"tourist\")\n\n# Create the line plot\nggplot(sf_long_tourist, aes(x = factor(year_month), y = tourist, color = tourist_type, group = tourist_type)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Number of Tourists Over Time\",\n       x = \"Year-Month\",\n       y = \"Tourist\",\n       color = \"Tourist Type\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nThe number of tourists over time chart demonstrates similar trend to the Revenue over time chart, with a significant drop in early 2020 due to COVID pandemic, then slowly recover from Mid 2021. However, there is 1 significant difference compared to revenue contribution, where Thai tourists is the main drivers of the total number of tourist, not foreign tourists.\n\n\n4.1.3 Average Ratio of Tourist Stay and Foreign to Thai tourists\nNext we look at the average ratio of tourist stay and Foreign to Thai tourist over time.\n\nsf_long_ratio &lt;- tourism %&gt;%\n  group_by(year_month) |&gt;\n  summarize(ratio_tourist_stay = mean(ratio_tourist_stay),\n            foreign_thai_tourist = mean(foreign_thai_tourist)) |&gt;\n  pivot_longer(cols = c(ratio_tourist_stay, foreign_thai_tourist), \n               names_to = \"ratio_type\", \n               values_to = \"ratio\")\n\n# Create the line plot\nggplot(sf_long_ratio, aes(x = factor(year_month), y = ratio, color = ratio_type, group = ratio_type)) +\n  geom_line() +\n  geom_point() +\n  labs(title = \"Tourism Ratio Over Time\",\n       x = \"Year-Month\",\n       y = \"Tourism Ratio\",\n       color = \"Ratio Type\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\nKey observations from above chart:\n\nRatio of foreign tourists to Thai tourists: the ratio starts at a high level in 2019, suggesting a predominance of foreign tourists during this period. The ratio drops significantly in May 2020 due to the pandemic restriction, then slowly recovers from April 2022.\nThe revenue per tourist in April and May 2020 are significantly higher than other months, this may be due to the pandemic travel bans and curfew happened during these 2 months, causing the number of tourists, especially foreign tourists to be very low.\n\nRatio of tourist stay over-night: this ratio also drops significantly in 2020, albeit the recovery speed is much faster from mid 2021, indicating the increasing contribution of Thai tourist to booked accommodation."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#tourism-by-province-in-2022",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#tourism-by-province-in-2022",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "4.2 Tourism by Province in 2022",
    "text": "4.2 Tourism by Province in 2022\nWe will focus on 2022 as this the year the tourism industry in Thailand started to recover after the pandemic and data is available for all months.\n\n4.2.1 Total Revenue\nThe below code chunks plot the full year 2022 revenue by province using ggplot.\n\n# Filter data for the year 2022 and aggregate by province\ntourism_2022 &lt;- tourism %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(total_revenue = sum(revenue_all))\n\n# Plot a bar chart showing total revenue by province for 2022\nggplot(tourism_2022, aes(x = reorder(province_eng,total_revenue), y = total_revenue)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Total Revenue by Province in 2022\",\n       x = \"Province\",\n       y = \"Total Revenue\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(angle = 0, hjust = 1)) +  # Ensure province labels are readable\n  coord_flip()\n\n\n\n\n\n\n\n\nWe can see the revenue distribution among Thailand’s provinces is highly skewed. The top 4 provinces with significantly higher revenue than the remaining provinces are: Bangkok, Phuket, Chonburi, Chiang Mai.\n\n\n4.2.2 Number of Tourist by Province\nThe below code chunk plots the total number of tourists by province in Thailand in 2022.\n\n# Filter data for the year 2022 and aggregate by province\ntourist_2022 &lt;- tourism %&gt;%\n  filter(year == 2022) %&gt;%\n  group_by(province_eng) %&gt;%\n  summarize(total_tourist = sum(no_tourist_all))\n\n# Plot a bar chart showing total revenue by province for 2022\nggplot(tourist_2022, aes(x = reorder(province_eng,total_tourist), y = total_tourist)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  labs(title = \"Number of Tourists by Province in 2022\",\n       x = \"Province\",\n       y = \"Number of Tourists\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(angle = 0, hjust = 1)) +\n  coord_flip()\n\n\n\n\n\n\n\n\nThe number of tourists by province is also unevenly distributed, although less skewed than the revenue distribution. The top 4 provinces with significantly higher number of tourists compared to the remaining provinces are: Bangkok, Chonburi, Kanchanaburi, Prachuap Khiri Khan. Among the top 4 provinces with highest revenue, only Bangkok and Chonburi are also in the top 4 provinces with highest number of tourist, indicating the revenue per tourist is higher in Phuket and Chiang Mai."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#correlation-matrix",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#correlation-matrix",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "4.3 Correlation Matrix",
    "text": "4.3 Correlation Matrix\nThe below code chunk plots a correlation matrix across the available tourism indicators to understand the relationships between all pair of variables.\n\ndata_subset &lt;- tourism[, c(\"revenue_all\", \"no_tourist_all\", \"ratio_tourist_stay\",\"no_tourist_stay\",\"no_tourist_thai\",\"no_tourist_foreign\",\"revenue_thai\",\"revenue_foreign\",\"revenue_per_tourist\",\"revenue_per_thai_tourist\",\"revenue_per_foreign_tourist\",\"foreign_thai_tourist\")]\n\n# Compute the correlation matrix\nM &lt;- cor(data_subset, use = \"complete.obs\")\n\n# Visualize the correlation matrix\ncorrplot(M, method = 'number',order = 'AOE', tl.cex = 0.6)\n\n\n\n\n\n\n\n\nBase on the above matrix, the below variables will be excluded from further analysis due to strong correlation with the key indicators (revenue_all, no_tourist_all, ratio_tourist_stay):\n\nno_tourist_thai and revenue_thai: high correlation (0.96 and 0.94) with no_tourist_all\nno_tourist_stay: high correlation (0.96) with no_tourist_all\nno_tourist_foreign and revenue_foreign: high correlation (0.96 and 0.98) with revenue_all\nrevenue_per_foreign_tourist: high correlation (0.71) with revenue_per_tourist\nrevenue_per_thai_tourist: reflect similar information to revenue_per_tourist and foreign_thai_tourist"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#total-revenue-2",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#total-revenue-2",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "8.1 Total Revenue",
    "text": "8.1 Total Revenue\nFirst we compute the local Moran’s I of revenue_all at province level using local_moran() as in below code chunk.\n\nset.seed(1234)\nlisa_revenue_all &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    revenue_all, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nThe below code chunk plots the LISA map of revenue_all using the classification from the mean LISA categories.\n\nlisa_sig_revenue_all &lt;- lisa_revenue_all  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_revenue_all) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_revenue_all) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from the LISA map:\n\nThere are clusters with Low-Low values in the North Easten region of Thailand, indicating low revenue from tourism in this area.\nThere are 2 Low-High clusters adjacent to Bangkok, this indicate the tourism revenue of the area around Bangkok is not evenly distributed.\nThere is 1 High-Low cluster at Kanchanaburi province, indicating the tourism revenue in this area is significantly higher than the surrounding neighbors."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#number-of-tourists-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#number-of-tourists-1",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "8.2 Number of Tourists",
    "text": "8.2 Number of Tourists\nFirst we compute the local Moran’s I of no_tourist_all at province level using local_moran() as in below code chunk.\n\nset.seed(1234)\nlisa_no_tourist_all &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    no_tourist_all, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nThe below code chunk plots the LISA map of no_tourist_all using the classification from the mean LISA categories.\n\nlisa_sig_no_tourist_all &lt;- lisa_no_tourist_all  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_no_tourist_all) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_no_tourist_all) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from above LISA map:\n\nSimilar to the LISA map on revenue_all, there are Low-Low clusters in the North Easter region and Low-High clusters around Bangkok.\nThere is 1 High-High cluster at Phetchaburi province, suggesting this can be a popular tourist destination compared to surrounding provinces."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#average-ratio-tourist-stay",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#average-ratio-tourist-stay",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "8.3 Average Ratio Tourist Stay",
    "text": "8.3 Average Ratio Tourist Stay\nFirst we compute the local Moran’s I of avg_ratio_stay at province level using local_moran() as in below code chunk.\n\nset.seed(1234)\nlisa_avg_ratio_stay &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    avg_ratio_stay, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nThe below code chunk plots the LISA map of avg_ratio_stay using the classification from the mean LISA categories.\n\nlisa_sig_avg_ratio_stay &lt;- lisa_avg_ratio_stay  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_avg_ratio_stay) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_avg_ratio_stay) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from above LISA map:\n\nThere are High-High clusters in the North region, suggesting tourists tend to stay overnight in this area.\nThere is 1 Low-High cluster also in the North region, suggesting tourists are less likely to stay overnight in this province, they may prefer to stay in the neighboring High-High provinces."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#foreign-to-thai-tourist",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#foreign-to-thai-tourist",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "8.4 Foreign to Thai tourist",
    "text": "8.4 Foreign to Thai tourist\nFirst we compute the local Moran’s I of foreign_thai_tourist at province level using local_moran() as in below code chunk.\n\nset.seed(1234)\nlisa_foreign_thai_tourist &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    foreign_thai_tourist, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nThe below code chunk plots the LISA map of foreign_thai_tourist using the classification from the mean LISA categories.\n\nlisa_sig_foreign_thai_tourist &lt;- lisa_foreign_thai_tourist  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_foreign_thai_tourist) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_foreign_thai_tourist) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from above LISA map:\n\nThere are Low-Low clusters in the Central region, suggesting these provinces are less popular to foreign visitors.\nThere are High-High clusters in the Coastal region at Phuket,\nPhang Nga and Surat Thani provinces. These are well-known destination for foreign visitors."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#revenue-per-tourist-1",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#revenue-per-tourist-1",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "8.5 Revenue per tourist",
    "text": "8.5 Revenue per tourist\nFirst we compute the local Moran’s I of revenue_per_tourist at province level using local_moran() as in below code chunk.\n\nset.seed(1234)\nlisa_revenue_per_tourist &lt;- wm_q %&gt;% \n  mutate(local_moran = local_moran(\n    revenue_per_tourist, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\n\nThe below code chunk plots the LISA map of revenue_per_tourist using the classification from the mean LISA categories.\n\nlisa_sig_revenue_per_tourist &lt;- lisa_revenue_per_tourist  %&gt;%\n  filter(p_ii_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa_revenue_per_tourist) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig_revenue_per_tourist) +\n  tm_fill(\"mean\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from above LISA map:\n\nThere are Low-Low clusters in the North East and Central regions, suggesting the revenue per tourist is lower in the provinces.\nThere are High-High clusters in Phukey and Phang Nga province. As these areas are popular to foreign visitors (also High-High cluster on Foreign to Thai tourists ratio), suggesting foreign visitors tend to spend more on their visits."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#create-a-time-series-cube",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#create-a-time-series-cube",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "9.1 Create a Time Series Cube",
    "text": "9.1 Create a Time Series Cube\nThe code chunk below uses spacetime() of sfdep to create an spatio-temporal cube from tourism and thailand dataframe. The .loc_col and .time_col arguments are used to define the location and time period column from the relevant dataset.\n\nthailand_st = spacetime(tourism, thailand,\n                        .loc_col = \"province_eng\",\n                        .time_col = \"year_month\")\n\nNext is_spacetime_cube() of sfdep package is used to verify if the conversion is successful. The output is TRUE meaning thailand_st is already a spatio-temporal cube.\n\nis_spacetime_cube(thailand_st)\n\n[1] TRUE"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#perform-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#perform-ehsa",
    "title": "Take-home Exercise 2: Discovering impacts of COVID-19 on Thailand tourism economy at province level using spatial and spatio-temporal statistics",
    "section": "9.2 Perform EHSA",
    "text": "9.2 Perform EHSA\nFirst we identify the neighbors and calculate the inverse distance weight using below code chunk.\n\nthailand_nb &lt;- thailand_st %&gt;%\n  activate(\"geometry\") %&gt;%\n  mutate(nb = include_self(\n    st_knn(geometry, k=6)),\n    wt = st_inverse_distance(nb, \n                             geometry, \n                             scale = 1,\n                             alpha = 1),\n    .before = 1) %&gt;%\n  set_nbs(\"nb\") %&gt;%\n  set_wts(\"wt\")\n\nWe perform EHSA using the emerging_hotspot_analysis() function from sfdep. Emerging Hot Spot Analysis detects trends in spatial clustering over time by combining the Getis-Ord Gi* statistic with the Mann-Kendall trend test to identify temporal patterns associated with local clustering of hot and cold spots. The function requires a spacetime object (thailand_st) and the variable name for the .var argument. The k argument sets the number of time lags (default is 1), and nsim specifies the number of simulations.\n\n9.2.1 Total Revenue\n\nset.seed(1234)\nehsa_revenue_all &lt;- emerging_hotspot_analysis(\n  x = thailand_st, \n  .var = \"revenue_all\", \n  k = 1, \n  nsim = 99\n)\n\nThe distribution of statistically significant EHSA classes is visualized with ggplot using below code chunk.\n\nggplot(data = filter(ehsa_revenue_all, p_value &lt; 0.05),\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can see majority of the areas has sporadic coldspot detected. This can be due to the impact of COVID-19 travel restriction.\nNext we join thailand sf dataframe with the derived ehsa using left_join() as below.\n\nthailand_ehsa_revenue_all &lt;- thailand %&gt;%\n  left_join(ehsa_revenue_all,\n            by = join_by(province_eng == location))\n\nThe below code chunk uses this joined dataframe to visualize the geographic distribution of EHSA classes.\n\nehsa_sig_revenue_all &lt;- thailand_ehsa_revenue_all  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thailand_ehsa_revenue_all) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_revenue_all) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nThe EHSA map provides insights into the spatial distribution of emerging hotspots and coldspots for tourism revenue in Thailand provinces from January 2019 to February 2023.\nSeveral provinces in the northern, northeastern and southern regions of Thailand are identified as sporadic coldspots. This suggests that these regions experienced some declines or stagnation in tourism revenue, in which COVID-19 travel restriction can be a major factor.\n\n\n9.2.2 Number of Tourists\n\nset.seed(1234)\nehsa_no_tourist_all &lt;- emerging_hotspot_analysis(\n  x = thailand_st, \n  .var = \"no_tourist_all\", \n  k = 1, \n  nsim = 99\n)\n\nThe distribution of statistically significant EHSA classes is visualized with ggplot using below code chunk.\n\nggplot(data = filter(ehsa_no_tourist_all, p_value &lt; 0.05),\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can see most of the areas has no pattern detected.\nNext we join thailand sf dataframe with the derived ehsa using left_join() as below.\n\nthailand_ehsa_no_tourist_all &lt;- thailand %&gt;%\n  left_join(ehsa_no_tourist_all,\n            by = join_by(province_eng == location))\n\nThe below code chunk uses this joined dataframe to visualize the geographic distribution of EHSA classes.\n\nehsa_sig &lt;- thailand_ehsa_no_tourist_all  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thailand_ehsa_no_tourist_all) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nThe map shows only 1 oscillating coldspot in Phichit province, suggesting this province used to be popular to tourists in the past but not as of February 2023.\n\n\n9.2.3 Ratio Tourist Stay\n\nset.seed(1234)\nehsa_ratio_tourist_stay &lt;- emerging_hotspot_analysis(\n  x = thailand_st, \n  .var = \"ratio_tourist_stay\", \n  k = 1, \n  nsim = 99\n)\n\nThe distribution of statistically significant EHSA classes is visualized with ggplot using below code chunk.\n\nggplot(data = filter(ehsa_ratio_tourist_stay, p_value &lt; 0.05),\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can see majority of the areas has oscilating hotspot.\nNext we join thailand sf dataframe with the derived ehsa using left_join() as below.\n\nthailand_ehsa_ratio_tourist_stay &lt;- thailand %&gt;%\n  left_join(ehsa_ratio_tourist_stay,\n            by = join_by(province_eng == location))\n\nThe below code chunk uses this joined dataframe to visualize the geographic distribution of EHSA classes.\n\nehsa_sig_ratio_tourist_stay &lt;- thailand_ehsa_ratio_tourist_stay  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thailand_ehsa_ratio_tourist_stay) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_ratio_tourist_stay) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nKey observations from the above EHSA map:\n\nSeveral provinces in the northern and central regions are identified as oscillating hotspots. This suggests these regions experienced significant fluctuations in the ratio of tourist stay overnight during the period 2019-2023, potentially indicating emerging tourist destinations with growing popularity.\nSome provinces in the northeastern region are classified as oscillating coldspots. This suggests these regions experienced fluctuations in the ratio of tourist stay overnight with an overall downward trend.\n\n\n\n9.2.4 Foreign to Thai tourists ratio\n\nset.seed(1234)\nehsa_foreign_thai_tourist &lt;- emerging_hotspot_analysis(\n  x = thailand_st, \n  .var = \"foreign_thai_tourist\", \n  k = 1, \n  nsim = 99\n)\n\nThe distribution of statistically significant EHSA classes is visualized with ggplot using below code chunk.\n\nggplot(data = filter(ehsa_foreign_thai_tourist, p_value &lt; 0.05),\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can see majority of the areas has sporadic coldspot pattern.\nNext we join thailand sf dataframe with the derived ehsa using left_join() as below.\n\nthailand_ehsa_foreign_thai_tourist &lt;- thailand %&gt;%\n  left_join(ehsa_foreign_thai_tourist,\n            by = join_by(province_eng == location))\n\nThe below code chunk uses this joined dataframe to visualize the geographic distribution of EHSA classes.\n\nehsa_sig_foreign_thai_tourist &lt;- thailand_ehsa_foreign_thai_tourist  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thailand_ehsa_foreign_thai_tourist) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_foreign_thai_tourist) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\nSeveral provinces in the central and northern regions of Thailand are identified as sporadic hotspots. This suggests significant fluctuations in the ratio of foreign to Thai tourists in these areas during the study period, potentially indicating increased popularity among foreign visitors.\nMany provinces in the northern, northeastern and central region around Bangkok are classified as sporadic coldspots, indicating fluctuations in the ratio of foreign to Thai tourists with an overall downward trend.\n\n\n\n9.2.5 Revenue per Tourist\n\nset.seed(1234)\nehsa_revenue_per_tourist &lt;- emerging_hotspot_analysis(\n  x = thailand_st, \n  .var = \"revenue_per_tourist\", \n  k = 1, \n  nsim = 99\n)\n\nThe distribution of statistically significant EHSA classes is visualized with ggplot using below code chunk.\n\nggplot(data = filter(ehsa_revenue_per_tourist, p_value &lt; 0.05),\n       aes(x = classification)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nWe can see majority of the areas has sporadic coldspot pattern.\nNext we join thailand sf dataframe with the derived ehsa using left_join() as below.\n\nthailand_ehsa_revenue_per_tourist &lt;- thailand %&gt;%\n  left_join(ehsa_revenue_per_tourist,\n            by = join_by(province_eng == location))\n\nThe below code chunk uses this joined dataframe to visualize the geographic distribution of EHSA classes.\n\nehsa_sig_revenue_per_tourist &lt;- thailand_ehsa_revenue_per_tourist  %&gt;%\n  filter(p_value &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(thailand_ehsa_revenue_per_tourist) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(ehsa_sig_revenue_per_tourist) +\n  tm_fill(\"classification\") + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\n\nSeveral provinces in the central and northern regions of Thailand, are identified as sporadic hotspots. This suggests significant fluctuations in revenue per tourist during the study period, with the overall value is still high compared to the neighboring provinces.\nMany provinces nationwide are classified as sporadic coldspots, indicating fluctuations in revenue per tourist with a relatively low value compared to their neighbors, may of which has sporadic hotspots pattern."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) accounts for non-stationary variables (e.g., climate, demographics, environment) and models local relationships between independent variables and a dependent variable. In this exercise, we’ll build hedonic pricing models using GWR, with the 2015 resale prices of condominiums as the dependent variable and structural and locational factors as independent variables."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#import-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#import-geospatial-data",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Import geospatial data",
    "text": "5.1 Import geospatial data\nThe geospatial data for this exercise is MP14_SUBZONE_WEB_PL, an ESRI shapefile representing the URA Master Plan 2014’s planning subzone boundaries as polygons. It uses the svy21 projected coordinate system. The code below uses the st_read() function from the sf package to import this shapefile for further analysis.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report indicates that the imported MP14_SUBZONE_WEB_PL shapefile is stored in an R object called mpsz, which is a simple feature (sf) object with a geometry type of multipolygon. However, it is important to note that the mpsz object lacks EPSG (coordinate reference system) information, which may need to be defined for spatial analyses."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#updating-crs-information",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.2 Updating CRS information",
    "text": "5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, we can verify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package as below.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG is indicated as 3414 now.\nNext, we reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#import-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#import-the-aspatial-data",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Import the aspatial data",
    "text": "6.1 Import the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nAfter importing the data file into R, it is important to examine if the data file has been imported correctly. The codes chunks below uses glimpse() to display the data structure of the imported object.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#convert-aspatial-data-frame-into-a-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#convert-aspatial-data-frame-into-a-sf-object",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.2 Convert aspatial data frame into a sf object",
    "text": "6.2 Convert aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object using st_as_sf() as in below code chunk.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to reproject the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.1 EDA using statistical graphics",
    "text": "7.1 EDA using statistical graphics\nThe distribution of SELLING_PRICE is plotted using ggplot as in below code chunk.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure shows a right-skewed distribution, indicating that most condominium units were sold at relatively lower prices. To normalize this skewed distribution, a log transformation can be applied. The code chunk below creates a new variable, LOG_SELLING_PRICE, by applying a log transformation to the SELLING_PRICE variable, using the mutate() function from the dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, we can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.2 Multiple Histogram Plots distribution of variables",
    "text": "7.2 Multiple Histogram Plots distribution of variables\nIn this section, we explore how to create small multiple histograms (also known as a trellis plot) using the ggarrange() function from the ggpubr package.\nThe provided code first creates 12 histograms and then uses ggarrange() to organize these histograms into a 3-column by 4-row layout to display them as a small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#draw-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#draw-statistical-point-map",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "7.3 Draw Statistical Point Map",
    "text": "7.3 Draw Statistical Point Map\nLastly, the geospatial distribution condominium resale prices in Singapore is plotted using tmap package.\nFirst, we will turn on the interactive mode of tmap by using below code chunk.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nNote that tm_dots() is utilized instead of tm_bubbles().\nThe set.zoom.limits argument in tm_view() specifies the minimum and maximum zoom levels, set to 11 and 14, respectively.\nBefore proceeding to the next section, the following code will switch R’s display back to plot mode.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.1 Simple Linear Regression Method",
    "text": "8.1 Simple Linear Regression Method\nFirst, we will create a simple linear regression model using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nThe lm() function returns an object of class lm (or `c(“mlm”, “lm”) for multiple responses).\nThe summary() and anova() functions can be used to obtain and display a summary and an analysis of variance table for the results. Additionally, generic accessor functions like coefficients, effects, fitted.values, and residuals can be used to extract various useful features from the lm object.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report indicates that SELLING_PRICE can be modeled using the equation:\ny= −258121.1 + 14719x1\nThe R-squared value of 0.4518 shows that the model explains about 45% of the variance in resale prices.\nSince the p-value is significantly smaller than 0.0001, we reject the null hypothesis that the mean is a good estimator for SELLING_PRICE, suggesting that our linear regression model is a good fit.\nThe Coefficients section reveals that the p-values for both the intercept and AREA_SQM estimates are below 0.001. Thus, we reject the null hypotheses that B0 and B1 are equal to 0, inferring that both are good parameter estimates.\nTo visualize the best-fit curve on a scatter plot, we can use the lm() function within ggplot’s geometry, as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe scatter plot reveals there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.2 Multiple Linear Regression Method",
    "text": "8.2 Multiple Linear Regression Method\n\n8.2.1 Visualising the relationships of the independent variables\nBefore constructing a multiple regression model, it’s essential to ensure that the independent variables are not highly correlated with one another, as this can compromise the model’s quality—a phenomenon known as multicollinearity.\nA correlation matrix is a common tool for visualizing relationships among independent variables. While R’s pairs() function can display this matrix, there are various packages available for enhanced visualization. In this section, we will use the corrplot package.\nThe code chunk below generates a scatterplot matrix to illustrate the relationships between the independent variables in the condo_resale data frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reordering is crucial for uncovering hidden structures and patterns within the data. The corrplot package offers four methods for this purpose: “AOE,” “FPC,” “hclust,” and “alphabet.” In the code chunk above, the AOE method, which orders variables based on the angular order of the eigenvectors as proposed by Michael Friendly, is utilized.\nThe scatterplot matrix reveals a strong correlation between Freehold and LEASE_99YEAR. Therefore, it is advisable to include only one of these variables in the subsequent model, leading to the exclusion of LEASE_99YEAR from further analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below uses lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n8.3.1 Preparing Publication Quality Table: olsrr method\nThe report indicates that not all independent variables are statistically significant. We will refine the model by removing these insignificant variables.\nWe are calibrate the revised model using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#preparing-publication-quality-table-gtsummary-method",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "8.4 Preparing Publication Quality Table: gtsummary method",
    "text": "8.4 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nThe code chunk below uses tbl_regression() to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table using add_glance_table() or adding as a table source note using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n8.4.1 Check for multicolinearity\nIn this section, we introduce the olsrr R package, designed for performing OLS regression. It offers various methods for enhancing multiple linear regression models, including:\n\nComprehensive regression output\nResidual diagnostics\nMeasures of influence\nHeteroskedasticity tests\nCollinearity diagnostics\nModel fit assessment\nVariable contribution assessment\nVariable selection procedures\n\nThe code chunk below uses the ols_vif_tol() function from the olsrr package to test for signs of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10, we can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n8.4.2 Test for Non-Linearity\nIn multiple linear regression, it’s crucial to test the assumptions of linearity and additivity between the dependent and independent variables.\nThe code chunk below uses the ols_plot_resid_fit() function from the olsrr package to perform the linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe scatter plot reveals that most of the data points are scattered around the 0 line. We can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.4.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist()of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residuals of the multiple linear regression model (i.e. condo.mlr1) resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\nWarning in ks.test.default(y, \"pnorm\", mean(y), sd(y)): ties should not be\npresent for the one-sample Kolmogorov-Smirnov test\n\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table indicates that the p-values of the four tests are significantly lower than the alpha value of 0.05. We reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\n8.4.4 Testing for Spatial Autocorrelation\nSince our hedonic model uses geographically referenced attributes, it’s essential to visualize the residuals of the model. To perform a spatial autocorrelation test, we first need to convert condo_resale.sf from an sf data frame into a SpatialPointsDataFrame.\nWe begin by exporting the residuals of the hedonic pricing model and saving them as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we join this newly created data frame with the condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\n\nThe code chunks creates an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nWe switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe figure above indicates signs of spatial autocorrelation.\nTo confirm this observation, we will perform the Moran’s I test.\nFirst, we need to compute the distance-based weight matrix using the dnearneigh() function from spdep package.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw()of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights object.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext,lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation.\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation reveals a p-value of less than 2.2 × 10^{-16}, which is below the alpha level of 0.05. We reject the null hypothesis that the residuals are randomly distributed.\nSince the observed Global Moran’s I is 0.14244180, which is greater than 0, we can conclude that the residuals exhibit a clustered distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#build-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#build-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.1 Build Fixed Bandwidth GWR Model",
    "text": "9.1 Build Fixed Bandwidth GWR Model\n\n9.1.1 Compute fixed bandwith\nIn the code chunk below, the bw.gwr() function from the GWModel package is used to determine the optimal fixed bandwidth for the model. The adaptive argument is set to FALSE, indicating that we are computing the fixed bandwidth.\nThere are two approaches to determine the stopping rule: the CV cross-validation approach and the AIC corrected (AICc) approach. We will define the stopping rule using the approach argument.\n\nbw.fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres.\n\n\n9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-13 15:44:32.468163 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-13 15:44:33.03484 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.2 Building Adaptive Bandwidth GWR Model",
    "text": "9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model using adaptive bandwidth approach.\n\n9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the recommended data points to be used is 30.\n\n\n9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can calibrate the gwr-based hedonic pricing model using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe model output can be displayed using below code chunk.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-13 15:44:37.162164 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-13 15:44:37.836094 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-gwr-output",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.3 Visualize GWR Output",
    "text": "9.3 Visualize GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted yyy values, condition number, local R2, residuals, and coefficients with standard errors:\n\nCondition Number: This diagnostic assesses local collinearity. High condition numbers (greater than 30) indicate strong local collinearity, leading to unstable results.\nLocal R2: Ranging from 0.0 to 1.0, these values reflect how well the local regression model fits the observed y values. Low R2 values suggest poor model performance. Mapping Local R2 can highlight areas where GWR predictions are strong or weak, potentially indicating missing important variables.\nPredicted Values: These are the estimated y values computed by GWR.\nResiduals: Calculated by subtracting fitted y values from observed y values. Standardized residuals should have a mean of zero and a standard deviation of one. A rendered map of standardized residuals can visually represent these values.\nCoefficient Standard Error: This measures the reliability of each coefficient estimate. Smaller standard errors relative to the coefficient values indicate greater confidence, while larger standard errors may suggest local collinearity issues.\n\nAll these metrics are stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y values, predicted values, coefficient standard errors, and t-values in the “data” slot of an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#converting-sdf-into-sf-data.frame",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.4 Converting SDF into sf data.frame",
    "text": "9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame using the code chunk below.\n\ncondo_resale.sf.adaptive &lt;- st_as_sf(gwr.adaptive$SDF) %&gt;%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 &lt;- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output &lt;- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive &lt;- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       &lt;dbl&gt; 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              &lt;dbl&gt; 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   &lt;dbl&gt; -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              &lt;dbl&gt; -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        &lt;dbl&gt; 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      &lt;dbl&gt; -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  &lt;dbl&gt; -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              &lt;dbl&gt; -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             &lt;dbl&gt; -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      &lt;dbl&gt; 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    &lt;dbl&gt; 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         &lt;dbl&gt; 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           &lt;dbl&gt; 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       &lt;dbl&gt; -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              &lt;dbl&gt; 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               &lt;dbl&gt; 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               &lt;dbl&gt; 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-local-r2",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.5 Visualize local R2",
    "text": "9.5 Visualize local R2\nThe code chunks creates an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html#visualize-coefficient-estimates",
    "title": "Hands-on Exercise 7: Calibrate Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "9.6 Visualize coefficient estimates",
    "text": "9.6 Visualize coefficient estimates\nThe code chunks below creates an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\nWarning: The shape mpsz_svy21 is invalid (after reprojection). See\nsf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\n\n9.6.1 By URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\",])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "First we import the relevant packages using p_load() of pacman.\n\npacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)\n\n\n\n\n\n\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") |&gt;\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nFirst we read in the csv file on condo resale pricing and other variables.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNext we convert the tible dataframe into an sf dataframe\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nWe save the data into rds file format.\n\nwrite_rds(condo_resale.sf, \"data/rds/condo_resale_sf.rds\")\n\nThe below code chunk reads the data from rds file.\n\ncondo_resale_sf &lt;- read_rds(\n  \"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-r-packages",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-r-packages",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "First we import the relevant packages using p_load() of pacman.\n\npacman::p_load(olsrr, ggstatsplot, ggpubr, \n               sf, spdep, GWmodel, tmap,\n               tidyverse, gtsummary, performance,\n               see, sfdep)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-data",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "mpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") |&gt;\n  st_transform(3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nFirst we read in the csv file on condo resale pricing and other variables.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nRows: 1436 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (23): LATITUDE, LONGITUDE, POSTCODE, SELLING_PRICE, AREA_SQM, AGE, PROX_...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNext we convert the tible dataframe into an sf dataframe\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nWe save the data into rds file format.\n\nwrite_rds(condo_resale.sf, \"data/rds/condo_resale_sf.rds\")\n\nThe below code chunk reads the data from rds file.\n\ncondo_resale_sf &lt;- read_rds(\n  \"data/rds/condo_resale_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#convert-aspatial-data-frame-into-an-sf-object",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#convert-aspatial-data-frame-into-an-sf-object",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "2.1 Convert aspatial data frame into an sf object",
    "text": "2.1 Convert aspatial data frame into an sf object\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#multicollinearity",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#multicollinearity",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Multicollinearity",
    "text": "5.1 Multicollinearity\n\nols_vif_tol(condo.mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\nThe result shows that no variable has VIF great than 5. Dummy variables will not affect the overall calibration a lot, that is why although FREEHOLD and LEASEHOLE_99YR have multicollinearity (as they are dummy variables derived from the same variable), their VIFs are still lower than 5."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#variable-selection",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#variable-selection",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.2 Variable Selection",
    "text": "5.2 Variable Selection\n\ncondo_fw_mlr = ols_step_forward_p(\n  condo.mlr,\n  p_val = 0.05,\n  details = FALSE)\n\n\nplot(condo_fw_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#test-for-non-linearity",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#test-for-non-linearity",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.3 Test for Non-linearity",
    "text": "4.3 Test for Non-linearity\nIn multiple linear regression, it’s essential to test the assumptions of linearity and additivity between the dependent and independent variables. The ols_plot_resid_fit() function from the olsrr package is used to perform this linearity assumption test as in below code chunk.\n\nols_plot_resid_fit(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure shows that most data points are scattered around the 0 line, indicating that the relationship between the dependent and independent variables is linear."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#residual-normality-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#residual-normality-test",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.4 Residual normality test",
    "text": "5.4 Residual normality test\nFirst we export the residuals of the hedonic pricing model and save it as a data frame.\n\nmlr_output = as.data.frame(condo_fw_mlr$model$residuals) |&gt;\n  rename('FW_MLR_RES' = 'condo_fw_mlr$model$residuals')\n\nNext we join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf = cbind(condo_resale.sf,\n                        mlr_output$FW_MLR_RES) |&gt;\n  rename('MLR_RES' = 'mlr_output.FW_MLR_RES')\n\nNext we use tmap to display the distribution of the residuals on an interactive map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntm_shape(mpsz) +\n  tmap_options(check.and.fix = TRUE) + # to fix the issue in the mpsz layer\n  tm_polygons(alpha = 0.4) +\n  tm_shape(condo_resale_sf) +\n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style = \"quantile\")\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\nVariable(s) \"MLR_RES\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThe map shows some high value clusters around the central region.\nThe Moran’s I test will be performed to prove our observations.\n\ncondo_resale_sf = condo_resale_sf |&gt;\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\n\nset.seed(1234)\nglobal_moran_perm(condo_resale_sf$MLR_RES,\n                  condo_resale_sf$nb,\n                  condo_resale_sf$wt,\n                  alternative = \"two.sided\",\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nAs the p-value is smaller than 0.05, we can reject the null hypothesis that the residuals are randomly distributed. Since the Moran I’s statistic = 0.32254 &gt; 0, we can infer that the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#gwmodel-method---fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#gwmodel-method---fixed-bandwidth",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 GWModel method - fixed bandwidth",
    "text": "6.1 GWModel method - fixed bandwidth\n\ngwr_fixed = gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                  data = condo_resale_sf,\n                  bw = bw_fixed,\n                  kernel = 'gaussian',\n                  longlat = FALSE)\n\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-14 22:21:59.318987 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-14 22:22:00.406847 \n\n\nThe output shows that the adjust R-square improve quite a lot to 84.3% compared to the global model (64.7%)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#convert-sdf-into-sf-data.frame",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#convert-sdf-into-sf-data.frame",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.4 Convert SDF into sf data.frame",
    "text": "6.4 Convert SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame using the code chunk below.\n\ngwr_adaptive_output = as.data.frame(\n  gwr_adaptive$SDF) |&gt;\n  select(-c(2:15))\n\n\ngwr_sf_adaptive = cbind(condo_resale_sf,\n                        gwr_adaptive_output)\n\nNext , glimpse() is used to display the content of gwr_sf_adaptive sf data frame.\n\nglimpse(gwr_sf_adaptive)\n\nRows: 1,436\nColumns: 63\n$ nb                      &lt;nb&gt; &lt;66, 77, 123, 238, 239, 343&gt;, &lt;21, 162, 163, 19…\n$ wt                      &lt;list&gt; &lt;0.1666667, 0.1666667, 0.1666667, 0.1666667, …\n$ POSTCODE                &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ MLR_RES                 &lt;dbl&gt; -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               &lt;dbl&gt; 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ y                       &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    &lt;dbl&gt; 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                &lt;dbl&gt; 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           &lt;dbl&gt; 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            &lt;dbl&gt; 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             &lt;dbl&gt; 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  &lt;dbl&gt; 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             &lt;dbl&gt; 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       &lt;dbl&gt; 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     &lt;dbl&gt; 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE &lt;dbl&gt; 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             &lt;dbl&gt; 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            &lt;dbl&gt; 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     &lt;dbl&gt; 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   &lt;dbl&gt; 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        &lt;dbl&gt; 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          &lt;dbl&gt; 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      &lt;dbl&gt; 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             &lt;dbl&gt; 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            &lt;dbl&gt; 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             &lt;dbl&gt; 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  &lt;dbl&gt; -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             &lt;dbl&gt; -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       &lt;dbl&gt; 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     &lt;dbl&gt; -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV &lt;dbl&gt; -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             &lt;dbl&gt; -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            &lt;dbl&gt; -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     &lt;dbl&gt; 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   &lt;dbl&gt; 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        &lt;dbl&gt; 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          &lt;dbl&gt; 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      &lt;dbl&gt; -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             &lt;dbl&gt; 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                &lt;dbl&gt; 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ geometry                &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n$ geometry.1              &lt;POINT [m]&gt; POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr_adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-local-r2",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-local-r2",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.5 Visualize Local R2",
    "text": "6.5 Visualize Local R2\nThe code chunk below creates an interactive point symbol map.\n\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\ntmap_options(check.and.fix = TRUE)\ntm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#generating-tidy-linear-regression-report",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#generating-tidy-linear-regression-report",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.1 Generating tidy linear regression report",
    "text": "4.1 Generating tidy linear regression report\n\nols_regress(condo_mlr)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     750537.537 \nR-Squared                    0.652       MSE                571262902261.223 \nAdj. R-Squared               0.647       Coef. Var                    43.160 \nPred R-Squared               0.637       AIC                       42971.173 \nMAE                     412117.987       SBC                       43081.835 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.515738e+15          19        7.977571e+13    139.648    0.0000 \nResidual      8.089083e+14        1416    571262902261.223                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     543071.420    136210.918                   3.987    0.000     275874.535     810268.305 \n            AREA_SQM      12688.669       370.119        0.579     34.283    0.000      11962.627      13414.710 \n                 AGE     -24566.001      2766.041       -0.166     -8.881    0.000     -29991.980     -19140.022 \n            PROX_CBD     -78121.985      6791.377       -0.267    -11.503    0.000     -91444.227     -64799.744 \n      PROX_CHILDCARE    -333219.036    111020.303       -0.087     -3.001    0.003    -551000.984    -115437.089 \n    PROX_ELDERLYCARE     170949.961     42110.748        0.083      4.060    0.000      88343.803     253556.120 \nPROX_URA_GROWTH_AREA      38507.622     12523.661        0.059      3.075    0.002      13940.700      63074.545 \n  PROX_HAWKER_MARKET      23801.197     29299.923        0.019      0.812    0.417     -33674.725      81277.120 \n   PROX_KINDERGARTEN     144097.972     82738.669        0.030      1.742    0.082     -18205.570     306401.514 \n            PROX_MRT    -322775.874     58528.079       -0.123     -5.515    0.000    -437586.937    -207964.811 \n           PROX_PARK     564487.876     66563.011        0.148      8.481    0.000     433915.162     695060.590 \n    PROX_PRIMARY_SCH     186170.524     65515.193        0.072      2.842    0.005      57653.253     314687.795 \nPROX_TOP_PRIMARY_SCH       -477.073     20597.972       -0.001     -0.023    0.982     -40882.894      39928.747 \n  PROX_SHOPPING_MALL    -207721.520     42855.500       -0.109     -4.847    0.000    -291788.613    -123654.427 \n    PROX_SUPERMARKET     -48074.679     77145.257       -0.012     -0.623    0.533    -199405.956     103256.599 \n       PROX_BUS_STOP     675755.044    138551.991        0.133      4.877    0.000     403965.817     947544.272 \n         NO_Of_UNITS       -216.180        90.302       -0.046     -2.394    0.017       -393.320        -39.040 \n     FAMILY_FRIENDLY     142128.272     47055.082        0.056      3.020    0.003      49823.107     234433.438 \n            FREEHOLD     300646.543     77296.529        0.117      3.890    0.000     149018.525     452274.561 \n      LEASEHOLD_99YR     -77137.375     77570.869       -0.030     -0.994    0.320    -229303.551      75028.801 \n-----------------------------------------------------------------------------------------------------------------\n\n\nThe output shows that the condo.mlr model can explain close to 65% of the variation in the price.\n\n4.1.1 Multicollinearity\n\nols_vif_tol(condo_mlr)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8601326 1.162611\n2                   AGE 0.7011585 1.426211\n3              PROX_CBD 0.4575471 2.185567\n4        PROX_CHILDCARE 0.2898233 3.450378\n5      PROX_ELDERLYCARE 0.5922238 1.688551\n6  PROX_URA_GROWTH_AREA 0.6614081 1.511926\n7    PROX_HAWKER_MARKET 0.4373874 2.286303\n8     PROX_KINDERGARTEN 0.8356793 1.196631\n9              PROX_MRT 0.4949877 2.020252\n10            PROX_PARK 0.8015728 1.247547\n11     PROX_PRIMARY_SCH 0.3823248 2.615577\n12 PROX_TOP_PRIMARY_SCH 0.4878620 2.049760\n13   PROX_SHOPPING_MALL 0.4903052 2.039546\n14     PROX_SUPERMARKET 0.6142127 1.628100\n15        PROX_BUS_STOP 0.3311024 3.020213\n16          NO_Of_UNITS 0.6543336 1.528272\n17      FAMILY_FRIENDLY 0.7191719 1.390488\n18             FREEHOLD 0.2728521 3.664990\n19       LEASEHOLD_99YR 0.2645988 3.779307\n\n\nThe result shows that no variable has VIF great than 5. Dummy variables will not affect the overall calibration a lot, that is why although FREEHOLD and LEASEHOLE_99YR have multicollinearity (as they are dummy variables derived from the same variable), their VIFs are still lower than 5.\n\n\n4.1.2 Variable Selection\n\ncondo_fw_mlr = ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE)\n\n\nplot(condo_fw_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-model-parameters",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-model-parameters",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.2 Visualize model parameters",
    "text": "4.2 Visualize model parameters\n\nggcoefstats(condo_mlr,\n            sort = \"ascending\")\n\nNumber of labels is greater than default palette color count.\n• Select another color `palette` (and/or `package`)."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#test-for-normality-assumption",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#test-for-normality-assumption",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "4.4 Test for Normality Assumption",
    "text": "4.4 Test for Normality Assumption\nThe code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo_fw_mlr$model)\n\n\n\n\n\n\n\n\nThe figure reveals that the residuals of the multiple linear regression model (i.e. condo_fw_mlr) resemble normal distribution.\nIf formal statistical test methods are preferred, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo_fw_mlr$model)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nAs the p-values of all 4 test are smaller than 0.05, we can reject the null hypothesis that the model resembles normal distribution and infer that the residuals are not normally distributed."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#spatial-stationary-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#spatial-stationary-test",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "5.1 Spatial stationary test",
    "text": "5.1 Spatial stationary test\nThe Moran’s I test will be performed to confirm our observations with the following hypothesis:\nHo: The residuals are randomly distributed (also known as spatial stationary).\nH1: The residuals are spatially non-stationary.\nFirst, we compute the adaptive distance-based weight matrix using st_knn() and st_weights() function of sfdep.\n\ncondo_resale_sf = condo_resale_sf |&gt;\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nset.seed(1234)\nglobal_moran_perm(condo_resale_sf$MLR_RES,\n                  condo_resale_sf$nb,\n                  condo_resale_sf$wt,\n                  alternative = \"two.sided\",\n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nAs the p-value is smaller than 0.05, we can reject the null hypothesis that the residuals are randomly distributed. Since the Moran I’s statistic = 0.32254 &gt; 0, we can infer that the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#build-fixed-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#build-fixed-bandwidth-gwr-model",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.1 Build Fixed Bandwidth GWR model",
    "text": "6.1 Build Fixed Bandwidth GWR model\nIn the code chunk below, the bw.gwr() function from the GWModel package is used to determine the optimal fixed bandwidth for the model. The adaptive argument is set to FALSE, indicating that we are computing the fixed bandwidth.\nThere are two approaches to determine the stopping rule: the CV cross-validation approach and the AIC corrected (AICc) approach. We will define the stopping rule using the approach argument.\n\nbw_fixed &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                     PROX_CBD + PROX_CHILDCARE + \n                     PROX_ELDERLYCARE   + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                     NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale_sf, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwith is 971.3405 metres.\n\n6.1.1 GWModel method - fixed bandwidth\nThe code chunk below is uised to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr_fixed &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + \n                         AGE    + PROX_CBD + PROX_CHILDCARE + \n                         PROX_ELDERLYCARE   +PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH +\n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                         NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale_sf, \n                       bw=bw_fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class gwrm. The code below displays the model output.\n\ngwr_fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 11:11:40.416682 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 11:11:41.962001 \n\n\nThe output shows that the adjust R-square improve quite a lot to 84.3% compared to the global model (64.7%). The AICc of the gwr is 42263.61, which is also significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#build-adaptive-bandwith-gwr-model",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#build-adaptive-bandwith-gwr-model",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.2 Build adaptive bandwith GWR model",
    "text": "6.2 Build adaptive bandwith GWR model\nIn this section, we will calibrate the gwr-based hedonic pricing model using adaptive bandwidth approach.\n\n6.2.1 Compute the adaptive bandwidth\nSimilar to the earlier section, we first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw_adaptive &lt;- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale_sf, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that 30 is the recommended data points to be used.\n\n\n6.2.2 Construct the adaptive bandwidth gwr model\nNow, we can calibrate the gwr-based hedonic pricing model using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale_sf, \n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below displays the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-15 11:11:49.82608 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale_sf, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  &lt; 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  &lt; 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  &lt; 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  &lt; 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2024-10-15 11:11:51.028385 \n\n\nThe output shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-gwr-output",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-gwr-output",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.3 Visualize GWR Output",
    "text": "6.3 Visualize GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted yyy values, condition number, local R2, residuals, and coefficients with standard errors:\n\nCondition Number: This diagnostic assesses local collinearity. High condition numbers (greater than 30) indicate strong local collinearity, leading to unstable results.\nLocal R2: Ranging from 0.0 to 1.0, these values reflect how well the local regression model fits the observed y values. Low R2 values suggest poor model performance. Mapping Local R2 can highlight areas where GWR predictions are strong or weak, potentially indicating missing important variables.\nPredicted Values: These are the estimated y values computed by GWR.\nResiduals: Calculated by subtracting fitted y values from observed y values. Standardized residuals should have a mean of zero and a standard deviation of one. A rendered map of standardized residuals can visually represent these values.\nCoefficient Standard Error: This measures the reliability of each coefficient estimate. Smaller standard errors relative to the coefficient values indicate greater confidence, while larger standard errors may suggest local collinearity issues.\n\nAll these metrics are stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y values, predicted values, coefficient standard errors, and t-values in the “data” slot of an object called SDF of the output list."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-coefficient-estimates",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualize-coefficient-estimates",
    "title": "In-class Exercise 7: Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "6.6 Visualize coefficient estimates",
    "text": "6.6 Visualize coefficient estimates\nThe code chunks below creates an interactive point symbol map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nAREA_SQM_SE &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV &lt;- tm_shape(mpsz)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(gwr_sf_adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape mpsz is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\n6.6.1 By URA Planning Region\n\ntm_shape(mpsz[mpsz$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(gwr_sf_adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)\n\nWarning: The shape mpsz[mpsz$REGION_N == \"CENTRAL REGION\", ] is invalid. See\nsf::st_is_valid"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modeling uses statistical or machine learning techniques to forecast outcomes, typically for future events. It relies on known outcomes and predictors (variables) to calibrate models.\nGeospatial predictive modeling is based on the idea that event occurrences are not uniformly or randomly distributed in space. Geospatial factors, such as infrastructure, sociocultural elements, and topography, influence where events happen. This type of modeling seeks to describe these constraints by spatially correlating historical event locations with environmental factors.\n\n\nIn this exercise, we’ll explore how to build a predictive model using the geographical random forest method. By the end of the exercise, you will be able to:\n\nPrepare training and test datasets using appropriate sampling methods.\nCalibrate predictive models using geospatial statistical and machine learning techniques.\nCompare and select the best model for predicting future outcomes.\nPredict future outcomes using the best-calibrated model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#objective",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#objective",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "In this exercise, we’ll explore how to build a predictive model using the geographical random forest method. By the end of the exercise, you will be able to:\n\nPrepare training and test datasets using appropriate sampling methods.\nCalibrate predictive models using geospatial statistical and machine learning techniques.\nCompare and select the best model for predicting future outcomes.\nPredict future outcomes using the best-calibrated model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#install-and-load-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#install-and-load-r-packages",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.1 Install and Load R packages",
    "text": "2.1 Install and Load R packages\nThe below code chunk performs these tasks:\n\nCreates a list (packages) of all required R packages.\nChecks if each package is installed and installs missing ones.\nLoads the installed packages into the environment.\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#read-data-file-from-rds",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#read-data-file-from-rds",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "3.1 Read data file from rds",
    "text": "3.1 Read data file from rds\nThe below code chunk reads data from rds file and store in mdata as simple feature dataframe.\n\nmdata &lt;- read_rds(\"data/mdata.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-sampling",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#data-sampling",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "3.2 Data Sampling",
    "text": "3.2 Data Sampling\nThe data is split into train and test data sets with with size of 65% and 35% respectively using initial_split() of rsample package. rsample is one of the package from tigymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/train_data.rds\")\nwrite_rds(test_data, \"data/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-the-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-the-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.1 Convert the sf data.frame to SpatialPointDataFrame",
    "text": "7.1 Convert the sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-adaptive-bandwidth",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.2 Compute adaptive bandwidth",
    "text": "7.2 Compute adaptive bandwidth\nNext, bw.gwr() of GWmodel package will be used to determine the optimal adaptive bandwidth to be used. The code chunk below uses CV approach to determine the optimal bandwidth.\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nThe result shows that 40 neighbour points is the optimal adaptive bandwidth to be used for this data set.\n\nwrite_rds(bw_adaptive, \"data/bw_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#construct-the-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#construct-the-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.3 Construct the adaptive bandwidth gwr model",
    "text": "7.3 Construct the adaptive bandwidth gwr model\nFirst we call the save bandwidth using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/bw_adaptive.rds\")\n\nNow, we go ahead to calibrate the gwr-based hedonic pricing model using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nNext the model is saved in rds format for future use.\n\nwrite_rds(gwr_adaptive, \"data/gwr_adaptive.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#retrieve-gwr-output-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#retrieve-gwr-output-object",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.4 Retrieve gwr output object",
    "text": "7.4 Retrieve gwr output object\nThe code chunk below retrieves the save gwr model object.\n\ngwr_adaptive &lt;- read_rds(\"data/gwr_adaptive.rds\")\n\nThe model output can be displayed using below code.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-18 14:16:00.628634 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2478e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2195e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1632e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1823e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2411e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5188e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0231e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.9 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209.1 \n   Residual sum of squares: 4.829191e+12 \n   R-square value:  0.967657 \n   Adjusted R-square value:  0.9611534 \n\n   ***********************************************************************\n   Program stops at: 2024-10-18 14:16:50.275885"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#convert-the-test-data-from-sf-data.frame-to-spatialpointdataframe",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.5 Convert the test data from sf data.frame to SpatialPointDataFrame",
    "text": "7.5 Convert the test data from sf data.frame to SpatialPointDataFrame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-adaptive-bandwidth-for-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-adaptive-bandwidth-for-the-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.6 Compute adaptive bandwidth for the test data",
    "text": "7.6 Compute adaptive bandwidth for the test data\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-predicted-values-of-the-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#compute-predicted-values-of-the-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "7.7 Compute predicted values of the test data",
    "text": "7.7 Compute predicted values of the test data\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw = bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extract-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#extract-coordinates-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.1 Extract coordinates data",
    "text": "8.1 Extract coordinates data\nThe code chunk below extracts the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nWe write all the output into rds for future use.\n\ncoords_train &lt;- write_rds(coords_train, \"data/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/coords_test.rds\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drop-geometry-field",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drop-geometry-field",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "8.2 Drop geometry field",
    "text": "8.2 Drop geometry field\nFirst, we drop the geometry column of the sf data.frame using st_drop_geometry() of sf package.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#predict-using-test-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#predict-using-test-data",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.1 Predict using Test Data",
    "text": "10.1 Predict using Test Data\n\n10.1.1 Prepare the test data\nThe code chunk combines the test data with its corresponding coordinates data.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n10.1.2 Predict with test data\nNext, predict.grf() of spatialML package is used to predict the resale value using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\nBefore moving on, we save the output into rds file for future usage.\n\nGRF_pred &lt;- write_rds(gwRF_pred, \"data/GRF_pred.rds\")\n\n\n\n10.1.3 Convert the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is more efficient to convert it into a data frame for further visualisation and analysis.\n\nGRF_pred &lt;- read_rds(\"data/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(GRF_pred)\n\nNext cbind() is used to append the predicted values onto test_data.\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/test_data_p.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calculate-root-mean-square-error",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#calculate-root-mean-square-error",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.2 Calculate Root Mean Square Error",
    "text": "10.2 Calculate Root Mean Square Error\nThe root mean square error (RMSE) quantifies the average difference between predicted and observed values in regression analysis. The following code chunk uses the rmse() function from Metrics package to calculate RMSE.\n\nrmse(test_data_p$resale_price, \n     test_data_p$GRF_pred)\n\n[1] 27302.9"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualize-the-predicted-values",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualize-the-predicted-values",
    "title": "Hands-on Exercise 8: Geographically Weighted Predictive Models",
    "section": "10.3 Visualize the predicted values",
    "text": "10.3 Visualize the predicted values\nScatterplot can be used to visualise the actual resale price and the predicted resale price using the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = GRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNote: A good predictive model should have the scatter points close to the diagonal line. The scatter plot can be also used to detect if any outlier presents in the model."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "",
    "text": "pacman::p_load(sf, spdep, GWmodel, SpatialML, tmap, rsample, Metrics, tidyverse, knitr,kableExtra)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#read-data-file-from-rds",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#read-data-file-from-rds",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.1 Read data file from rds",
    "text": "2.1 Read data file from rds\nThe below code chunk reads data from rds file and store in mdata as simple feature dataframe.\n\nmdata &lt;- read_rds(\"data/mdata.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.2 Data Sampling",
    "text": "2.2 Data Sampling\nThe data is split into train and test data sets with with size of 65% and 35% respectively using initial_split() of rsample package. rsample is one of the package from tidymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\nWe write the data to rds format.\n\nwrite_rds(train_data, \"data/train_data.rds\")\nwrite_rds(test_data, \"data/test_data.rds\")\n\nRead the data from rds format.\n\ntrain_data &lt;- read_rds(\"data/train_data.rds\")\ntest_data &lt;- read_rds(\"data/test_data.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.2 Multicollinearity Check",
    "text": "2.2 Multicollinearity Check\nIt is a good practice to use correlation matrix to examine if there is sign of multicollinearity before loading the predictors into a predictive model.\n\nmdata_nogeo = mdata |&gt;\n  st_drop_geometry()\nggstatsplot::ggcorrmat(mdata_nogeo[,2:17])"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check-with-vif",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#multicollinearity-check-with-vif",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "3.1 Multicollinearity check with VIF",
    "text": "3.1 Multicollinearity check with VIF\n\n3.1.1 VIF Table\n\nvif = performance::check_collinearity(price_mlr)\nkable(vif,\n      caption = \"Variance Inflator Factor (VIF) Results\") |&gt;\n  kable_styling(font_size = 10)\n\n\nVariance Inflator Factor (VIF) Results\n\n\nTerm\nVIF\nVIF_CI_low\nVIF_CI_high\nSE_factor\nTolerance\nTolerance_CI_low\nTolerance_CI_high\n\n\n\n\nfloor_area_sqm\n1.151407\n1.089081\n1.257341\n1.073036\n0.8685025\n0.7953289\n0.9182057\n\n\nstorey_order\n1.214342\n1.142122\n1.323261\n1.101972\n0.8234911\n0.7557088\n0.8755630\n\n\nremaining_lease_mths\n1.350011\n1.259448\n1.472187\n1.161900\n0.7407345\n0.6792616\n0.7939987\n\n\nPROX_CBD\n1.881970\n1.727036\n2.069921\n1.371849\n0.5313581\n0.4831102\n0.5790269\n\n\nPROX_ELDERLYCARE\n1.143973\n1.082945\n1.249905\n1.069567\n0.8741464\n0.8000608\n0.9234082\n\n\nPROX_HAWKER\n1.185396\n1.117532\n1.292447\n1.088759\n0.8435996\n0.7737259\n0.8948292\n\n\nPROX_MRT\n1.206165\n1.135149\n1.314495\n1.098255\n0.8290742\n0.7607483\n0.8809413\n\n\nPROX_PARK\n1.193096\n1.124046\n1.300581\n1.092289\n0.8381557\n0.7688872\n0.8896430\n\n\nPROX_MALL\n1.436647\n1.335177\n1.568835\n1.198602\n0.6960652\n0.6374157\n0.7489641\n\n\nPROX_SUPERMARKET\n1.222273\n1.148901\n1.331800\n1.105565\n0.8181476\n0.7508635\n0.8703968\n\n\nWITHIN_350M_KINDERGARTEN\n1.132339\n1.073426\n1.238522\n1.064114\n0.8831275\n0.8074138\n0.9315967\n\n\nWITHIN_350M_CHILDCARE\n1.387186\n1.291898\n1.513579\n1.177788\n0.7208840\n0.6606856\n0.7740549\n\n\nWITHIN_350M_BUS\n1.192068\n1.123176\n1.299493\n1.091819\n0.8388780\n0.7695311\n0.8903325\n\n\nWITHIN_1KM_PRISCH\n1.510863\n1.400273\n1.652008\n1.229172\n0.6618734\n0.6053239\n0.7141467\n\n\n\n\n\n\n\n\n\n3.1.2 VIF Plot\n\nplot(vif) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nVariable `Component` is not in your data frame :/"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#compute-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#compute-adaptive-bandwidth",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.1 Compute adaptive bandwidth",
    "text": "4.1 Compute adaptive bandwidth\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 610 CV score: 3.396927e+12 \nAdaptive bandwidth: 385 CV score: 3.174206e+12 \nAdaptive bandwidth: 245 CV score: 2.869e+12 \nAdaptive bandwidth: 159 CV score: 2.565794e+12 \nAdaptive bandwidth: 105 CV score: 2.214738e+12 \nAdaptive bandwidth: 72 CV score: 1.950172e+12 \nAdaptive bandwidth: 51 CV score: 1.778792e+12 \nAdaptive bandwidth: 39 CV score: 1.661084e+12 \nAdaptive bandwidth: 30 CV score: 1.568725e+12 \nAdaptive bandwidth: 26 CV score: 1.548313e+12 \nAdaptive bandwidth: 22 CV score: 1.538462e+12 \nAdaptive bandwidth: 21 CV score: 1.523028e+12 \nAdaptive bandwidth: 19 CV score: 1.512568e+12 \nAdaptive bandwidth: 19 CV score: 1.512568e+12 \n\n\n\nbw_adaptive\n\n[1] 19\n\n\nThe result shows that 19 neighbour points is the optimal adaptive bandwidth to be used for this data set.\n\nwrite_rds(bw_adaptive, \"data/bw_adaptive.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#construct-the-adaptive-bandwidth-gwr-model",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#construct-the-adaptive-bandwidth-gwr-model",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.2 Construct the adaptive bandwidth gwr model",
    "text": "4.2 Construct the adaptive bandwidth gwr model\nFirst we call the save bandwidth using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/bw_adaptive.rds\")\n\nNow, we go ahead to calibrate the gwr-based hedonic pricing model using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nThe model result is as below.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-31 20:47:02.273628 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 975\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-167207  -37824    -238   34255  225584 \n\n   Coefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              114172.89   34962.31   3.266 0.001131 ** \n   floor_area_sqm             2777.54     296.47   9.369  &lt; 2e-16 ***\n   storey_order              12752.37    1088.20  11.719  &lt; 2e-16 ***\n   remaining_lease_mths        349.53      14.91  23.442  &lt; 2e-16 ***\n   PROX_CBD                 -16227.90     641.72 -25.288  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -10941.60    3272.30  -3.344 0.000859 ***\n   PROX_HAWKER              -19593.07    4079.93  -4.802 1.82e-06 ***\n   PROX_MRT                 -39890.18    5465.55  -7.298 6.10e-13 ***\n   PROX_PARK                -15142.07    4697.20  -3.224 0.001308 ** \n   PROX_MALL                -14453.47    6518.98  -2.217 0.026847 *  \n   PROX_SUPERMARKET         -17056.10   13703.69  -1.245 0.213569    \n   WITHIN_350M_KINDERGARTEN   8899.14    2066.84   4.306 1.84e-05 ***\n   WITHIN_350M_CHILDCARE     -1558.56    1195.89  -1.303 0.192796    \n   WITHIN_350M_BUS            -540.34     747.34  -0.723 0.469842    \n   WITHIN_1KM_PRISCH        -10529.56    1579.19  -6.668 4.38e-11 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61510 on 960 degrees of freedom\n   Multiple R-squared: 0.7389\n   Adjusted R-squared: 0.7351 \n   F-statistic: 194.1 on 14 and 960 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.632074e+12\n   Sigma(hat): 61097.14\n   AIC:  24286.36\n   AICc:  24286.93\n   BIC:  23499.6\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 19 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -1863475.57  -212514.91     5601.15   245291.24\n   floor_area_sqm              -4400.58     1177.77     2045.27     3344.75\n   storey_order                 3138.23     8074.15    10578.11    13835.86\n   remaining_lease_mths         -567.87      346.52      426.05      503.37\n   PROX_CBD                   -81354.37   -23497.13   -10946.60    -1279.01\n   PROX_ELDERLYCARE          -262405.86   -23077.81    -5490.80    17533.13\n   PROX_HAWKER               -225301.62   -36521.56   -10558.54    20145.23\n   PROX_MRT                  -305062.32   -90849.20   -55778.06   -20478.31\n   PROX_PARK                 -257739.81   -32859.80   -15051.91     8565.74\n   PROX_MALL                 -274223.21   -36280.73     3682.06    49856.21\n   PROX_SUPERMARKET          -176209.93   -45157.90    -5420.26    30645.48\n   WITHIN_350M_KINDERGARTEN   -43330.60    -9582.09    -2482.36     5469.75\n   WITHIN_350M_CHILDCARE      -15807.60    -2525.30     1294.72     3234.90\n   WITHIN_350M_BUS             -9134.82    -1825.47      331.29     2176.76\n   WITHIN_1KM_PRISCH          -54170.21    -3571.71      512.00     4646.67\n                                  Max.\n   Intercept                1668279.80\n   floor_area_sqm              7814.05\n   storey_order               26308.30\n   remaining_lease_mths         716.27\n   PROX_CBD                  131063.39\n   PROX_ELDERLYCARE          179454.03\n   PROX_HAWKER               146976.72\n   PROX_MRT                  126271.79\n   PROX_PARK                  96580.81\n   PROX_MALL                 342520.41\n   PROX_SUPERMARKET          177471.19\n   WITHIN_350M_KINDERGARTEN   40409.87\n   WITHIN_350M_CHILDCARE      15476.12\n   WITHIN_350M_BUS            11155.18\n   WITHIN_1KM_PRISCH          32922.16\n   ************************Diagnostic information*************************\n   Number of data points: 975 \n   Effective number of parameters (2trace(S) - trace(S'S)): 409.2118 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 565.7882 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 23520.23 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 22826.57 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 23824.92 \n   Residual sum of squares: 595314539646 \n   R-square value:  0.9572056 \n   Adjusted R-square value:  0.9261993 \n\n   ***********************************************************************\n   Program stops at: 2024-10-31 20:47:02.609367 \n\n\nNext the model is saved in rds format for future use.\n\nwrite_rds(gwr_adaptive, \"data/gwr_adaptive.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#retrieve-gwr-output-object",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#retrieve-gwr-output-object",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.3 Retrieve gwr output object",
    "text": "4.3 Retrieve gwr output object\nThe code chunk below retrieves the save gwr model object.\n\ngwr_adaptive &lt;- read_rds(\"data/gwr_adaptive.rds\")\n\nThe model output can be displayed using below code.\n\ngwr_adaptive"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predict-with-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predict-with-test-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "4.4 Predict with Test Data",
    "text": "4.4 Predict with Test Data\n\n4.4.1 Test Data bw\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nAdaptive bandwidth: 332 CV score: 1.808831e+12 \nAdaptive bandwidth: 213 CV score: 1.680658e+12 \nAdaptive bandwidth: 139 CV score: 1.487342e+12 \nAdaptive bandwidth: 93 CV score: 1.327673e+12 \nAdaptive bandwidth: 65 CV score: 1.150371e+12 \nAdaptive bandwidth: 47 CV score: 1.023446e+12 \nAdaptive bandwidth: 36 CV score: 901695754647 \nAdaptive bandwidth: 29 CV score: 869852523865 \nAdaptive bandwidth: 25 CV score: 863464583366 \nAdaptive bandwidth: 22 CV score: 855145692336 \nAdaptive bandwidth: 20 CV score: 8.39443e+11 \nAdaptive bandwidth: 19 CV score: 8.35764e+11 \nAdaptive bandwidth: 18 CV score: 837955316896 \nAdaptive bandwidth: 19 CV score: 8.35764e+11 \n\n\n\n\n4.4.2 Predict with test data\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data, \n                        predictdata = test_data, \n                        bw=bw_adaptive, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#prepare-coordinates-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#prepare-coordinates-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.1 Prepare Coordinates data",
    "text": "5.1 Prepare Coordinates data\nThe code chunk below extracts the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nWe write all the output into rds for future use.\n\ncoords_train &lt;- write_rds(coords_train, \"data/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/coords_test.rds\" )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#drop-geometry-field",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#drop-geometry-field",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.2 Drop Geometry field",
    "text": "5.2 Drop Geometry field\nFirst, we drop the geometry column of the sf data.frame using st_drop_geometry() of sf package as ranger() function require tible dataframe.\n\ntrain_data_nogeom &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrate-random-forest-model",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrate-random-forest-model",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.3 Calibrate Random Forest model",
    "text": "5.3 Calibrate Random Forest model\nWe calibrate a model to predict HDB resale price using random forest function of ranger package.\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data_nogeom)\n\nModel output\n\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       2313484641 \nR squared (OOB):                  0.8380181 \n\n\n\nwrite_rds(rf, \"data/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/rf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrate-with-grf",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#calibrate-with-grf",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.4 Calibrate with grf()",
    "text": "5.4 Calibrate with grf()\nIn this section, we explore how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data_nogeom, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\n\nNumber of Observations: 975\n\n\nNumber of Independent Variables: 14\n\n\nKernel: Adaptive\nNeightbours: 55\n\n\n\n--------------- Global ML Model Summary ---------------\n\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data_nogeom, num.trees = 500, mtry = 4, importance = \"impurity\",      num.threads = NULL) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      975 \nNumber of independent variables:  14 \nMtry:                             4 \nTarget node size:                 5 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       2112956167 \nR squared (OOB):                  0.8520584 \n\n\n\nImportance:\n\n\n          floor_area_sqm             storey_order     remaining_lease_mths \n            7.014621e+11             1.472727e+12             2.368021e+12 \n                PROX_CBD         PROX_ELDERLYCARE              PROX_HAWKER \n            4.516177e+12             5.035574e+11             6.351735e+11 \n                PROX_MRT                PROX_PARK                PROX_MALL \n            7.926518e+11             5.292538e+11             4.432979e+11 \n        PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN    WITHIN_350M_CHILDCARE \n            3.705109e+11             1.128608e+11             2.219549e+11 \n         WITHIN_350M_BUS        WITHIN_1KM_PRISCH \n            2.189088e+11             7.361648e+11 \n\n\n\nMean Square Error (Not OOB): 404387373.973\n\n\nR-squared (Not OOB) %: 97.166\n\n\nAIC (Not OOB): 19352.437\n\n\nAICc (Not OOB): 19352.937\n\n\n\n--------------- Local Model Summary ---------------\n\n\n\nResiduals OOB:\n\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-244730.6  -21894.3   -1486.0    -147.8   20203.9  272305.6 \n\n\n\nResiduals Predicted (Not OOB):\n\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-39989.0  -3523.0   -235.4   -115.9   2820.4  49785.4 \n\n\n\nLocal Variable Importance:\n\n\n                                Min          Max         Mean          StD\nfloor_area_sqm            696919686 171359696724  24585231938  31054898436\nstorey_order              556286378 336284813866  29111637645  53940346777\nremaining_lease_mths     5015621769 662431581470 102796953916 142322738014\nPROX_CBD                  969645111 333574144319  32398603460  51529843423\nPROX_ELDERLYCARE         1885669191 133808777431  23022318538  24756166362\nPROX_HAWKER              1054538821 197323237741  21225513496  25502913522\nPROX_MRT                 1230399011 268171063212  28859762449  46296774533\nPROX_PARK                1001025148 178811098249  19686271129  20914300056\nPROX_MALL                1463394653 260061426721  27018175100  39644748521\nPROX_SUPERMARKET          919432669 168565348890  19481442490  27618922136\nWITHIN_350M_KINDERGARTEN  190947575  43671284878   5500713976   6598985175\nWITHIN_350M_CHILDCARE     386573451 178795505651  19080750625  34710094711\nWITHIN_350M_BUS           641999519 139202195056   8908180301  11083301899\nWITHIN_1KM_PRISCH         232944521  62733693084   6845346956   8828863011\n\n\n\nMean squared error (OOB): 2109345256.436\n\n\nR-squared (OOB) %: 85.216\n\n\nAIC (OOB): 20962.902\n\n\nAICc (OOB): 20963.403\n\n\nMean squared error Predicted (Not OOB): 52672246.874\n\n\nR-squared Predicted (Not OOB) %: 99.631\n\n\nAIC Predicted (Not OOB): 17365.109\n\n\nAICc Predicted (Not OOB): 17365.61\n\n\n\nCalculation time (in seconds): 29.6244\n\n\nThe model output is saved into rds format using the below code chunk.\n\nwrite_rds(gwRF_adaptive, \"data/gwRF_adaptive.rds\")\n\nThe below code chunk retrieves the saved model.\n\ngwRF_adaptive &lt;- read_rds(\"data/gwRF_adaptive.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predict-using-the-test-data",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#predict-using-the-test-data",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.5 Predict using the test data",
    "text": "5.5 Predict using the test data\n\n5.5.1 Prepare the test data\nThe code chunk combines the test data with its corresponding coordinates data.\n\ntest_data_nogeom &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\n5.5.2 Predict with the test data\nNext, predict.grf() of spatialML package is used to predict the resale value using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_nogeom, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\n\n\n5.5.3 Convert the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is more efficient to convert it into a data frame for further visualisation and analysis.\n\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\nNext cbind() is used to append the predicted values onto test_data.\n\ntest_data_pred &lt;- cbind(test_data, \n                        GRF_pred_df)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualiza-the-predicted-values",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#visualiza-the-predicted-values",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "5.6 Visualiza the predicted values",
    "text": "5.6 Visualiza the predicted values\n\nggplot(data = test_data_pred,\n       aes(x = gwRF_pred,\n           y = resale_price)) +\n  geom_point()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/Prepare_HDB_data.html",
    "href": "In-class_Ex/In-class_Ex08/Prepare_HDB_data.html",
    "title": "Take-home Exercise 3: Preparing HDB data for Geographically Weighted Predictive Model",
    "section": "",
    "text": "1 Import R Packages\n\npacman::p_load(tidyverse, sf, httr, jsonlite, rvest)\n\n\nrvest: use for web crawling\njsonlite: to convert json file to dataframe format\ntidyverse & sf: further data manipulation\n\n\n\n2 Import the Data\nFirst we load in the Resale data from January 2023 to September 2024.\n\nresale &lt;- read_csv(\"data/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nRows: 192234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nWe narrow down the data scope to load into Onemap API later.\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\nNext we extract the list of unique addresses from resale_selected. The list is sorted to ensure the first address is always picked up.\n\nadd_list &lt;- sort(unique(resale_selected$address))\n\nThe below function read in any address list and record the coordinates of the parsed addresses.\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n    # as the API provided code for 1 address search at a time only, for pasrsing a list of addresses we use the common/elastic/search syntax as below\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nWe run the get_coords function on the add_list.\n\ncoords &lt;- get_coords(add_list)\n\n\nwrite_rds(coords, \"data/rds/coords.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "",
    "text": "In this hands-on exercise, we’ll explore how to model geographical accessibility using R’s geospatial analysis packages.\nBy the end of this exercise, you’ll be able to:\n\nImport GIS polygon data into R and save it as a simple feature data frame with functions from the sf package.\nImport aspatial data into R and similarly save it as a simple feature data frame with sf functions.\nCompute accessibility measures using Hansen’s potential model and the Spatial Accessibility Measure (SAM).\nVisualize accessibility measures with the tmap and ggplot2 packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#import-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#import-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.1 Import geospatial data",
    "text": "4.1 Import geospatial data\nWe will import three geospatial data sets from the data/geospatial sub-folder: MP14_SUBZONE_NO_SEA_PL, hexagons, and ELDERCARE. The code chunk below imports these shapefiles using the st_read() function from the sf package.\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_NO_SEA_PL\")\n\nReading layer `MP14_SUBZONE_NO_SEA_PL' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nhexagons &lt;- st_read(dsn = \"data/geospatial\", layer = \"hexagons\") \n\nReading layer `hexagons' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3125 features and 6 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 21506.33 xmax: 50010.26 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\n\n\n\neldercare &lt;- st_read(dsn = \"data/geospatial\", layer = \"ELDERCARE\") \n\nReading layer `ELDERCARE' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex09\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 120 features and 19 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21 / Singapore TM\n\n\nThe report indicates that the R object containing the imported MP14_SUBZONE_WEB_PL shapefile is named mpsz. It is a simple feature object with geometry type multipolygon. It is important to note that the mpsz simple feature object lacks EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#update-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#update-crs-information",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.2 Update CRS information",
    "text": "4.2 Update CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz &lt;- st_transform(mpsz, 3414)\neldercare &lt;- st_transform(eldercare, 3414)\nhexagons &lt;- st_transform(hexagons, 3414)\n\nAfter transforming the projection metadata, we can verify the projection of the newly transformed mpsz_svy21 using st_crs() of sf package as in below code chunk.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG is indicated as 3414 now."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#clean-and-update-attribute-fields-of-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#clean-and-update-attribute-fields-of-the-geospatial-data",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "4.3 Clean and Update attribute fields of the geospatial data",
    "text": "4.3 Clean and Update attribute fields of the geospatial data\nMany redundant fields exist in both data tables eldercare and hexagons. The code chunks below excludes these redundant fields while adding two new fields: demand to the hexagons data table and capacity to the eldercare simple feature data frame. Both fields will be derived using the mutate() function from the dplyr package.\n\neldercare &lt;- eldercare %&gt;%\n  select(fid, ADDRESSPOS) %&gt;%\n  mutate(capacity = 100)\n\n\nhexagons &lt;- hexagons %&gt;%\n  select(fid) %&gt;%\n  mutate(demand = 100)\n\nFor this hands-on exercise, a constant value of 100 is used for both the capacity and demand fields. In practice, actual demand for the hexagons and capacity for the eldercare centers should be applied."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#import-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#import-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.1 Import distance matrix",
    "text": "5.1 Import distance matrix\nThe code chunk below uses read_cvs() of readr package to import OD_Matrix.csv into RStudio as a tibble data.frame called ODMatrix.\n\nODMatrix &lt;- read_csv(\"data/aspatial/OD_Matrix.csv\", skip = 0)\n\nRows: 375000 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (6): origin_id, destination_id, entry_cost, network_cost, exit_cost, tot...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#tidy-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#tidy-distance-matrix",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "5.2 Tidy distance matrix",
    "text": "5.2 Tidy distance matrix\nThe imported ODMatrix organised the distance matrix columnwise.\n\nhead(ODMatrix)\n\n# A tibble: 6 × 6\n  origin_id destination_id entry_cost network_cost exit_cost total_cost\n      &lt;dbl&gt;          &lt;dbl&gt;      &lt;dbl&gt;        &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1         1              1       668.       19847.      47.6     20562.\n2         1              2       668.       45027.      31.9     45727.\n3         1              3       668.       17644.     173.      18486.\n4         1              4       668.       36010.      92.2     36770.\n5         1              5       668.       31068.      64.6     31801.\n6         1              6       668.       31195.     117.      31980.\n\n\nHowever, most of the modelling packages in R is expecting a matrix look similar to the figure below.\n\nThe rows represent origins (also know as from field) and the columns represent destination (i.e. also known as to field.). The pivot_wider() function from the tidyr package was used to transform the O-D matrix from a long format to a wide format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  pivot_wider(names_from = destination_id, values_from = total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nAs SVY21 projected coordinate system is used, the distance is measured in metre. The code chunk below converta the unit measurement from metre to kilometre.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.1 Compute Hansen’s accessibility",
    "text": "6.1 Compute Hansen’s accessibility\nNow we are ready to compute Hansen’s accessibility using the ac() function from the SpatialAcc package. Before proceeding, it’s advisable to review the function’s arguments at least once to ensure that all required inputs are available.\nThe code chunk below calculates Hansen’s accessibility, using ac() from the SpatialAcc package, and saves the output in a data frame called acc_Hansen using the data.frame() function.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\n\nhead(acc_Hansen)\n\n  ac.hexagons.demand..eldercare.capacity..distmat_km..power...2..\n1                                                    1.648313e-14\n2                                                    1.096143e-16\n3                                                    3.865857e-17\n4                                                    1.482856e-17\n5                                                    1.051348e-17\n6                                                    5.076391e-18\n\n\nThe default field name is messy, we rename it to accHansen using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nNotice that the field name is much more tidy now.\n\nhead(acc_Hansen)\n\n     accHansen\n1 1.648313e-14\n2 1.096143e-16\n3 3.865857e-17\n4 1.482856e-17\n5 1.051348e-17\n6 5.076391e-18\n\n\nNext, we convert the data table into tibble format by using the code chunk below.\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nLastly, bind_cols() of dplyr is used to join the acc_Hansen tibble data frame with the hexagons simple feature data frame. The output is saved in hexagon_Hansen.\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)\n\nNotice that hexagon_Hansen is a simple feature data frame and not a tibble data frame.\n\nhead(hexagon_Hansen)\n\nSimple feature collection with 6 features and 3 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 22756.33 xmax: 3244.888 ymax: 27756.33\nProjected CRS: SVY21 / Singapore TM\n  fid demand    accHansen                       geometry\n1   1    100 1.648313e-14 POLYGON ((2667.538 27506.33...\n2   2    100 1.096143e-16 POLYGON ((2667.538 25006.33...\n3   3    100 3.865857e-17 POLYGON ((2667.538 24506.33...\n4   4    100 1.482856e-17 POLYGON ((2667.538 24006.33...\n5   5    100 1.051348e-17 POLYGON ((2667.538 23506.33...\n6   6    100 5.076391e-18 POLYGON ((2667.538 23006.33...\n\n\nThe steps above can be perform using a single code chunk as below.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 0.5, \n                            family = \"Hansen\"))\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\nacc_Hansen &lt;- as_tibble(acc_Hansen)\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-hansens-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-hansens-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.2 Visualize Hansen’s accessibility",
    "text": "6.2 Visualize Hansen’s accessibility\n\n6.2.1 Extract map extend\nFirst we extract the extend of hexagons simple feature data frame by using st_bbox() of sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "6.3 Statistical graphic visualisation",
    "text": "6.3 Statistical graphic visualisation\nIn this section, we will compare the distribution of Hansen’s accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_Hansen simple feature data frame using the code chunk below.\n\nhexagon_Hansen &lt;- st_join(hexagon_Hansen, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot graphical method.\n\nggplot(data=hexagon_Hansen, \n       aes(y = log(accHansen), \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.1 Compute KD2SFCA’s accessibility",
    "text": "7.1 Compute KD2SFCA’s accessibility\nIn this section, we will repeat most of the steps used in the previous section to conduct the analysis, with some code combined into a single code chunk.\nThe code chunk below calculates Hansen’s accessibility using the ac() function from the SpatialAcc package, and the output is saved in a data frame called acc_KD2SFCA. Note that KD2SFCA is specified for the family argument.\n\nacc_KD2SFCA &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            d0 = 50,\n                            power = 2, \n                            family = \"KD2SFCA\"))\n\ncolnames(acc_KD2SFCA) &lt;- \"accKD2SFCA\"\nacc_KD2SFCA &lt;- as_tibble(acc_KD2SFCA)\nhexagon_KD2SFCA &lt;- bind_cols(hexagons, acc_KD2SFCA)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-kd2sfcas-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-kd2sfcas-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.2 Visualize KD2SFCA’s accessibility",
    "text": "7.2 Visualize KD2SFCA’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_KD2SFCA,\n         bbox = mapex) + \n  tm_fill(col = \"accKD2SFCA\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: KD2SFCA method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation-1",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation-1",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "7.3 Statistical graphic visualisation",
    "text": "7.3 Statistical graphic visualisation\nNow, we will compare the distribution of KD2CFA accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_KD2SFCA simple feature data frame using the code chunk below.\n\nhexagon_KD2SFCA &lt;- st_join(hexagon_KD2SFCA, mpsz, \n                          join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution by using boxplot.\n\nggplot(data=hexagon_KD2SFCA, \n       aes(y = accKD2SFCA, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-sam-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#compute-sam-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.1 Compute SAM Accessibility",
    "text": "8.1 Compute SAM Accessibility\nIn this section, we will repeat most of the steps learned in the previous section to perform the analysis, with some code combined into a single code chunk.\nThe code chunk below calculates Hansen’s accessibility using the ac() function from the SpatialAcc package, and the output is saved in a data frame called acc_SAM. Note that SAM is specified for the family argument.\n\nacc_SAM &lt;- data.frame(ac(hexagons$demand,\n                         eldercare$capacity,\n                         distmat_km, \n                         d0 = 50,\n                         power = 2, \n                         family = \"SAM\"))\n\ncolnames(acc_SAM) &lt;- \"accSAM\"\nacc_SAM &lt;- as_tibble(acc_SAM)\nhexagon_SAM &lt;- bind_cols(hexagons, acc_SAM)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-sams-accessibility",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#visualize-sams-accessibility",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.2 Visualize SAM’s accessibility",
    "text": "8.2 Visualize SAM’s accessibility\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore. Notice that mapex is reused for bbox argument.\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(hexagon_SAM,\n         bbox = mapex) + \n  tm_fill(col = \"accSAM\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: SAM method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 3),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation-2",
    "href": "Hands-on_Ex/Hands-on_Ex09/Hands-on_Ex09.html#statistical-graphic-visualisation-2",
    "title": "Hands-on Exercise 9: Modelling Geographical Accessibility",
    "section": "8.3 Statistical graphic visualisation",
    "text": "8.3 Statistical graphic visualisation\nNow, we will compare the distribution of SAM accessibility values by URA Planning Region.\nFirst, we need to add the planning region field to the hexagon_SAM simple feature data frame using the code chunk below.\n\nhexagon_SAM &lt;- st_join(hexagon_SAM, mpsz, \n                       join = st_intersects)\n\nNext, ggplot() will be used to plot the distribution using boxplot.\n\nggplot(data=hexagon_SAM, \n       aes(y = accSAM, \n           x= REGION_N)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\", \n             fun.y=\"mean\", \n             colour =\"red\", \n             size=2)\n\nWarning in geom_point(stat = \"summary\", fun.y = \"mean\", colour = \"red\", :\nIgnoring unknown parameters: `fun.y`\n\n\nNo summary function supplied, defaulting to `mean_se()`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/ELDERCARE.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/ELDERCARE.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/hexagons.html",
    "href": "Hands-on_Ex/Hands-on_Ex09/data/geospatial/hexagons.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "",
    "text": "Spatial interaction represents the movement of people, goods, or information between locations in geographical space, covering everything from freight shipments and flight schedules to rush hour traffic and pedestrian flow.\nEach spatial interaction is composed of an origin/destination pair, represented as a cell in a matrix where rows correspond to origin locations (centroids) and columns to destination locations (centroids). This structure is known as an origin/destination (OD) matrix, or spatial interaction matrix.\nIn this hands-on exercise, we explore how to build an OD matrix using the “Passenger Volume by Origin Destination Bus Stops” dataset from the LTA DataMall. By the end, you will be able to:\n\nImport and extract OD data for a specific time interval,\nImport and save geospatial data (e.g., bus stops and mpsz) into sf tibble data frames,\nAdd planning subzone codes to the bus stops sf tibble,\nCreate desire line geospatial data from the OD data, and\nVisualize passenger volume between origin and destination bus stops using the desire line data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#import-the-od-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#import-the-od-data",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "3.1 Import the OD data",
    "text": "3.1 Import the OD data\nFirst we import the Passenger Volume by Origin Destination Bus Stops data set downloaded from LTA DataMall using read_csv() of readr package.\n\nodbus &lt;- read_csv(\"data/aspatial/origin_destination_bus_202409.csv\")\n\nRows: 5721503 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): YEAR_MONTH, DAY_TYPE, PT_TYPE, ORIGIN_PT_CODE, DESTINATION_PT_CODE\ndbl (2): TIME_PER_HOUR, TOTAL_TRIPS\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe display the odbus tibble data table by using the code chunk below.\n\nglimpse(odbus)\n\nRows: 5,721,503\nColumns: 7\n$ YEAR_MONTH          &lt;chr&gt; \"2024-09\", \"2024-09\", \"2024-09\", \"2024-09\", \"2024-…\n$ DAY_TYPE            &lt;chr&gt; \"WEEKENDS/HOLIDAY\", \"WEEKENDS/HOLIDAY\", \"WEEKENDS/…\n$ TIME_PER_HOUR       &lt;dbl&gt; 20, 19, 23, 14, 14, 18, 9, 15, 7, 21, 7, 7, 8, 10,…\n$ PT_TYPE             &lt;chr&gt; \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"BUS\", \"…\n$ ORIGIN_PT_CODE      &lt;chr&gt; \"46009\", \"59091\", \"54181\", \"61039\", \"44629\", \"7720…\n$ DESTINATION_PT_CODE &lt;chr&gt; \"46249\", \"59419\", \"54201\", \"61111\", \"44009\", \"6441…\n$ TOTAL_TRIPS         &lt;dbl&gt; 586, 54, 72, 256, 902, 6, 5, 15, 6, 4, 76, 36, 3, …\n\n\nA quick check of the odbus tibble data frame reveals that values in the ORIGIN_PT_CODE and DESTINATION_PT_CODE columns are in numeric format. The code chunk below converts these values to character data type.\n\nodbus$ORIGIN_PT_CODE &lt;- as.factor(odbus$ORIGIN_PT_CODE)\nodbus$DESTINATION_PT_CODE &lt;- as.factor(odbus$DESTINATION_PT_CODE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#extract-the-study-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#extract-the-study-data",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "3.2 Extract the study data",
    "text": "3.2 Extract the study data\nFor the purpose of this exercise, we extract commuting flows on weekday and between 6 and 9 o’clock.\n\nodbus6_9 &lt;- odbus %&gt;%\n  filter(DAY_TYPE == \"WEEKDAY\") %&gt;%\n  filter(TIME_PER_HOUR &gt;= 6 &\n           TIME_PER_HOUR &lt;= 9) %&gt;%\n  group_by(ORIGIN_PT_CODE,\n           DESTINATION_PT_CODE) %&gt;%\n  summarise(TRIPS = sum(TOTAL_TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_PT_CODE'. You can override using\nthe `.groups` argument.\n\n\nTable below shows the content of odbus6_9.\n\ndatatable(odbus6_9)\n\nWarning in instance$preRenderHook(instance): It seems your data is too big for\nclient-side DataTables. You may consider server-side processing:\nhttps://rstudio.github.io/DT/server.html\n\n\n\n\n\n\nWe save the output in rds format for future used.\n\nwrite_rds(odbus6_9, \"data/rds/odbus6_9.rds\")\n\nThe code chunk below import the save odbus6_9.rds into R environment.\n\nodbus6_9 &lt;- read_rds(\"data/rds/odbus6_9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#import-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#import-geospatial-data",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "4.1 Import Geospatial Data",
    "text": "4.1 Import Geospatial Data\nWe import the 2 datasets into R environment using below code chunks.\n\nbusstop &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"BusStop\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `BusStop' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5166 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48285.52 ymax: 52983.82\nProjected CRS: SVY21\n\n\n\nmpsz &lt;- st_read(dsn = \"data/geospatial\",\n                   layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Hands-on_Ex\\Hands-on_Ex10\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\n\n\nmpsz\n\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n                 SUBZONE_N SUBZONE_C       PLN_AREA_N PLN_AREA_C       REGION_N\n1              MARINA EAST    MESZ01      MARINA EAST         ME CENTRAL REGION\n2         INSTITUTION HILL    RVSZ05     RIVER VALLEY         RV CENTRAL REGION\n3           ROBERTSON QUAY    SRSZ01  SINGAPORE RIVER         SR CENTRAL REGION\n4  JURONG ISLAND AND BUKOM    WISZ01  WESTERN ISLANDS         WI    WEST REGION\n5             FORT CANNING    MUSZ02           MUSEUM         MU CENTRAL REGION\n6         MARINA EAST (MP)    MPSZ05    MARINE PARADE         MP CENTRAL REGION\n7                   SUDONG    WISZ03  WESTERN ISLANDS         WI    WEST REGION\n8                  SEMAKAU    WISZ02  WESTERN ISLANDS         WI    WEST REGION\n9           SOUTHERN GROUP    SISZ02 SOUTHERN ISLANDS         SI CENTRAL REGION\n10                 SENTOSA    SISZ01 SOUTHERN ISLANDS         SI CENTRAL REGION\n   REGION_C                       geometry\n1        CR MULTIPOLYGON (((33222.98 29...\n2        CR MULTIPOLYGON (((28481.45 30...\n3        CR MULTIPOLYGON (((28087.34 30...\n4        WR MULTIPOLYGON (((14557.7 304...\n5        CR MULTIPOLYGON (((29542.53 31...\n6        CR MULTIPOLYGON (((35279.55 30...\n7        WR MULTIPOLYGON (((15772.59 21...\n8        WR MULTIPOLYGON (((19843.41 21...\n9        CR MULTIPOLYGON (((30870.53 22...\n10       CR MULTIPOLYGON (((26879.04 26...\n\n\nNote:\n\nst_read() function of sf package is used to import the shapefile into R as sf data frame.\nst_transform() function of sf package is used to transform the projection to crs 3414.\n\nThe code chunk below write mpsz sf tibble data frame into an rds file for future use.\n\nmpsz &lt;- write_rds(mpsz, \"data/rds/mpsz.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#combine-busstop-and-mpsz",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#combine-busstop-and-mpsz",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "5.1 Combine Busstop and mpsz",
    "text": "5.1 Combine Busstop and mpsz\nThe code chunk below populates the planning subzone code (SUBZONE_C) from the mpsz sf data frame into the busstop sf data frame. The st_intersection() function is used to perform a point-in-polygon overlay, resulting in a point sf object.\nNext, select() from the dplyr package is used to retain only BUS_STOP_N and SUBZONE_C in the busstop_mpsz sf data frame. Note that five bus stops are excluded in the result data frame because they fall outside Singapore’s boundary.\n\nbusstop_mpsz &lt;- st_intersection(busstop, mpsz) %&gt;%\n  select(BUS_STOP_N, SUBZONE_C) %&gt;%\n  st_drop_geometry()\n\nWarning: attribute variables are assumed to be spatially constant throughout\nall geometries\n\n\n\ndatatable(busstop_mpsz)\n\n\n\n\n\nBefore moving to the next step, we save the output into rds format.\n\nwrite_rds(busstop_mpsz, \"data/rds/busstop_mpsz.rds\")  \n\nNext, we append the planning subzone code from busstop_mpsz data frame onto odbus6_9 data frame.\n\nod_data &lt;- left_join(odbus6_9 , busstop_mpsz,\n            by = c(\"ORIGIN_PT_CODE\" = \"BUS_STOP_N\")) %&gt;%\n  rename(ORIGIN_BS = ORIGIN_PT_CODE,\n         ORIGIN_SZ = SUBZONE_C,\n         DESTIN_BS = DESTINATION_PT_CODE)\n\nWarning in left_join(odbus6_9, busstop_mpsz, by = c(ORIGIN_PT_CODE = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 16245 of `x` matches multiple rows in `y`.\nℹ Row 674 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\nBefore continue, it is a good practice to check for duplicating records.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n# A tibble: 1,452 × 4\n   ORIGIN_BS DESTIN_BS TRIPS ORIGIN_SZ\n   &lt;chr&gt;     &lt;fct&gt;     &lt;dbl&gt; &lt;chr&gt;    \n 1 09047     01611         3 ORSZ02   \n 2 09047     01611         3 ORSZ02   \n 3 09047     02049        52 ORSZ02   \n 4 09047     02049        52 ORSZ02   \n 5 09047     02089        32 ORSZ02   \n 6 09047     02089        32 ORSZ02   \n 7 09047     02151        87 ORSZ02   \n 8 09047     02151        87 ORSZ02   \n 9 09047     02161        24 ORSZ02   \n10 09047     02161        24 ORSZ02   \n# ℹ 1,442 more rows\n\n\nThe code chunk below retain the unique records if duplication is found.\n\nod_data &lt;- unique(od_data)\n\nWe check again confirm if the duplicating records issue has been addressed fully.\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\nduplicate\n\n# A tibble: 0 × 4\n# ℹ 4 variables: ORIGIN_BS &lt;chr&gt;, DESTIN_BS &lt;fct&gt;, TRIPS &lt;dbl&gt;, ORIGIN_SZ &lt;chr&gt;\n\n\nNext, we update od_data data frame with the planning subzone codes.\n\nod_data &lt;- left_join(od_data , busstop_mpsz,\n            by = c(\"DESTIN_BS\" = \"BUS_STOP_N\")) \n\nWarning in left_join(od_data, busstop_mpsz, by = c(DESTIN_BS = \"BUS_STOP_N\")): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 162 of `x` matches multiple rows in `y`.\nℹ Row 673 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nduplicate &lt;- od_data %&gt;%\n  group_by_all() %&gt;%\n  filter(n()&gt;1) %&gt;%\n  ungroup()\n\n\nod_data &lt;- unique(od_data)\n\n\nod_data &lt;- od_data %&gt;%\n  rename(DESTIN_SZ = SUBZONE_C) %&gt;%\n  drop_na() %&gt;%\n  group_by(ORIGIN_SZ, DESTIN_SZ) %&gt;%\n  summarise(MORNING_PEAK = sum(TRIPS))\n\n`summarise()` has grouped output by 'ORIGIN_SZ'. You can override using the\n`.groups` argument.\n\n\nIt is time to save the output into an rds file format.\n\nwrite_rds(od_data, \"data/rds/od_data_fii.rds\")\n\n\nod_data_fii &lt;- read_rds(\"data/rds/od_data_fii.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#remove-intra-zonal-flows",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#remove-intra-zonal-flows",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "6.1 Remove intra-zonal flows",
    "text": "6.1 Remove intra-zonal flows\nWe will not plot the intra-zonal flows. The code chunk below is used to remove intra-zonal flows.\n\nod_data_fij &lt;- od_data[od_data$ORIGIN_SZ!=od_data$DESTIN_SZ,]\n\n\nwrite_rds(od_data_fij, \"data/rds/od_data_fij.rds\")\n\n\nod_data_fij &lt;- read_rds(\"data/rds/od_data_fij.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#create-desire-lines",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#create-desire-lines",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "6.2 Create desire lines",
    "text": "6.2 Create desire lines\nThe code chunk below use od2line() of stplanr package to create the desire lines.\n\nflowLine &lt;- od2line(flow = od_data_fij, \n                    zones = mpsz,\n                    zone_code = \"SUBZONE_C\")\n\nCreating centroids representing desire line start and end points.\n\n\n\nwrite_rds(flowLine, \"data/rds/flowLine.rds\")\n\n\nflowLine &lt;- read_rds(\"data/rds/flowLine.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#visualize-the-desire-lines",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex101.html#visualize-the-desire-lines",
    "title": "Hands-on Exercise 10.1: Process and Visualize Flow Data",
    "section": "6.3 Visualize the desire lines",
    "text": "6.3 Visualize the desire lines\nThe code chunk below is used to visualise the resulting desire lines.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\n\n\n\n\n\n\n\nWarning: Be patient as the rendering process takes more time because of the transparency argument (alpha)\nWhen flow data are messy and highly skewed, as seen above, it’s more effective to focus on selected flows—such as those greater than or equal to 5000, as shown below.\n\ntm_shape(mpsz) +\n  tm_polygons() +\nflowLine %&gt;%  \n  filter(MORNING_PEAK &gt;= 5000) %&gt;%\ntm_shape() +\n  tm_lines(lwd = \"MORNING_PEAK\",\n           style = \"quantile\",\n           scale = c(0.1, 1, 3, 5, 7, 10),\n           n = 6,\n           alpha = 0.3)\n\nWarning in g$scale * (w_legend/maxW): longer object length is not a multiple of\nshorter object length\n\n\nWarning in g$scale * (x/maxW): longer object length is not a multiple of\nshorter object length"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/data/geospatial/MPSZ-2019.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Prepare_HDB_data.html",
    "href": "Take-home_Ex/Take-home_Ex03/Prepare_HDB_data.html",
    "title": "Take-home Exercise 3: Preparing HDB data for Geographically Weighted Predictive Model",
    "section": "",
    "text": "1 Import R Packages\n\npacman::p_load(tidyverse, sf, httr, jsonlite, rvest, tmap)\n\n\nrvest: use for web crawling\njsonlite: to convert json file to dataframe format\ntidyverse & sf: further data manipulation\n\n\n\n2 Import the Data\nFirst we load in the Resale data from January 2023 to September 2024.\n\nresale &lt;- read_csv(\"data/rawdata/resale.csv\") %&gt;%\n  filter(month &gt;= \"2023-01\" & month &lt;= \"2024-09\")\n\nRows: 192234 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): month, town, flat_type, block, street_name, storey_range, flat_mode...\ndbl (3): floor_area_sqm, lease_commence_date, resale_price\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nresale_tidy &lt;- resale %&gt;%\n  mutate(address = paste(block,street_name)) %&gt;%\n  mutate(remaining_lease_yr = as.integer(\n    str_sub(remaining_lease, 0, 2)))%&gt;%\n  mutate(remaining_lease_mth = as.integer(\n    str_sub(remaining_lease, 9, 11)))\n\nWe narrow down the data scope to load into Onemap API later.\n\nresale_selected &lt;- resale_tidy %&gt;%\n  filter(month == \"2024-09\")\n\nNext we extract the list of unique addresses from resale_selected. The list is sorted to ensure the first address is always picked up.\n\nadd_list &lt;- sort(unique(resale_selected$address))\n\nThe below function read in any address list and record the coordinates of the parsed addresses.\n\nget_coords &lt;- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords &lt;- data.frame()\n    \n  for (i in add_list){\n    #print(i)\n    # as the API provided code for 1 address search at a time only, for pasrsing a list of addresses we use the common/elastic/search syntax as below\n    r &lt;- GET('https://www.onemap.gov.sg/api/common/elastic/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data &lt;- fromJSON(rawToChar(r$content))\n    found &lt;- data$found\n    res &lt;- data$results\n    \n    # Create a new data frame for each address\n    new_row &lt;- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal &lt;- res$POSTAL \n      lat &lt;- res$LATITUDE\n      lng &lt;- res$LONGITUDE\n      new_row &lt;- data.frame(address= i, \n                            postal = postal, \n                            latitude = lat, \n                            longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found &gt; 1){\n      # Remove those with NIL as postal\n      res_sub &lt;- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row &lt;- data.frame(address= i, \n                                postal = NA, \n                                latitude = NA, \n                                longitude = NA)\n      }\n      \n      else{\n        top1 &lt;- head(res_sub, n = 1)\n        postal &lt;- top1$POSTAL \n        lat &lt;- top1$LATITUDE\n        lng &lt;- top1$LONGITUDE\n        new_row &lt;- data.frame(address= i, \n                              postal = postal, \n                              latitude = lat, \n                              longitude = lng)\n      }\n    }\n\n    else {\n      new_row &lt;- data.frame(address= i, \n                            postal = NA, \n                            latitude = NA, \n                            longitude = NA)\n    }\n    \n    # Add the row\n    postal_coords &lt;- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\nWe run the get_coords function on the add_list.\n\ncoords &lt;- get_coords(add_list)\n\n\nwrite_rds(coords, \"data/rds/coords.rds\")\n\n\neldercare = st_read(dsn = 'data/rawdata',\n                    layer = 'ELDERCARE') |&gt;\n  st_transform(crs = 3414)\n\nReading layer `ELDERCARE' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\rawdata' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\n\n\nCHAS = st_read('data/rawdata/CHASClinics.kml') |&gt;\n  st_transform(crs = 3414)\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\thuphuong1110\\ISSS626-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\rawdata\\CHASClinics.kml' \n  using driver `KML'\nSimple feature collection with 1193 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\n\n3 Count number of points within a Distance\nCount all the eldercare/clinics within 1km from the HDB\n\nbuffer_1km = st_buffer(eldercare, dist = 1000)\n\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(buffer_1km) + # plot the larger share first (polygon &gt; points)\n  tm_polygons() +\n  tm_shape(CHAS) +\n  tm_dots()\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\n\nbuffer_1km$clinic_count = lengths(\n  st_intersects(buffer_1km, CHAS))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/hexagons.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/hexagons.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/ELDERCARE.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/ELDERCARE.html",
    "title": "ISSS626-GAA",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;  ELDERCARE  ENG dataset\n\nELDERCARE\n\n                 0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html",
    "title": "In-class Exercise 9: Modelling Geography of Accessibility",
    "section": "",
    "text": "pacman::p_load(tmap, SpatialAcc, sf, \n               ggstatsplot, reshape2,\n               tidyverse, rstantools)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tidy-distance-matrix",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#tidy-distance-matrix",
    "title": "In-class Exercise 9: Modelling Geography of Accessibility",
    "section": "3.1 Tidy Distance matrix",
    "text": "3.1 Tidy Distance matrix\nThe imported ODMatrix organised the distance matrix columnwise. However, most of the modelling packages in R is expecting a matrix look where The rows represent origins (also know as from field) and the columns represent destination (i.e. also known as to field.).\nThe pivot_wider() function from the tidyr package was used to transform the O-D matrix from a long format to a wide format.\n\ndistmat &lt;- ODMatrix %&gt;%\n  select(origin_id, destination_id, total_cost) %&gt;%\n  pivot_wider(names_from = destination_id, values_from = total_cost)%&gt;%\n  select(c(-c('origin_id')))\n\nAs SVY21 projected coordinate system is used, the distance is measured in metre. The code chunk below convert the unit measurement from metre to kilometre.\n\ndistmat_km &lt;- as.matrix(distmat/1000)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#compute-hansens-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#compute-hansens-accessibility",
    "title": "In-class Exercise 9: Modelling Geography of Accessibility",
    "section": "4.1 Compute Hansen’s accessibility",
    "text": "4.1 Compute Hansen’s accessibility\nNow we are ready to compute Hansen’s accessibility using the ac() function from the SpatialAcc package. Before proceeding, it’s advisable to review the function’s arguments at least once to ensure that all required inputs are available.\nThe code chunk below calculates Hansen’s accessibility, using ac() from the SpatialAcc package, and saves the output in a data frame called acc_Hansen using the data.frame() function.\n\nacc_Hansen &lt;- data.frame(ac(hexagons$demand,\n                            eldercare$capacity,\n                            distmat_km, \n                            #d0 = 50,\n                            power = 2, \n                            family = \"Hansen\"))\n\nThe default field name is messy, we rename it to accHansen using the code chunk below.\n\ncolnames(acc_Hansen) &lt;- \"accHansen\"\n\nacc_Hansen &lt;- as_tibble(acc_Hansen)\n\nhexagon_Hansen &lt;- bind_cols(hexagons, acc_Hansen)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualize-hansens-accessibility",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#visualize-hansens-accessibility",
    "title": "In-class Exercise 9: Modelling Geography of Accessibility",
    "section": "4.2 Visualize Hansen’s accessibility",
    "text": "4.2 Visualize Hansen’s accessibility\nFirst we extract the extend of hexagons simple feature data frame by using st_bbox() of sf package.\n\nmapex &lt;- st_bbox(hexagons)\n\nThe code chunk below uses a collection of mapping fucntions of tmap package to create a high cartographic quality accessibility to eldercare centre in Singapore.\n\ntm_shape(hexagon_Hansen,\n         bbox = mapex) + \n  tm_fill(col = \"accHansen\",\n          n = 10,\n          style = \"quantile\",\n          border.col = \"black\",\n          border.lwd = 1) +\ntm_shape(eldercare) +\n  tm_symbols(size = 0.1) +\n  tm_layout(main.title = \"Accessibility to eldercare: Hansen method\",\n            main.title.position = \"center\",\n            main.title.size = 2,\n            legend.outside = FALSE,\n            legend.height = 0.45, \n            legend.width = 3.0,\n            legend.format = list(digits = 6),\n            legend.position = c(\"right\", \"top\"),\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#statistical-graphic",
    "title": "In-class Exercise 9: Modelling Geography of Accessibility",
    "section": "4.3 Statistical Graphic",
    "text": "4.3 Statistical Graphic\n\nhexagon_Hansen = st_join(hexagon_Hansen, mpsz,\n                         join = st_intersects)\n\n\nggbetweenstats(\n  data = hexagon_Hansen,\n  x = REGION_N,\n  y = accHansen,\n  type = 'p'\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling-1",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html#data-sampling-1",
    "title": "In-class Exercise 8: Geographically Weighted Predictive Models",
    "section": "2.1 Data Sampling",
    "text": "2.1 Data Sampling\nThe data is split into train and test data sets with with size of 65% and 35% respectively using initial_split() of rsample package. rsample is one of the package from tidymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(HDB_sample, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\nWe write the data to rds format.\n\nwrite_rds(train_data, \"data/train_data.rds\")\nwrite_rds(test_data, \"data/test_data.rds\")\n\nRead the data from rds format.\n\ntrain_data &lt;- read_rds(\"data/train_data.rds\")\ntest_data &lt;- read_rds(\"data/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "",
    "text": "Spatial Interaction Models (SIMs) are mathematical models to estimate flows between spatial entities developed by Alan Wilson in the late 1960s, and refined for transport modeling by Boyce and Williams (2015), The four main traditional SIM types (Wilson 1971) are:\n\nUnconstrained\nProduction-constrained\nAttraction-constrained\nDoubly-constrained\n\nCommon methods for calibrating OD flow models include OLS, log-normal, Poisson, and negative binomial (NB) regression, each processing flow data differently as dependent variables. This chapter provides a hands-on experience with R packages to calibrate SIMs using these regression methods.\nNote on Calibration\nCalibration involves adjusting model parameters to closely align estimates with observed data. This iterative process leverages computers to optimize goodness-of-fit statistics, indicating when an optimal solution is achieved. Traditionally, this required programming skills to iteratively modify parameters, evaluate goodness-of-fit, and repeat until the statistic reached its maximum or minimum. (Adam Dennett, 2018)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#converte-from-sf-data.table-to-spatialpolygonsdataframe",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#converte-from-sf-data.table-to-spatialpolygonsdataframe",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "5.1 Converte from sf data.table to SpatialPolygonsDataFrame",
    "text": "5.1 Converte from sf data.table to SpatialPolygonsDataFrame\nThere are two primary methods for computing a distance matrix: one using sf and the other using sp. Based on previous experience, sf can be slower with large datasets, so the sp method is preferred here. The code below first converts mpsz from an sf tibble data frame to a SpatialPolygonsDataFrame in sp format using as.Spatial().\n\nmpsz_sp &lt;- as(mpsz, \"Spatial\")\nmpsz_sp\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 332 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 6\nnames       : SUBZONE_N, SUBZONE_C, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C \nmin values  : ADMIRALTY,    AMSZ01, ANG MO KIO,         AM, CENTRAL REGION,       CR \nmax values  :    YUNNAN,    YSSZ09,     YISHUN,         YS,    WEST REGION,       WR"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#compute-the-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#compute-the-distance-matrix",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "5.2 Compute the distance matrix",
    "text": "5.2 Compute the distance matrix\nNext, spDists() of sp package is used to compute the Euclidean distance between the centroids of the planning subzones.\n\ndist &lt;- spDists(mpsz_sp, \n                longlat = FALSE)\n\n\nhead(dist, n=c(10, 10))\n\n           [,1]       [,2]      [,3]      [,4]       [,5]      [,6]      [,7]\n [1,]     0.000  3926.0025  3939.108 20252.964  2989.9839  1431.330 19211.836\n [2,]  3926.003     0.0000   305.737 16513.865   951.8314  5254.066 16242.523\n [3,]  3939.108   305.7370     0.000 16412.062  1045.9088  5299.849 16026.146\n [4,] 20252.964 16513.8648 16412.062     0.000 17450.3044 21665.795  7229.017\n [5,]  2989.984   951.8314  1045.909 17450.304     0.0000  4303.232 17020.916\n [6,]  1431.330  5254.0664  5299.849 21665.795  4303.2323     0.000 20617.082\n [7,] 19211.836 16242.5230 16026.146  7229.017 17020.9161 20617.082     0.000\n [8,] 14960.942 12749.4101 12477.871 11284.279 13336.0421 16281.453  5606.082\n [9,]  7515.256  7934.8082  7649.776 18427.503  7801.6163  8403.896 14810.930\n[10,]  6391.342  4975.0021  4669.295 15469.566  5226.8731  7707.091 13111.391\n           [,8]      [,9]     [,10]\n [1,] 14960.942  7515.256  6391.342\n [2,] 12749.410  7934.808  4975.002\n [3,] 12477.871  7649.776  4669.295\n [4,] 11284.279 18427.503 15469.566\n [5,] 13336.042  7801.616  5226.873\n [6,] 16281.453  8403.896  7707.091\n [7,]  5606.082 14810.930 13111.391\n [8,]     0.000  9472.024  8575.490\n [9,]  9472.024     0.000  3780.800\n[10,]  8575.490  3780.800     0.000\n\n\nNotice that the output dist is an R matrix object class. The column headers and row headers are not labeled with the planning subzone codes."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#label-column-and-row-headers-of-a-distance-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#label-column-and-row-headers-of-a-distance-matrix",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "5.3 Label column and row headers of a distance matrix",
    "text": "5.3 Label column and row headers of a distance matrix\nFirst, we create a list sorted according to the the distance matrix by planning sub-zone code.\n\nsz_names &lt;- mpsz$SUBZONE_C\n\nNext we attach SUBZONE_C to row and column headers of the distance matrix.\n\ncolnames(dist) &lt;- paste0(sz_names)\nrownames(dist) &lt;- paste0(sz_names)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#pivot-distance-value-by-subzone_c",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#pivot-distance-value-by-subzone_c",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "5.4 Pivot distance value by SUBZONE_C",
    "text": "5.4 Pivot distance value by SUBZONE_C\nNext, we pivot the distance matrix into a long table using row and column subzone codes as show in the code chunk below.\n\ndistPair &lt;- melt(dist) %&gt;%\n  rename(dist = value)\nhead(distPair, 10)\n\n     Var1   Var2      dist\n1  MESZ01 MESZ01     0.000\n2  RVSZ05 MESZ01  3926.003\n3  SRSZ01 MESZ01  3939.108\n4  WISZ01 MESZ01 20252.964\n5  MUSZ02 MESZ01  2989.984\n6  MPSZ05 MESZ01  1431.330\n7  WISZ03 MESZ01 19211.836\n8  WISZ02 MESZ01 14960.942\n9  SISZ02 MESZ01  7515.256\n10 SISZ01 MESZ01  6391.342\n\n\nNotice that the within zone distance is 0."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#update-intra-zonal-distances",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#update-intra-zonal-distances",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "5.5 Update intra-zonal distances",
    "text": "5.5 Update intra-zonal distances\nIn this section, we append a constant value to replace the intra-zone distance of 0.\nFirst, we select and find out the minimum value of the distance using summary().\n\ndistPair %&gt;%\n  filter(dist &gt; 0) %&gt;%\n  summary()\n\n      Var1             Var2             dist        \n MESZ01 :   331   MESZ01 :   331   Min.   :  173.8  \n RVSZ05 :   331   RVSZ05 :   331   1st Qu.: 7149.5  \n SRSZ01 :   331   SRSZ01 :   331   Median :11890.0  \n WISZ01 :   331   WISZ01 :   331   Mean   :12229.4  \n MUSZ02 :   331   MUSZ02 :   331   3rd Qu.:16401.7  \n MPSZ05 :   331   MPSZ05 :   331   Max.   :49894.4  \n (Other):107906   (Other):107906                    \n\n\nNext, a constant distance value of 50m is added into intra-zones distance.\n\ndistPair$dist &lt;- ifelse(distPair$dist == 0,\n                        50, distPair$dist)\n\nThe code chunk below checks the result data.frame.\n\ndistPair %&gt;%\n  summary()\n\n      Var1             Var2             dist      \n MESZ01 :   332   MESZ01 :   332   Min.   :   50  \n RVSZ05 :   332   RVSZ05 :   332   1st Qu.: 7097  \n SRSZ01 :   332   SRSZ01 :   332   Median :11864  \n WISZ01 :   332   WISZ01 :   332   Mean   :12193  \n MUSZ02 :   332   MUSZ02 :   332   3rd Qu.:16388  \n MPSZ05 :   332   MPSZ05 :   332   Max.   :49894  \n (Other):108232   (Other):108232                  \n\n\nWe can see the min dist is 50, which is the value we assign earlier.\nNext we rename the origin and destination fields.\n\ndistPair &lt;- distPair %&gt;%\n  rename(orig = Var1,\n         dest = Var2)\n\nThen we use the below code chunk to save the result for future use.\n\nwrite_rds(distPair, \"data/rds/distPair.rds\") \n\n\ndistPair &lt;- read_rds(\"data/rds/distPair.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#separate-intra-flow-from-passenger-volume-df",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#separate-intra-flow-from-passenger-volume-df",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "6.1 Separate intra-flow from passenger volume df",
    "text": "6.1 Separate intra-flow from passenger volume df\nThe code chunk below add 2 new fields to flow_data dataframe.\n\nflow_data$FlowNoIntra &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0, flow_data$TRIPS)\nflow_data$offset &lt;- ifelse(\n  flow_data$ORIGIN_SZ == flow_data$DESTIN_SZ, \n  0.000001, 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#combine-passenger-volume-data-with-distance-value",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#combine-passenger-volume-data-with-distance-value",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "6.2 Combine passenger volume data with distance value",
    "text": "6.2 Combine passenger volume data with distance value\nBefore we can join flow_data and distPair, we need to convert data value type of ORIGIN_SZ and DESTIN_SZ fields to factor data type.\n\nflow_data$ORIGIN_SZ &lt;- as.factor(flow_data$ORIGIN_SZ)\nflow_data$DESTIN_SZ &lt;- as.factor(flow_data$DESTIN_SZ)\n\nNext, left_join() of dplyr is used to join flow_data dataframe and distPair dataframe. The output is save in flow_data1.\n\nflow_data1 &lt;- flow_data %&gt;%\n  left_join (distPair,\n             by = c(\"ORIGIN_SZ\" = \"orig\",\n                    \"DESTIN_SZ\" = \"dest\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#import-population-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#import-population-data",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "7.1 Import population data",
    "text": "7.1 Import population data\n\npop &lt;- read_csv(\"data/aspatial/pop.csv\")\n\nRows: 332 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): PA, SZ\ndbl (3): AGE7_12, AGE13_24, AGE25_64\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#geospatial-data-wrangling",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "7.2 Geospatial data wrangling",
    "text": "7.2 Geospatial data wrangling\n\npop &lt;- pop %&gt;%\n  left_join(mpsz,\n            by = c(\"PA\" = \"PLN_AREA_N\",\n                   \"SZ\" = \"SUBZONE_N\")) %&gt;%\n  select(1:6) %&gt;%\n  rename(SZ_NAME = SZ,\n         SZ = SUBZONE_C)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#prepare-origin-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#prepare-origin-attribute",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "7.3 Prepare origin attribute",
    "text": "7.3 Prepare origin attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(ORIGIN_SZ = \"SZ\")) %&gt;%\n  rename(ORIGIN_AGE7_12 = AGE7_12,\n         ORIGIN_AGE13_24 = AGE13_24,\n         ORIGIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#prepare-destination-attribute",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#prepare-destination-attribute",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "7.4 Prepare destination attribute",
    "text": "7.4 Prepare destination attribute\n\nflow_data1 &lt;- flow_data1 %&gt;%\n  left_join(pop,\n            by = c(DESTIN_SZ = \"SZ\")) %&gt;%\n  rename(DESTIN_AGE7_12 = AGE7_12,\n         DESTIN_AGE13_24 = AGE13_24,\n         DESTIN_AGE25_64 = AGE25_64) %&gt;%\n  select(-c(PA, SZ_NAME))\n\nWe write the output flow_data1 into rds data file format.\n\nwrite_rds(flow_data1, \"data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#import-the-modelling-data",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#import-the-modelling-data",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.1 Import the modelling data",
    "text": "8.1 Import the modelling data\nFirst we import the modelling data using below code chunk.\n\nSIM_data &lt;- read_rds(\"data/rds/flow_data_6-9.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#visualize-the-dependent-variable",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#visualize-the-dependent-variable",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.2 Visualize the dependent variable",
    "text": "8.2 Visualize the dependent variable\nFirstly, we plot the distribution of the dependent variable (TRIPS) using histogram.\n\nggplot(data = SIM_data,\n       aes(x = TRIPS)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThe distribution appears highly skewed and does not resemble a bell-shaped (normal) distribution.\nNext, let’s visualize the relationship between the dependent variable and one of the key independent variables in the Spatial Interaction Model: distance.\n\nggplot(data = SIM_data,\n       aes(x = dist,\n           y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe relationship between the variables does not resemble a linear pattern in the initial scatter plot.\nHowever, when plotting the scatter plot using the log-transformed version of both variables, their relationship appears more linear.\n\nggplot(data = SIM_data,\n       aes(x = log(dist),\n           y = log(TRIPS))) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#check-for-variables-with-zero-values",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#check-for-variables-with-zero-values",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.3 Check for variables with zero values",
    "text": "8.3 Check for variables with zero values\nSince Poisson Regression relies on logarithmic transformations, and log(0) is undefined, it’s crucial to ensure there are no zero values in the explanatory variables.\nThe code chunk below uses summary() from base R to compute summary statistics for all variables in the SIM_data data frame.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12 ORIGIN_AGE13_24\n Min.   :0.000001   Min.   :   50   Min.   :   0   Min.   :    0  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240   1st Qu.:  440  \n Median :1.000000   Median : 6067   Median : 700   Median : 1350  \n Mean   :0.982150   Mean   : 6880   Mean   :1032   Mean   : 2269  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480   3rd Qu.: 3260  \n Max.   :1.000000   Max.   :26136   Max.   :6340   Max.   :16380  \n ORIGIN_AGE25_64 DESTIN_AGE7_12 DESTIN_AGE13_24 DESTIN_AGE25_64\n Min.   :    0   Min.   :   0   Min.   :    0   Min.   :    0  \n 1st Qu.: 2200   1st Qu.: 240   1st Qu.:  460   1st Qu.: 2200  \n Median : 6810   Median : 720   Median : 1420   Median : 7030  \n Mean   :10487   Mean   :1033   Mean   : 2290   Mean   :10574  \n 3rd Qu.:15770   3rd Qu.:1500   3rd Qu.: 3260   3rd Qu.:15830  \n Max.   :74610   Max.   :6340   Max.   :16380   Max.   :74610  \n\n\nThe output reveals that variables ORIGIN_AGE7_12, ORIGIN_AGE13_24, ORIGIN_AGE25_64,DESTIN_AGE7_12, DESTIN_AGE13_24, DESTIN_AGE25_64 consist of 0 values.\nIn view of this, code chunk below will be used to replace zero values to 0.99.\n\nSIM_data$DESTIN_AGE7_12 &lt;- ifelse(\n  SIM_data$DESTIN_AGE7_12 == 0,\n  0.99, SIM_data$DESTIN_AGE7_12)\nSIM_data$DESTIN_AGE13_24 &lt;- ifelse(\n  SIM_data$DESTIN_AGE13_24 == 0,\n  0.99, SIM_data$DESTIN_AGE13_24)\nSIM_data$DESTIN_AGE25_64 &lt;- ifelse(\n  SIM_data$DESTIN_AGE25_64 == 0,\n  0.99, SIM_data$DESTIN_AGE25_64)\nSIM_data$ORIGIN_AGE7_12 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE7_12 == 0,\n  0.99, SIM_data$ORIGIN_AGE7_12)\nSIM_data$ORIGIN_AGE13_24 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE13_24 == 0,\n  0.99, SIM_data$ORIGIN_AGE13_24)\nSIM_data$ORIGIN_AGE25_64 &lt;- ifelse(\n  SIM_data$ORIGIN_AGE25_64 == 0,\n  0.99, SIM_data$ORIGIN_AGE25_64)\n\nWe run the summary again.\n\nsummary(SIM_data)\n\n  ORIGIN_SZ          DESTIN_SZ             TRIPS         FlowNoIntra      \n Length:14734       Length:14734       Min.   :     1   Min.   :     0.0  \n Class :character   Class :character   1st Qu.:    14   1st Qu.:    13.0  \n Mode  :character   Mode  :character   Median :    76   Median :    70.0  \n                                       Mean   :  1021   Mean   :   839.9  \n                                       3rd Qu.:   426   3rd Qu.:   379.0  \n                                       Max.   :232187   Max.   :148274.0  \n     offset              dist       ORIGIN_AGE7_12    ORIGIN_AGE13_24   \n Min.   :0.000001   Min.   :   50   Min.   :   0.99   Min.   :    0.99  \n 1st Qu.:1.000000   1st Qu.: 3346   1st Qu.: 240.00   1st Qu.:  440.00  \n Median :1.000000   Median : 6067   Median : 700.00   Median : 1350.00  \n Mean   :0.982150   Mean   : 6880   Mean   :1031.86   Mean   : 2268.84  \n 3rd Qu.:1.000000   3rd Qu.: 9729   3rd Qu.:1480.00   3rd Qu.: 3260.00  \n Max.   :1.000000   Max.   :26136   Max.   :6340.00   Max.   :16380.00  \n ORIGIN_AGE25_64    DESTIN_AGE7_12    DESTIN_AGE13_24    DESTIN_AGE25_64   \n Min.   :    0.99   Min.   :   0.99   Min.   :    0.99   Min.   :    0.99  \n 1st Qu.: 2200.00   1st Qu.: 240.00   1st Qu.:  460.00   1st Qu.: 2200.00  \n Median : 6810.00   Median : 720.00   Median : 1420.00   Median : 7030.00  \n Mean   :10487.62   Mean   :1033.40   Mean   : 2290.35   Mean   :10574.46  \n 3rd Qu.:15770.00   3rd Qu.:1500.00   3rd Qu.: 3260.00   3rd Qu.:15830.00  \n Max.   :74610.00   Max.   :6340.00   Max.   :16380.00   Max.   :74610.00  \n\n\nNotice that all the 0 values have been replaced by 0.99."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#unconstrained-spatial-interaction-model",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#unconstrained-spatial-interaction-model",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.4 Unconstrained Spatial Interaction Model",
    "text": "8.4 Unconstrained Spatial Interaction Model\nIn this section, we will calibrate an unconstrained spatial interaction model using glm() from the base R stats package. The explanatory variables include origin population by various age cohorts, destination population by different age cohorts (e.g., ORIGIN_AGE25_64), and the distance between origin and destination in kilometers (e.g., dist).\nThe general formula for an Unconstrained Spatial Interaction Model is:\n\nThe code chunk used to calibrate to model is shown below.\n\nuncSIM &lt;- glm(formula = TRIPS ~ \n                log(ORIGIN_AGE25_64) + \n                log(DESTIN_AGE25_64) +\n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nuncSIM\n\n\nCall:  glm(formula = TRIPS ~ log(ORIGIN_AGE25_64) + log(DESTIN_AGE25_64) + \n    log(dist), family = poisson(link = \"log\"), data = SIM_data, \n    na.action = na.exclude)\n\nCoefficients:\n         (Intercept)  log(ORIGIN_AGE25_64)  log(DESTIN_AGE25_64)  \n           10.407308              0.244859              0.009562  \n           log(dist)  \n           -0.705896  \n\nDegrees of Freedom: 14733 Total (i.e. Null);  14730 Residual\nNull Deviance:      60800000 \nResidual Deviance: 36430000     AIC: 36520000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#r-squared-function",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#r-squared-function",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.5 R-squared function",
    "text": "8.5 R-squared function\nIn order to measure how much variation of the trips can be accounted by the model, we write a function to calculate R-Squared value as shown below.\n\nCalcRSquared &lt;- function(observed,estimated){\n  r &lt;- cor(observed,estimated)\n  R2 &lt;- r^2\n  R2\n}\n\nNext, we compute the R-squared of the unconstrained SIM by using the code chunk below.\n\nCalcRSquared(uncSIM$data$TRIPS, uncSIM$fitted.values)\n\n[1] 0.1892576\n\n\n\nr2_mcfadden(uncSIM)\n\n# R2 for Generalized Linear Regression\n       R2: 0.400\n  adj. R2: 0.400"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#origin-production-constrained-sim",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#origin-production-constrained-sim",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.6 Origin (Production) constrained SIM",
    "text": "8.6 Origin (Production) constrained SIM\nIn this section, we fit an origin constrained SIM using the code chunk below.\nThe general formula of Origin Constrained Spatial Interaction Model\n\n\norcSIM &lt;- glm(formula = TRIPS ~ \n                 ORIGIN_SZ +\n                 log(DESTIN_AGE25_64) +\n                 log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(orcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + log(DESTIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)           1.211e+01  3.785e-03  3199.012  &lt; 2e-16 ***\nORIGIN_SZAMSZ02       1.008e+00  4.450e-03   226.401  &lt; 2e-16 ***\nORIGIN_SZAMSZ03       5.474e-01  4.563e-03   119.959  &lt; 2e-16 ***\nORIGIN_SZAMSZ04      -7.494e-02  5.187e-03   -14.448  &lt; 2e-16 ***\nORIGIN_SZAMSZ05      -2.006e-01  5.790e-03   -34.650  &lt; 2e-16 ***\nORIGIN_SZAMSZ06       4.193e-01  5.130e-03    81.736  &lt; 2e-16 ***\nORIGIN_SZAMSZ07      -1.372e+00  9.683e-03  -141.686  &lt; 2e-16 ***\nORIGIN_SZAMSZ08      -1.022e+00  8.956e-03  -114.087  &lt; 2e-16 ***\nORIGIN_SZAMSZ09       2.239e-01  5.408e-03    41.396  &lt; 2e-16 ***\nORIGIN_SZAMSZ10       5.061e-01  4.716e-03   107.311  &lt; 2e-16 ***\nORIGIN_SZAMSZ11      -1.856e+00  1.285e-02  -144.414  &lt; 2e-16 ***\nORIGIN_SZAMSZ12      -1.580e+00  1.076e-02  -146.883  &lt; 2e-16 ***\nORIGIN_SZBDSZ01       1.072e+00  4.345e-03   246.734  &lt; 2e-16 ***\nORIGIN_SZBDSZ02       5.198e-01  5.079e-03   102.340  &lt; 2e-16 ***\nORIGIN_SZBDSZ03       9.865e-01  4.490e-03   219.724  &lt; 2e-16 ***\nORIGIN_SZBDSZ04       1.767e+00  3.894e-03   453.646  &lt; 2e-16 ***\nORIGIN_SZBDSZ05       6.395e-01  4.546e-03   140.691  &lt; 2e-16 ***\nORIGIN_SZBDSZ06       9.363e-01  4.543e-03   206.094  &lt; 2e-16 ***\nORIGIN_SZBDSZ07      -1.281e+00  9.558e-03  -133.991  &lt; 2e-16 ***\nORIGIN_SZBDSZ08      -1.167e+00  9.032e-03  -129.194  &lt; 2e-16 ***\nORIGIN_SZBKSZ01      -4.540e-01  6.538e-03   -69.437  &lt; 2e-16 ***\nORIGIN_SZBKSZ02       3.736e-01  5.115e-03    73.050  &lt; 2e-16 ***\nORIGIN_SZBKSZ03       5.841e-01  4.934e-03   118.375  &lt; 2e-16 ***\nORIGIN_SZBKSZ04      -1.177e-01  5.914e-03   -19.895  &lt; 2e-16 ***\nORIGIN_SZBKSZ05      -2.164e-01  5.832e-03   -37.115  &lt; 2e-16 ***\nORIGIN_SZBKSZ06       3.684e-03  5.873e-03     0.627  0.53048    \nORIGIN_SZBKSZ07       7.456e-01  4.426e-03   168.439  &lt; 2e-16 ***\nORIGIN_SZBKSZ08      -2.279e-02  5.348e-03    -4.261 2.04e-05 ***\nORIGIN_SZBKSZ09      -9.572e-02  5.721e-03   -16.733  &lt; 2e-16 ***\nORIGIN_SZBLSZ01      -1.688e+00  1.482e-02  -113.887  &lt; 2e-16 ***\nORIGIN_SZBLSZ02      -2.154e+00  1.924e-02  -111.980  &lt; 2e-16 ***\nORIGIN_SZBLSZ03      -3.249e+00  3.930e-02   -82.662  &lt; 2e-16 ***\nORIGIN_SZBLSZ04      -2.203e+00  2.306e-02   -95.557  &lt; 2e-16 ***\nORIGIN_SZBMSZ01      -1.267e-01  5.222e-03   -24.266  &lt; 2e-16 ***\nORIGIN_SZBMSZ02      -1.075e+00  6.742e-03  -159.386  &lt; 2e-16 ***\nORIGIN_SZBMSZ03      -4.386e-01  5.794e-03   -75.707  &lt; 2e-16 ***\nORIGIN_SZBMSZ04      -6.333e-02  5.157e-03   -12.280  &lt; 2e-16 ***\nORIGIN_SZBMSZ05      -2.256e+00  1.247e-02  -180.957  &lt; 2e-16 ***\nORIGIN_SZBMSZ06      -2.378e+00  1.618e-02  -147.029  &lt; 2e-16 ***\nORIGIN_SZBMSZ07      -4.769e-01  5.653e-03   -84.362  &lt; 2e-16 ***\nORIGIN_SZBMSZ08      -5.652e-01  5.811e-03   -97.259  &lt; 2e-16 ***\nORIGIN_SZBMSZ09      -1.232e+00  8.688e-03  -141.760  &lt; 2e-16 ***\nORIGIN_SZBMSZ10      -1.471e+00  9.130e-03  -161.131  &lt; 2e-16 ***\nORIGIN_SZBMSZ11      -7.866e-01  6.595e-03  -119.263  &lt; 2e-16 ***\nORIGIN_SZBMSZ12      -1.072e+00  9.149e-03  -117.206  &lt; 2e-16 ***\nORIGIN_SZBMSZ13      -1.207e-01  5.691e-03   -21.218  &lt; 2e-16 ***\nORIGIN_SZBMSZ14      -5.376e-01  6.629e-03   -81.098  &lt; 2e-16 ***\nORIGIN_SZBMSZ15      -3.253e-01  6.054e-03   -53.740  &lt; 2e-16 ***\nORIGIN_SZBMSZ16      -1.548e+00  9.144e-03  -169.303  &lt; 2e-16 ***\nORIGIN_SZBMSZ17      -2.169e+00  1.576e-02  -137.622  &lt; 2e-16 ***\nORIGIN_SZBPSZ01       1.369e-01  5.553e-03    24.660  &lt; 2e-16 ***\nORIGIN_SZBPSZ02      -3.292e-02  6.462e-03    -5.094 3.50e-07 ***\nORIGIN_SZBPSZ03       1.491e-01  6.149e-03    24.241  &lt; 2e-16 ***\nORIGIN_SZBPSZ04       3.544e-01  5.084e-03    69.711  &lt; 2e-16 ***\nORIGIN_SZBPSZ05       5.454e-01  4.554e-03   119.764  &lt; 2e-16 ***\nORIGIN_SZBPSZ06      -1.406e+00  9.311e-03  -151.045  &lt; 2e-16 ***\nORIGIN_SZBPSZ07      -1.004e+00  8.575e-03  -117.068  &lt; 2e-16 ***\nORIGIN_SZBSSZ01      -1.625e-02  5.276e-03    -3.080  0.00207 ** \nORIGIN_SZBSSZ02       3.088e-01  4.787e-03    64.495  &lt; 2e-16 ***\nORIGIN_SZBSSZ03       2.555e-01  4.689e-03    54.487  &lt; 2e-16 ***\nORIGIN_SZBTSZ01      -6.646e-02  5.385e-03   -12.340  &lt; 2e-16 ***\nORIGIN_SZBTSZ02      -1.078e+00  7.797e-03  -138.225  &lt; 2e-16 ***\nORIGIN_SZBTSZ03      -2.284e-01  5.727e-03   -39.876  &lt; 2e-16 ***\nORIGIN_SZBTSZ04      -1.053e+00  1.019e-02  -103.339  &lt; 2e-16 ***\nORIGIN_SZBTSZ05      -1.647e+00  1.100e-02  -149.690  &lt; 2e-16 ***\nORIGIN_SZBTSZ06      -7.804e-01  7.181e-03  -108.682  &lt; 2e-16 ***\nORIGIN_SZBTSZ07      -2.298e+00  1.321e-02  -173.921  &lt; 2e-16 ***\nORIGIN_SZBTSZ08      -1.283e+00  9.394e-03  -136.560  &lt; 2e-16 ***\nORIGIN_SZCBSZ01      -1.911e+00  5.483e-02   -34.844  &lt; 2e-16 ***\nORIGIN_SZCCSZ01      -1.758e+00  1.331e-02  -132.099  &lt; 2e-16 ***\nORIGIN_SZCHSZ01      -1.236e+00  1.178e-02  -104.954  &lt; 2e-16 ***\nORIGIN_SZCHSZ02      -5.424e-01  7.940e-03   -68.307  &lt; 2e-16 ***\nORIGIN_SZCHSZ03       4.332e-01  5.841e-03    74.153  &lt; 2e-16 ***\nORIGIN_SZCKSZ01       1.843e-01  5.117e-03    36.007  &lt; 2e-16 ***\nORIGIN_SZCKSZ02       6.800e-01  5.087e-03   133.672  &lt; 2e-16 ***\nORIGIN_SZCKSZ03       8.030e-01  4.522e-03   177.574  &lt; 2e-16 ***\nORIGIN_SZCKSZ04       1.298e+00  4.562e-03   284.446  &lt; 2e-16 ***\nORIGIN_SZCKSZ05       1.011e+00  5.305e-03   190.602  &lt; 2e-16 ***\nORIGIN_SZCKSZ06       1.262e+00  5.042e-03   250.262  &lt; 2e-16 ***\nORIGIN_SZCLSZ01      -6.805e-01  7.661e-03   -88.836  &lt; 2e-16 ***\nORIGIN_SZCLSZ02      -1.837e+00  1.364e-02  -134.665  &lt; 2e-16 ***\nORIGIN_SZCLSZ03      -1.001e+00  7.949e-03  -125.969  &lt; 2e-16 ***\nORIGIN_SZCLSZ04       6.966e-01  4.460e-03   156.204  &lt; 2e-16 ***\nORIGIN_SZCLSZ05      -1.974e+00  1.474e-02  -133.906  &lt; 2e-16 ***\nORIGIN_SZCLSZ06       8.585e-01  4.204e-03   204.230  &lt; 2e-16 ***\nORIGIN_SZCLSZ07      -2.974e-01  5.575e-03   -53.346  &lt; 2e-16 ***\nORIGIN_SZCLSZ08       3.231e-01  5.802e-03    55.688  &lt; 2e-16 ***\nORIGIN_SZCLSZ09      -1.697e+00  1.555e-02  -109.106  &lt; 2e-16 ***\nORIGIN_SZDTSZ02      -4.061e+00  8.341e-02   -48.693  &lt; 2e-16 ***\nORIGIN_SZDTSZ03      -4.031e+00  7.381e-02   -54.618  &lt; 2e-16 ***\nORIGIN_SZDTSZ13      -3.000e+00  3.129e-02   -95.889  &lt; 2e-16 ***\nORIGIN_SZGLSZ01      -1.405e+00  9.192e-03  -152.876  &lt; 2e-16 ***\nORIGIN_SZGLSZ02       2.536e-01  4.889e-03    51.880  &lt; 2e-16 ***\nORIGIN_SZGLSZ03       2.411e-01  4.855e-03    49.649  &lt; 2e-16 ***\nORIGIN_SZGLSZ04       8.350e-01  4.200e-03   198.826  &lt; 2e-16 ***\nORIGIN_SZGLSZ05       6.207e-01  4.375e-03   141.857  &lt; 2e-16 ***\nORIGIN_SZHGSZ01       2.806e-01  4.746e-03    59.121  &lt; 2e-16 ***\nORIGIN_SZHGSZ02       4.917e-01  4.712e-03   104.351  &lt; 2e-16 ***\nORIGIN_SZHGSZ03       2.452e-01  5.113e-03    47.952  &lt; 2e-16 ***\nORIGIN_SZHGSZ04       9.052e-01  4.303e-03   210.358  &lt; 2e-16 ***\nORIGIN_SZHGSZ05       1.170e+00  4.253e-03   275.033  &lt; 2e-16 ***\nORIGIN_SZHGSZ06      -1.016e-01  5.413e-03   -18.773  &lt; 2e-16 ***\nORIGIN_SZHGSZ07       6.984e-01  4.455e-03   156.757  &lt; 2e-16 ***\nORIGIN_SZHGSZ08       1.005e-01  5.354e-03    18.781  &lt; 2e-16 ***\nORIGIN_SZHGSZ09      -5.390e-01  6.962e-03   -77.417  &lt; 2e-16 ***\nORIGIN_SZHGSZ10      -3.512e+00  4.211e-02   -83.388  &lt; 2e-16 ***\nORIGIN_SZJESZ01       4.022e-01  4.869e-03    82.601  &lt; 2e-16 ***\nORIGIN_SZJESZ02       2.273e-01  4.924e-03    46.158  &lt; 2e-16 ***\nORIGIN_SZJESZ03       1.829e-01  5.286e-03    34.598  &lt; 2e-16 ***\nORIGIN_SZJESZ04      -1.177e+00  9.142e-03  -128.767  &lt; 2e-16 ***\nORIGIN_SZJESZ05      -2.065e+00  1.382e-02  -149.494  &lt; 2e-16 ***\nORIGIN_SZJESZ06       2.301e-01  4.853e-03    47.410  &lt; 2e-16 ***\nORIGIN_SZJESZ07      -1.889e+00  1.183e-02  -159.599  &lt; 2e-16 ***\nORIGIN_SZJESZ08      -1.062e+00  1.147e-02   -92.551  &lt; 2e-16 ***\nORIGIN_SZJESZ09       5.237e-01  4.959e-03   105.612  &lt; 2e-16 ***\nORIGIN_SZJESZ10      -1.829e+00  1.800e-02  -101.616  &lt; 2e-16 ***\nORIGIN_SZJESZ11      -2.023e+00  1.931e-02  -104.738  &lt; 2e-16 ***\nORIGIN_SZJWSZ01       2.125e-01  6.405e-03    33.183  &lt; 2e-16 ***\nORIGIN_SZJWSZ02       8.858e-01  4.521e-03   195.929  &lt; 2e-16 ***\nORIGIN_SZJWSZ03       1.269e+00  4.188e-03   302.922  &lt; 2e-16 ***\nORIGIN_SZJWSZ04       1.284e+00  4.280e-03   300.017  &lt; 2e-16 ***\nORIGIN_SZJWSZ05      -1.393e+00  1.252e-02  -111.339  &lt; 2e-16 ***\nORIGIN_SZJWSZ06      -1.015e+00  1.067e-02   -95.109  &lt; 2e-16 ***\nORIGIN_SZJWSZ07      -2.694e+00  2.751e-02   -97.911  &lt; 2e-16 ***\nORIGIN_SZJWSZ08       1.950e+00  4.110e-03   474.430  &lt; 2e-16 ***\nORIGIN_SZJWSZ09       1.831e+00  3.899e-03   469.595  &lt; 2e-16 ***\nORIGIN_SZKLSZ01       1.636e-01  4.902e-03    33.374  &lt; 2e-16 ***\nORIGIN_SZKLSZ02      -5.156e-01  6.321e-03   -81.570  &lt; 2e-16 ***\nORIGIN_SZKLSZ03      -4.145e-01  5.949e-03   -69.666  &lt; 2e-16 ***\nORIGIN_SZKLSZ04      -2.283e+00  1.187e-02  -192.327  &lt; 2e-16 ***\nORIGIN_SZKLSZ05      -8.593e-01  8.272e-03  -103.882  &lt; 2e-16 ***\nORIGIN_SZKLSZ06      -4.709e+00  1.857e-01   -25.352  &lt; 2e-16 ***\nORIGIN_SZKLSZ07      -1.123e+00  8.408e-03  -133.615  &lt; 2e-16 ***\nORIGIN_SZKLSZ08      -1.476e+00  9.152e-03  -161.321  &lt; 2e-16 ***\nORIGIN_SZLKSZ01      -3.273e+00  3.875e-02   -84.465  &lt; 2e-16 ***\nORIGIN_SZMDSZ01      -2.615e+00  2.802e-02   -93.303  &lt; 2e-16 ***\nORIGIN_SZMDSZ02      -8.945e-01  1.035e-02   -86.389  &lt; 2e-16 ***\nORIGIN_SZMDSZ03      -1.998e+00  1.703e-02  -117.297  &lt; 2e-16 ***\nORIGIN_SZMPSZ01      -1.093e+00  8.367e-03  -130.656  &lt; 2e-16 ***\nORIGIN_SZMPSZ02      -5.975e-01  6.898e-03   -86.616  &lt; 2e-16 ***\nORIGIN_SZMPSZ03      -9.706e-03  5.319e-03    -1.825  0.06804 .  \nORIGIN_SZMUSZ02      -3.923e+00  1.038e-01   -37.806  &lt; 2e-16 ***\nORIGIN_SZNTSZ01      -2.829e+00  3.529e-02   -80.157  &lt; 2e-16 ***\nORIGIN_SZNTSZ02      -3.256e+00  2.323e-02  -140.180  &lt; 2e-16 ***\nORIGIN_SZNTSZ03      -9.865e-01  7.777e-03  -126.848  &lt; 2e-16 ***\nORIGIN_SZNTSZ05      -3.353e+00  4.964e-02   -67.546  &lt; 2e-16 ***\nORIGIN_SZNTSZ06      -3.818e+00  5.576e-02   -68.483  &lt; 2e-16 ***\nORIGIN_SZNVSZ01       4.449e-01  4.482e-03    99.269  &lt; 2e-16 ***\nORIGIN_SZNVSZ02      -6.279e-01  6.470e-03   -97.044  &lt; 2e-16 ***\nORIGIN_SZNVSZ03      -1.212e+00  7.788e-03  -155.644  &lt; 2e-16 ***\nORIGIN_SZNVSZ04      -1.469e+00  9.091e-03  -161.543  &lt; 2e-16 ***\nORIGIN_SZNVSZ05      -2.628e+00  1.579e-02  -166.466  &lt; 2e-16 ***\nORIGIN_SZPGSZ01      -9.541e-01  1.223e-02   -78.035  &lt; 2e-16 ***\nORIGIN_SZPGSZ02      -5.353e-01  7.233e-03   -74.009  &lt; 2e-16 ***\nORIGIN_SZPGSZ03       9.574e-01  4.437e-03   215.779  &lt; 2e-16 ***\nORIGIN_SZPGSZ04       1.110e+00  4.417e-03   251.169  &lt; 2e-16 ***\nORIGIN_SZPGSZ05       2.658e-01  5.758e-03    46.156  &lt; 2e-16 ***\nORIGIN_SZPLSZ01      -8.153e-01  1.044e-02   -78.119  &lt; 2e-16 ***\nORIGIN_SZPLSZ02      -1.675e+00  1.478e-02  -113.340  &lt; 2e-16 ***\nORIGIN_SZPLSZ03      -2.963e+00  3.672e-02   -80.686  &lt; 2e-16 ***\nORIGIN_SZPLSZ04      -3.279e+00  3.684e-02   -89.012  &lt; 2e-16 ***\nORIGIN_SZPLSZ05      -2.466e+00  2.245e-02  -109.864  &lt; 2e-16 ***\nORIGIN_SZPNSZ01       1.411e+00  4.584e-03   307.690  &lt; 2e-16 ***\nORIGIN_SZPNSZ02      -5.043e-01  1.108e-02   -45.503  &lt; 2e-16 ***\nORIGIN_SZPNSZ03      -1.878e+00  1.940e-02   -96.796  &lt; 2e-16 ***\nORIGIN_SZPNSZ04      -2.761e+00  3.112e-02   -88.706  &lt; 2e-16 ***\nORIGIN_SZPNSZ05      -2.277e+00  2.628e-02   -86.662  &lt; 2e-16 ***\nORIGIN_SZPRSZ01      -7.934e-01  1.142e-02   -69.499  &lt; 2e-16 ***\nORIGIN_SZPRSZ02       9.414e-01  4.615e-03   203.981  &lt; 2e-16 ***\nORIGIN_SZPRSZ03       7.674e-01  4.626e-03   165.881  &lt; 2e-16 ***\nORIGIN_SZPRSZ04      -3.771e-01  7.516e-03   -50.168  &lt; 2e-16 ***\nORIGIN_SZPRSZ05       1.327e+00  4.325e-03   306.737  &lt; 2e-16 ***\nORIGIN_SZPRSZ06      -4.081e-01  8.651e-03   -47.172  &lt; 2e-16 ***\nORIGIN_SZPRSZ07      -2.151e+00  1.610e-02  -133.558  &lt; 2e-16 ***\nORIGIN_SZPRSZ08       5.293e-04  6.383e-03     0.083  0.93391    \nORIGIN_SZQTSZ01      -4.144e-01  6.846e-03   -60.539  &lt; 2e-16 ***\nORIGIN_SZQTSZ02      -7.967e-01  6.327e-03  -125.933  &lt; 2e-16 ***\nORIGIN_SZQTSZ03      -2.415e-01  5.681e-03   -42.509  &lt; 2e-16 ***\nORIGIN_SZQTSZ04      -1.013e+00  7.129e-03  -142.123  &lt; 2e-16 ***\nORIGIN_SZQTSZ05      -3.923e-01  5.994e-03   -65.446  &lt; 2e-16 ***\nORIGIN_SZQTSZ06      -5.662e-01  6.481e-03   -87.359  &lt; 2e-16 ***\nORIGIN_SZQTSZ07      -1.558e+00  9.635e-03  -161.662  &lt; 2e-16 ***\nORIGIN_SZQTSZ08      -1.577e-01  5.699e-03   -27.665  &lt; 2e-16 ***\nORIGIN_SZQTSZ09      -6.189e-01  6.633e-03   -93.312  &lt; 2e-16 ***\nORIGIN_SZQTSZ10      -4.511e-01  6.512e-03   -69.271  &lt; 2e-16 ***\nORIGIN_SZQTSZ11      -1.455e+00  9.800e-03  -148.421  &lt; 2e-16 ***\nORIGIN_SZQTSZ12      -1.475e+00  1.044e-02  -141.309  &lt; 2e-16 ***\nORIGIN_SZQTSZ13      -3.529e-01  6.413e-03   -55.038  &lt; 2e-16 ***\nORIGIN_SZQTSZ14      -1.591e+00  9.847e-03  -161.565  &lt; 2e-16 ***\nORIGIN_SZQTSZ15      -8.955e-01  1.027e-02   -87.184  &lt; 2e-16 ***\nORIGIN_SZRCSZ01      -1.375e+00  1.265e-02  -108.704  &lt; 2e-16 ***\nORIGIN_SZRCSZ06      -6.196e-01  8.475e-03   -73.116  &lt; 2e-16 ***\nORIGIN_SZRVSZ01      -3.523e+00  3.237e-02  -108.818  &lt; 2e-16 ***\nORIGIN_SZRVSZ02      -2.912e+00  2.776e-02  -104.868  &lt; 2e-16 ***\nORIGIN_SZRVSZ03      -3.145e+00  2.379e-02  -132.232  &lt; 2e-16 ***\nORIGIN_SZRVSZ04      -3.357e+00  5.567e-02   -60.309  &lt; 2e-16 ***\nORIGIN_SZRVSZ05      -2.438e+00  1.644e-02  -148.272  &lt; 2e-16 ***\nORIGIN_SZSBSZ01       5.890e-01  5.529e-03   106.520  &lt; 2e-16 ***\nORIGIN_SZSBSZ02      -7.098e-01  8.213e-03   -86.432  &lt; 2e-16 ***\nORIGIN_SZSBSZ03       9.634e-01  4.611e-03   208.943  &lt; 2e-16 ***\nORIGIN_SZSBSZ04       7.729e-01  5.289e-03   146.136  &lt; 2e-16 ***\nORIGIN_SZSBSZ05      -9.966e-02  6.543e-03   -15.231  &lt; 2e-16 ***\nORIGIN_SZSBSZ06      -1.778e+00  1.719e-02  -103.427  &lt; 2e-16 ***\nORIGIN_SZSBSZ07      -1.161e+00  1.256e-02   -92.436  &lt; 2e-16 ***\nORIGIN_SZSBSZ08      -1.212e+00  1.222e-02   -99.227  &lt; 2e-16 ***\nORIGIN_SZSBSZ09      -5.783e-01  8.579e-03   -67.412  &lt; 2e-16 ***\nORIGIN_SZSESZ02       9.999e-01  4.409e-03   226.798  &lt; 2e-16 ***\nORIGIN_SZSESZ03       1.214e+00  4.164e-03   291.675  &lt; 2e-16 ***\nORIGIN_SZSESZ04       8.141e-01  4.868e-03   167.238  &lt; 2e-16 ***\nORIGIN_SZSESZ05      -2.186e-01  5.915e-03   -36.961  &lt; 2e-16 ***\nORIGIN_SZSESZ06       7.298e-01  4.689e-03   155.641  &lt; 2e-16 ***\nORIGIN_SZSESZ07      -2.543e+00  1.961e-02  -129.689  &lt; 2e-16 ***\nORIGIN_SZSGSZ01      -1.016e+00  8.550e-03  -118.869  &lt; 2e-16 ***\nORIGIN_SZSGSZ02      -1.120e+00  9.589e-03  -116.799  &lt; 2e-16 ***\nORIGIN_SZSGSZ03       2.169e-01  5.167e-03    41.970  &lt; 2e-16 ***\nORIGIN_SZSGSZ04       2.672e-01  4.792e-03    55.757  &lt; 2e-16 ***\nORIGIN_SZSGSZ05      -1.785e+00  1.060e-02  -168.456  &lt; 2e-16 ***\nORIGIN_SZSGSZ06       4.017e-01  4.541e-03    88.470  &lt; 2e-16 ***\nORIGIN_SZSGSZ07      -6.303e-01  6.235e-03  -101.098  &lt; 2e-16 ***\nORIGIN_SZSKSZ01      -1.928e-01  7.765e-03   -24.826  &lt; 2e-16 ***\nORIGIN_SZSKSZ02       3.870e-01  5.689e-03    68.026  &lt; 2e-16 ***\nORIGIN_SZSKSZ03      -6.815e-01  7.983e-03   -85.369  &lt; 2e-16 ***\nORIGIN_SZSKSZ04      -2.528e+00  2.702e-02   -93.548  &lt; 2e-16 ***\nORIGIN_SZSKSZ05      -1.370e+00  1.552e-02   -88.311  &lt; 2e-16 ***\nORIGIN_SZSLSZ01      -3.218e+00  3.058e-02  -105.238  &lt; 2e-16 ***\nORIGIN_SZSLSZ04      -6.800e-01  7.683e-03   -88.497  &lt; 2e-16 ***\nORIGIN_SZSRSZ01      -2.389e+00  1.583e-02  -150.989  &lt; 2e-16 ***\nORIGIN_SZTHSZ01      -2.183e+00  4.887e-02   -44.666  &lt; 2e-16 ***\nORIGIN_SZTHSZ03      -2.243e+00  2.243e-02  -100.025  &lt; 2e-16 ***\nORIGIN_SZTHSZ04      -2.005e+00  2.869e-02   -69.879  &lt; 2e-16 ***\nORIGIN_SZTHSZ06      -2.276e+00  1.784e-02  -127.557  &lt; 2e-16 ***\nORIGIN_SZTMSZ01       4.015e-01  5.814e-03    69.048  &lt; 2e-16 ***\nORIGIN_SZTMSZ02       2.222e+00  3.795e-03   585.568  &lt; 2e-16 ***\nORIGIN_SZTMSZ03       1.412e+00  4.108e-03   343.608  &lt; 2e-16 ***\nORIGIN_SZTMSZ04       9.106e-01  4.742e-03   192.036  &lt; 2e-16 ***\nORIGIN_SZTMSZ05      -3.259e-01  7.534e-03   -43.253  &lt; 2e-16 ***\nORIGIN_SZTNSZ01      -1.806e+00  1.038e-02  -174.076  &lt; 2e-16 ***\nORIGIN_SZTNSZ02      -1.741e+00  9.778e-03  -178.108  &lt; 2e-16 ***\nORIGIN_SZTNSZ03      -2.277e+00  1.338e-02  -170.199  &lt; 2e-16 ***\nORIGIN_SZTNSZ04      -7.703e-01  7.197e-03  -107.032  &lt; 2e-16 ***\nORIGIN_SZTPSZ01      -6.466e-01  6.287e-03  -102.841  &lt; 2e-16 ***\nORIGIN_SZTPSZ02       4.633e-01  4.347e-03   106.578  &lt; 2e-16 ***\nORIGIN_SZTPSZ03      -5.186e-01  6.085e-03   -85.234  &lt; 2e-16 ***\nORIGIN_SZTPSZ04      -2.900e-01  5.779e-03   -50.190  &lt; 2e-16 ***\nORIGIN_SZTPSZ05      -2.169e-01  6.072e-03   -35.720  &lt; 2e-16 ***\nORIGIN_SZTPSZ06       3.357e-01  5.942e-03    56.486  &lt; 2e-16 ***\nORIGIN_SZTPSZ07      -2.517e-01  6.317e-03   -39.846  &lt; 2e-16 ***\nORIGIN_SZTPSZ08      -1.075e+00  9.109e-03  -118.034  &lt; 2e-16 ***\nORIGIN_SZTPSZ09      -3.708e-01  6.189e-03   -59.903  &lt; 2e-16 ***\nORIGIN_SZTPSZ10      -6.889e-01  7.634e-03   -90.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11       7.661e-02  5.459e-03    14.033  &lt; 2e-16 ***\nORIGIN_SZTPSZ12      -5.971e-01  6.522e-03   -91.552  &lt; 2e-16 ***\nORIGIN_SZTSSZ01      -3.517e+00  4.739e-02   -74.210  &lt; 2e-16 ***\nORIGIN_SZTSSZ02       3.022e-01  7.334e-03    41.203  &lt; 2e-16 ***\nORIGIN_SZTSSZ03       3.730e-01  7.073e-03    52.733  &lt; 2e-16 ***\nORIGIN_SZTSSZ04       3.610e-01  7.463e-03    48.372  &lt; 2e-16 ***\nORIGIN_SZTSSZ05      -1.103e+00  1.404e-02   -78.566  &lt; 2e-16 ***\nORIGIN_SZTSSZ06      -1.310e+00  1.718e-02   -76.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ01      -1.233e-01  7.861e-03   -15.690  &lt; 2e-16 ***\nORIGIN_SZWCSZ02      -2.872e+00  3.159e-02   -90.911  &lt; 2e-16 ***\nORIGIN_SZWCSZ03      -4.138e+00  1.241e-01   -33.349  &lt; 2e-16 ***\nORIGIN_SZWDSZ01       1.370e+00  4.146e-03   330.448  &lt; 2e-16 ***\nORIGIN_SZWDSZ02       1.041e+00  4.747e-03   219.219  &lt; 2e-16 ***\nORIGIN_SZWDSZ03       2.189e+00  4.035e-03   542.344  &lt; 2e-16 ***\nORIGIN_SZWDSZ04       1.142e+00  4.963e-03   230.074  &lt; 2e-16 ***\nORIGIN_SZWDSZ05       5.160e-01  4.998e-03   103.230  &lt; 2e-16 ***\nORIGIN_SZWDSZ06       1.208e+00  4.611e-03   262.019  &lt; 2e-16 ***\nORIGIN_SZWDSZ07      -3.805e-01  8.034e-03   -47.365  &lt; 2e-16 ***\nORIGIN_SZWDSZ08      -4.839e-01  7.878e-03   -61.426  &lt; 2e-16 ***\nORIGIN_SZWDSZ09       1.475e+00  4.401e-03   335.097  &lt; 2e-16 ***\nORIGIN_SZYSSZ01      -1.552e-01  5.643e-03   -27.496  &lt; 2e-16 ***\nORIGIN_SZYSSZ02       8.958e-01  4.973e-03   180.144  &lt; 2e-16 ***\nORIGIN_SZYSSZ03       1.757e+00  4.275e-03   411.050  &lt; 2e-16 ***\nORIGIN_SZYSSZ04       8.439e-01  4.538e-03   185.955  &lt; 2e-16 ***\nORIGIN_SZYSSZ05      -9.995e-02  5.920e-03   -16.884  &lt; 2e-16 ***\nORIGIN_SZYSSZ06      -1.175e+00  1.079e-02  -108.835  &lt; 2e-16 ***\nORIGIN_SZYSSZ07      -1.202e+00  1.127e-02  -106.642  &lt; 2e-16 ***\nORIGIN_SZYSSZ08       1.244e-02  6.104e-03     2.039  0.04148 *  \nORIGIN_SZYSSZ09       1.385e+00  4.239e-03   326.757  &lt; 2e-16 ***\nlog(DESTIN_AGE25_64)  2.298e-02  8.832e-05   260.146  &lt; 2e-16 ***\nlog(dist)            -6.947e-01  1.295e-04 -5363.438  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26726668  on 14453  degrees of freedom\nAIC: 26818857\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(orcSIM$data$TRIPS, orcSIM$fitted.values)\n\n[1] 0.4165837"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#destination-constrained",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#destination-constrained",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.7 Destination constrained",
    "text": "8.7 Destination constrained\nn this section, we will fit a destination constrained SIM using the code chunk below.\nThe general formula of Destination Constrained Spatial Interaction Model.\n\n\ndecSIM &lt;- glm(formula = TRIPS ~ \n                DESTIN_SZ + \n                log(ORIGIN_AGE25_64) + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(decSIM)\n\n\nCall:\nglm(formula = TRIPS ~ DESTIN_SZ + log(ORIGIN_AGE25_64) + log(dist), \n    family = poisson(link = \"log\"), data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                       Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)          10.8110189  0.0033476  3229.499  &lt; 2e-16 ***\nDESTIN_SZAMSZ02       0.1775885  0.0041530    42.761  &lt; 2e-16 ***\nDESTIN_SZAMSZ03       0.2064091  0.0040888    50.482  &lt; 2e-16 ***\nDESTIN_SZAMSZ04      -0.9406455  0.0060637  -155.127  &lt; 2e-16 ***\nDESTIN_SZAMSZ05      -1.1578100  0.0061804  -187.337  &lt; 2e-16 ***\nDESTIN_SZAMSZ06      -0.8861493  0.0059241  -149.584  &lt; 2e-16 ***\nDESTIN_SZAMSZ07      -1.7712447  0.0096070  -184.370  &lt; 2e-16 ***\nDESTIN_SZAMSZ08      -1.0707197  0.0067763  -158.009  &lt; 2e-16 ***\nDESTIN_SZAMSZ09      -0.9682250  0.0060435  -160.210  &lt; 2e-16 ***\nDESTIN_SZAMSZ10       0.2612773  0.0043738    59.737  &lt; 2e-16 ***\nDESTIN_SZAMSZ11      -0.3714704  0.0086200   -43.094  &lt; 2e-16 ***\nDESTIN_SZAMSZ12       0.0250455  0.0049850     5.024 5.06e-07 ***\nDESTIN_SZBDSZ01       0.5154763  0.0037827   136.271  &lt; 2e-16 ***\nDESTIN_SZBDSZ02      -0.2843120  0.0049517   -57.417  &lt; 2e-16 ***\nDESTIN_SZBDSZ03      -0.0134646  0.0042692    -3.154  0.00161 ** \nDESTIN_SZBDSZ04       1.0014441  0.0034463   290.582  &lt; 2e-16 ***\nDESTIN_SZBDSZ05       0.3721573  0.0038992    95.445  &lt; 2e-16 ***\nDESTIN_SZBDSZ06       0.2013935  0.0042182    47.744  &lt; 2e-16 ***\nDESTIN_SZBDSZ07      -1.0642612  0.0092942  -114.508  &lt; 2e-16 ***\nDESTIN_SZBDSZ08      -1.7769370  0.0105721  -168.077  &lt; 2e-16 ***\nDESTIN_SZBKSZ01      -1.1944766  0.0065580  -182.141  &lt; 2e-16 ***\nDESTIN_SZBKSZ02      -0.2604946  0.0052044   -50.053  &lt; 2e-16 ***\nDESTIN_SZBKSZ03      -0.5905775  0.0055618  -106.184  &lt; 2e-16 ***\nDESTIN_SZBKSZ04      -0.0521573  0.0048274   -10.804  &lt; 2e-16 ***\nDESTIN_SZBKSZ05      -0.8258599  0.0057094  -144.650  &lt; 2e-16 ***\nDESTIN_SZBKSZ06      -0.8696763  0.0060934  -142.725  &lt; 2e-16 ***\nDESTIN_SZBKSZ07       0.2216292  0.0040334    54.949  &lt; 2e-16 ***\nDESTIN_SZBKSZ08      -1.1179375  0.0068749  -162.612  &lt; 2e-16 ***\nDESTIN_SZBKSZ09      -0.2888733  0.0049056   -58.886  &lt; 2e-16 ***\nDESTIN_SZBLSZ01      -0.4487061  0.0070226   -63.894  &lt; 2e-16 ***\nDESTIN_SZBLSZ02       0.6343096  0.0065174    97.326  &lt; 2e-16 ***\nDESTIN_SZBLSZ03       1.3492337  0.0074135   181.997  &lt; 2e-16 ***\nDESTIN_SZBLSZ04      -0.0339193  0.0131568    -2.578  0.00993 ** \nDESTIN_SZBMSZ01      -0.3497912  0.0046910   -74.567  &lt; 2e-16 ***\nDESTIN_SZBMSZ02      -0.5995634  0.0048828  -122.792  &lt; 2e-16 ***\nDESTIN_SZBMSZ03      -0.8726401  0.0056851  -153.495  &lt; 2e-16 ***\nDESTIN_SZBMSZ04      -0.5350402  0.0048888  -109.442  &lt; 2e-16 ***\nDESTIN_SZBMSZ05      -0.4981814  0.0065971   -75.515  &lt; 2e-16 ***\nDESTIN_SZBMSZ06      -2.0640198  0.0123050  -167.739  &lt; 2e-16 ***\nDESTIN_SZBMSZ07      -0.3100988  0.0045283   -68.480  &lt; 2e-16 ***\nDESTIN_SZBMSZ08      -1.2748152  0.0062622  -203.573  &lt; 2e-16 ***\nDESTIN_SZBMSZ09      -2.8056325  0.0143532  -195.471  &lt; 2e-16 ***\nDESTIN_SZBMSZ10      -1.9166407  0.0089273  -214.693  &lt; 2e-16 ***\nDESTIN_SZBMSZ11      -1.7261160  0.0079281  -217.722  &lt; 2e-16 ***\nDESTIN_SZBMSZ12      -1.1495908  0.0077721  -147.912  &lt; 2e-16 ***\nDESTIN_SZBMSZ13      -0.5428008  0.0050824  -106.799  &lt; 2e-16 ***\nDESTIN_SZBMSZ14      -1.1422302  0.0076325  -149.653  &lt; 2e-16 ***\nDESTIN_SZBMSZ15      -1.2217517  0.0068685  -177.878  &lt; 2e-16 ***\nDESTIN_SZBMSZ16      -2.4074288  0.0107900  -223.116  &lt; 2e-16 ***\nDESTIN_SZBMSZ17      -2.6985491  0.0164771  -163.776  &lt; 2e-16 ***\nDESTIN_SZBPSZ01      -0.6183085  0.0054605  -113.233  &lt; 2e-16 ***\nDESTIN_SZBPSZ02      -1.4579175  0.0083271  -175.080  &lt; 2e-16 ***\nDESTIN_SZBPSZ03      -1.0775392  0.0075109  -143.463  &lt; 2e-16 ***\nDESTIN_SZBPSZ04      -0.6645303  0.0058070  -114.436  &lt; 2e-16 ***\nDESTIN_SZBPSZ05       0.3449386  0.0039504    87.318  &lt; 2e-16 ***\nDESTIN_SZBPSZ06      -0.9360064  0.0077394  -120.941  &lt; 2e-16 ***\nDESTIN_SZBPSZ07      -0.6850065  0.0077761   -88.091  &lt; 2e-16 ***\nDESTIN_SZBSSZ01      -0.3144210  0.0045803   -68.647  &lt; 2e-16 ***\nDESTIN_SZBSSZ02      -0.7531935  0.0051075  -147.469  &lt; 2e-16 ***\nDESTIN_SZBSSZ03       0.1964072  0.0038255    51.342  &lt; 2e-16 ***\nDESTIN_SZBTSZ01       0.0749897  0.0041584    18.033  &lt; 2e-16 ***\nDESTIN_SZBTSZ02      -0.8214254  0.0065659  -125.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ03      -0.1672596  0.0047942   -34.888  &lt; 2e-16 ***\nDESTIN_SZBTSZ04      -1.7727273  0.0103706  -170.938  &lt; 2e-16 ***\nDESTIN_SZBTSZ05      -0.8162630  0.0067401  -121.105  &lt; 2e-16 ***\nDESTIN_SZBTSZ06      -0.8159130  0.0059754  -136.546  &lt; 2e-16 ***\nDESTIN_SZBTSZ07      -2.1139258  0.0105602  -200.178  &lt; 2e-16 ***\nDESTIN_SZBTSZ08      -1.3565179  0.0086828  -156.231  &lt; 2e-16 ***\nDESTIN_SZCBSZ01      -4.6643129  0.3162417   -14.749  &lt; 2e-16 ***\nDESTIN_SZCCSZ01      -1.0088833  0.0080155  -125.866  &lt; 2e-16 ***\nDESTIN_SZCHSZ01      -1.1909317  0.0095262  -125.017  &lt; 2e-16 ***\nDESTIN_SZCHSZ02       0.0890035  0.0052277    17.025  &lt; 2e-16 ***\nDESTIN_SZCHSZ03       1.4883985  0.0039094   380.724  &lt; 2e-16 ***\nDESTIN_SZCKSZ01      -0.1684738  0.0047561   -35.422  &lt; 2e-16 ***\nDESTIN_SZCKSZ02      -0.4314614  0.0051537   -83.720  &lt; 2e-16 ***\nDESTIN_SZCKSZ03       0.6413457  0.0038639   165.983  &lt; 2e-16 ***\nDESTIN_SZCKSZ04      -0.6370791  0.0059869  -106.412  &lt; 2e-16 ***\nDESTIN_SZCKSZ05      -0.4185112  0.0065348   -64.044  &lt; 2e-16 ***\nDESTIN_SZCKSZ06       0.7003888  0.0045139   155.163  &lt; 2e-16 ***\nDESTIN_SZCLSZ01       0.3751343  0.0047400    79.143  &lt; 2e-16 ***\nDESTIN_SZCLSZ02      -2.2913668  0.0133371  -171.804  &lt; 2e-16 ***\nDESTIN_SZCLSZ03      -1.0498490  0.0076548  -137.149  &lt; 2e-16 ***\nDESTIN_SZCLSZ04      -0.1118915  0.0044886   -24.928  &lt; 2e-16 ***\nDESTIN_SZCLSZ05      -1.3113032  0.0084067  -155.983  &lt; 2e-16 ***\nDESTIN_SZCLSZ06       0.1661786  0.0040203    41.334  &lt; 2e-16 ***\nDESTIN_SZCLSZ07      -0.6429895  0.0052617  -122.202  &lt; 2e-16 ***\nDESTIN_SZCLSZ08      -0.4271702  0.0057208   -74.670  &lt; 2e-16 ***\nDESTIN_SZCLSZ09       0.3882136  0.0063758    60.888  &lt; 2e-16 ***\nDESTIN_SZDTSZ02      -3.0106480  0.0348374   -86.420  &lt; 2e-16 ***\nDESTIN_SZDTSZ03      -1.4195712  0.0144110   -98.506  &lt; 2e-16 ***\nDESTIN_SZDTSZ13      -2.2368573  0.0161427  -138.567  &lt; 2e-16 ***\nDESTIN_SZGLSZ01       0.0013721  0.0051224     0.268  0.78881    \nDESTIN_SZGLSZ02      -0.3376674  0.0046195   -73.097  &lt; 2e-16 ***\nDESTIN_SZGLSZ03       0.3659900  0.0038384    95.350  &lt; 2e-16 ***\nDESTIN_SZGLSZ04       0.2969928  0.0038026    78.103  &lt; 2e-16 ***\nDESTIN_SZGLSZ05       0.1786445  0.0038853    45.980  &lt; 2e-16 ***\nDESTIN_SZHGSZ01       0.2979206  0.0038825    76.735  &lt; 2e-16 ***\nDESTIN_SZHGSZ02      -0.5701034  0.0051182  -111.388  &lt; 2e-16 ***\nDESTIN_SZHGSZ03      -1.0387610  0.0061020  -170.233  &lt; 2e-16 ***\nDESTIN_SZHGSZ04      -0.2264881  0.0043617   -51.926  &lt; 2e-16 ***\nDESTIN_SZHGSZ05      -0.2287090  0.0044851   -50.993  &lt; 2e-16 ***\nDESTIN_SZHGSZ06      -0.7896437  0.0054081  -146.010  &lt; 2e-16 ***\nDESTIN_SZHGSZ07       0.2268880  0.0040336    56.249  &lt; 2e-16 ***\nDESTIN_SZHGSZ08      -0.4260784  0.0048967   -87.013  &lt; 2e-16 ***\nDESTIN_SZHGSZ09       0.1027784  0.0051341    20.019  &lt; 2e-16 ***\nDESTIN_SZHGSZ10      -2.8571803  0.0262064  -109.026  &lt; 2e-16 ***\nDESTIN_SZJESZ01      -0.0843635  0.0048222   -17.495  &lt; 2e-16 ***\nDESTIN_SZJESZ02      -0.5197682  0.0051511  -100.904  &lt; 2e-16 ***\nDESTIN_SZJESZ03      -0.6250311  0.0056619  -110.392  &lt; 2e-16 ***\nDESTIN_SZJESZ04      -0.3937360  0.0065536   -60.080  &lt; 2e-16 ***\nDESTIN_SZJESZ05      -0.9748291  0.0097665   -99.814  &lt; 2e-16 ***\nDESTIN_SZJESZ06       0.3642736  0.0040600    89.722  &lt; 2e-16 ***\nDESTIN_SZJESZ07      -1.1571882  0.0081557  -141.887  &lt; 2e-16 ***\nDESTIN_SZJESZ08      -0.5955747  0.0078071   -76.286  &lt; 2e-16 ***\nDESTIN_SZJESZ09      -0.3629500  0.0053966   -67.256  &lt; 2e-16 ***\nDESTIN_SZJESZ10       0.7691552  0.0069348   110.912  &lt; 2e-16 ***\nDESTIN_SZJESZ11       0.9365743  0.0065801   142.335  &lt; 2e-16 ***\nDESTIN_SZJWSZ01      -0.4568805  0.0064536   -70.795  &lt; 2e-16 ***\nDESTIN_SZJWSZ02      -0.2880426  0.0051632   -55.788  &lt; 2e-16 ***\nDESTIN_SZJWSZ03       0.6680404  0.0039264   170.142  &lt; 2e-16 ***\nDESTIN_SZJWSZ04       0.9492158  0.0037186   255.262  &lt; 2e-16 ***\nDESTIN_SZJWSZ05      -0.1938053  0.0060810   -31.871  &lt; 2e-16 ***\nDESTIN_SZJWSZ06       0.3813164  0.0054551    69.900  &lt; 2e-16 ***\nDESTIN_SZJWSZ07      -1.2676010  0.0280038   -45.265  &lt; 2e-16 ***\nDESTIN_SZJWSZ08       0.5013149  0.0044573   112.471  &lt; 2e-16 ***\nDESTIN_SZJWSZ09       1.4161404  0.0033937   417.291  &lt; 2e-16 ***\nDESTIN_SZKLSZ01      -0.6909444  0.0051540  -134.059  &lt; 2e-16 ***\nDESTIN_SZKLSZ02      -0.8146023  0.0057129  -142.589  &lt; 2e-16 ***\nDESTIN_SZKLSZ03      -1.3956114  0.0065167  -214.161  &lt; 2e-16 ***\nDESTIN_SZKLSZ04      -1.9070281  0.0087370  -218.270  &lt; 2e-16 ***\nDESTIN_SZKLSZ05      -0.9293576  0.0071070  -130.766  &lt; 2e-16 ***\nDESTIN_SZKLSZ06      -2.5402234  0.0362062   -70.160  &lt; 2e-16 ***\nDESTIN_SZKLSZ07      -1.2017213  0.0065751  -182.769  &lt; 2e-16 ***\nDESTIN_SZKLSZ08      -0.6083433  0.0050916  -119.480  &lt; 2e-16 ***\nDESTIN_SZLKSZ01      -1.5186810  0.0204155   -74.389  &lt; 2e-16 ***\nDESTIN_SZMDSZ01      -1.4601772  0.0198347   -73.617  &lt; 2e-16 ***\nDESTIN_SZMDSZ02      -1.1554609  0.0111345  -103.773  &lt; 2e-16 ***\nDESTIN_SZMDSZ03      -2.9919337  0.0250838  -119.277  &lt; 2e-16 ***\nDESTIN_SZMPSZ01      -1.1705809  0.0077128  -151.771  &lt; 2e-16 ***\nDESTIN_SZMPSZ02      -0.9380957  0.0060321  -155.517  &lt; 2e-16 ***\nDESTIN_SZMPSZ03      -0.1761013  0.0046389   -37.962  &lt; 2e-16 ***\nDESTIN_SZMUSZ02      -2.4525115  0.0199630  -122.853  &lt; 2e-16 ***\nDESTIN_SZNTSZ01      -3.6605524  0.0447752   -81.754  &lt; 2e-16 ***\nDESTIN_SZNTSZ02      -2.0082021  0.0108736  -184.686  &lt; 2e-16 ***\nDESTIN_SZNTSZ03      -1.2387489  0.0076141  -162.691  &lt; 2e-16 ***\nDESTIN_SZNTSZ05      -1.8054361  0.0249540   -72.351  &lt; 2e-16 ***\nDESTIN_SZNTSZ06      -2.9500517  0.0428601   -68.830  &lt; 2e-16 ***\nDESTIN_SZNVSZ01      -0.4089022  0.0044288   -92.327  &lt; 2e-16 ***\nDESTIN_SZNVSZ02      -0.6865452  0.0052770  -130.102  &lt; 2e-16 ***\nDESTIN_SZNVSZ03      -0.7333670  0.0054243  -135.199  &lt; 2e-16 ***\nDESTIN_SZNVSZ04      -2.2095097  0.0106997  -206.503  &lt; 2e-16 ***\nDESTIN_SZNVSZ05      -1.8721104  0.0089058  -210.212  &lt; 2e-16 ***\nDESTIN_SZPGSZ01      -1.8756618  0.0153008  -122.586  &lt; 2e-16 ***\nDESTIN_SZPGSZ02      -0.9435337  0.0067224  -140.356  &lt; 2e-16 ***\nDESTIN_SZPGSZ03       0.3458476  0.0040152    86.134  &lt; 2e-16 ***\nDESTIN_SZPGSZ04      -0.0271485  0.0044805    -6.059 1.37e-09 ***\nDESTIN_SZPGSZ05      -0.8920273  0.0070730  -126.117  &lt; 2e-16 ***\nDESTIN_SZPLSZ01      -0.2153087  0.0068270   -31.538  &lt; 2e-16 ***\nDESTIN_SZPLSZ02      -1.3646116  0.0131155  -104.046  &lt; 2e-16 ***\nDESTIN_SZPLSZ03      -0.0869245  0.0095838    -9.070  &lt; 2e-16 ***\nDESTIN_SZPLSZ04      -0.2574560  0.0093336   -27.584  &lt; 2e-16 ***\nDESTIN_SZPLSZ05      -0.7186364  0.0116835   -61.509  &lt; 2e-16 ***\nDESTIN_SZPNSZ01       1.1326963  0.0049977   226.643  &lt; 2e-16 ***\nDESTIN_SZPNSZ02       1.6516855  0.0064492   256.106  &lt; 2e-16 ***\nDESTIN_SZPNSZ03       0.8504093  0.0077034   110.394  &lt; 2e-16 ***\nDESTIN_SZPNSZ04       1.6891381  0.0075802   222.836  &lt; 2e-16 ***\nDESTIN_SZPNSZ05       0.7402750  0.0115948    63.845  &lt; 2e-16 ***\nDESTIN_SZPRSZ01      -1.0257636  0.0084652  -121.175  &lt; 2e-16 ***\nDESTIN_SZPRSZ02      -0.2028503  0.0049839   -40.701  &lt; 2e-16 ***\nDESTIN_SZPRSZ03       0.5560483  0.0038496   144.442  &lt; 2e-16 ***\nDESTIN_SZPRSZ04      -0.6824142  0.0079047   -86.330  &lt; 2e-16 ***\nDESTIN_SZPRSZ05       0.0316117  0.0044946     7.033 2.02e-12 ***\nDESTIN_SZPRSZ06       0.3706283  0.0052006    71.267  &lt; 2e-16 ***\nDESTIN_SZPRSZ07      -1.4740460  0.0117304  -125.661  &lt; 2e-16 ***\nDESTIN_SZPRSZ08      -0.7869180  0.0064862  -121.321  &lt; 2e-16 ***\nDESTIN_SZQTSZ01      -1.2790095  0.0085392  -149.781  &lt; 2e-16 ***\nDESTIN_SZQTSZ02      -1.4989188  0.0073423  -204.149  &lt; 2e-16 ***\nDESTIN_SZQTSZ03      -0.9334132  0.0064035  -145.765  &lt; 2e-16 ***\nDESTIN_SZQTSZ04      -1.0506142  0.0065335  -160.805  &lt; 2e-16 ***\nDESTIN_SZQTSZ05      -0.9765013  0.0058471  -167.006  &lt; 2e-16 ***\nDESTIN_SZQTSZ06      -1.2206088  0.0063560  -192.042  &lt; 2e-16 ***\nDESTIN_SZQTSZ07      -1.6794007  0.0108727  -154.460  &lt; 2e-16 ***\nDESTIN_SZQTSZ08      -0.1214413  0.0047980   -25.311  &lt; 2e-16 ***\nDESTIN_SZQTSZ09      -0.5252607  0.0057371   -91.555  &lt; 2e-16 ***\nDESTIN_SZQTSZ10      -0.5981644  0.0054192  -110.378  &lt; 2e-16 ***\nDESTIN_SZQTSZ11      -0.0766021  0.0053446   -14.333  &lt; 2e-16 ***\nDESTIN_SZQTSZ12      -0.6153017  0.0070680   -87.054  &lt; 2e-16 ***\nDESTIN_SZQTSZ13      -0.1690535  0.0051315   -32.944  &lt; 2e-16 ***\nDESTIN_SZQTSZ14      -0.5398362  0.0062233   -86.744  &lt; 2e-16 ***\nDESTIN_SZQTSZ15      -0.1873015  0.0073132   -25.611  &lt; 2e-16 ***\nDESTIN_SZRCSZ01      -0.5875494  0.0071798   -81.833  &lt; 2e-16 ***\nDESTIN_SZRCSZ06      -2.0856090  0.0188789  -110.473  &lt; 2e-16 ***\nDESTIN_SZRVSZ01      -2.6183708  0.0162319  -161.310  &lt; 2e-16 ***\nDESTIN_SZRVSZ02      -3.1882190  0.0326141   -97.756  &lt; 2e-16 ***\nDESTIN_SZRVSZ03      -2.5981974  0.0135074  -192.353  &lt; 2e-16 ***\nDESTIN_SZRVSZ04      -1.9741504  0.0154961  -127.396  &lt; 2e-16 ***\nDESTIN_SZRVSZ05      -3.1547734  0.0256310  -123.084  &lt; 2e-16 ***\nDESTIN_SZSBSZ01      -0.3097949  0.0060601   -51.121  &lt; 2e-16 ***\nDESTIN_SZSBSZ02      -1.1229132  0.0076338  -147.097  &lt; 2e-16 ***\nDESTIN_SZSBSZ03       0.6289715  0.0041400   151.926  &lt; 2e-16 ***\nDESTIN_SZSBSZ04       0.1419430  0.0051357    27.638  &lt; 2e-16 ***\nDESTIN_SZSBSZ05      -0.9256413  0.0071963  -128.628  &lt; 2e-16 ***\nDESTIN_SZSBSZ06      -2.3487368  0.0221611  -105.984  &lt; 2e-16 ***\nDESTIN_SZSBSZ07      -0.7864630  0.0181706   -43.282  &lt; 2e-16 ***\nDESTIN_SZSBSZ08       1.3240051  0.0051598   256.599  &lt; 2e-16 ***\nDESTIN_SZSBSZ09       0.8431156  0.0048330   174.449  &lt; 2e-16 ***\nDESTIN_SZSESZ02      -0.2385874  0.0046618   -51.180  &lt; 2e-16 ***\nDESTIN_SZSESZ03       0.5439188  0.0036932   147.276  &lt; 2e-16 ***\nDESTIN_SZSESZ04      -0.6715716  0.0054222  -123.856  &lt; 2e-16 ***\nDESTIN_SZSESZ05      -0.3601932  0.0047508   -75.818  &lt; 2e-16 ***\nDESTIN_SZSESZ06      -0.6088413  0.0057017  -106.782  &lt; 2e-16 ***\nDESTIN_SZSESZ07      -2.9477507  0.0226797  -129.973  &lt; 2e-16 ***\nDESTIN_SZSGSZ01      -0.5100640  0.0058280   -87.519  &lt; 2e-16 ***\nDESTIN_SZSGSZ02      -0.0439941  0.0051633    -8.520  &lt; 2e-16 ***\nDESTIN_SZSGSZ03      -0.3700648  0.0047152   -78.483  &lt; 2e-16 ***\nDESTIN_SZSGSZ04      -0.3021335  0.0046865   -64.468  &lt; 2e-16 ***\nDESTIN_SZSGSZ05      -2.2253287  0.0097908  -227.288  &lt; 2e-16 ***\nDESTIN_SZSGSZ06       0.2963602  0.0037948    78.097  &lt; 2e-16 ***\nDESTIN_SZSGSZ07      -0.5940373  0.0051371  -115.637  &lt; 2e-16 ***\nDESTIN_SZSISZ01      -1.4528976  0.0257790   -56.360  &lt; 2e-16 ***\nDESTIN_SZSKSZ01      -0.0374952  0.0066885    -5.606 2.07e-08 ***\nDESTIN_SZSKSZ02       0.7271418  0.0050281   144.617  &lt; 2e-16 ***\nDESTIN_SZSKSZ03      -0.0640794  0.0059146   -10.834  &lt; 2e-16 ***\nDESTIN_SZSKSZ04      -0.5610767  0.0139676   -40.170  &lt; 2e-16 ***\nDESTIN_SZSKSZ05       0.1510974  0.0104871    14.408  &lt; 2e-16 ***\nDESTIN_SZSLSZ01      -0.5823031  0.0083356   -69.858  &lt; 2e-16 ***\nDESTIN_SZSLSZ04      -0.8166665  0.0070329  -116.122  &lt; 2e-16 ***\nDESTIN_SZSRSZ01      -2.3241796  0.0127215  -182.696  &lt; 2e-16 ***\nDESTIN_SZTHSZ01      -2.8157635  0.0366840   -76.757  &lt; 2e-16 ***\nDESTIN_SZTHSZ03      -2.1005978  0.0250842   -83.742  &lt; 2e-16 ***\nDESTIN_SZTHSZ04      -2.1246250  0.0213690   -99.425  &lt; 2e-16 ***\nDESTIN_SZTHSZ06      -1.4571092  0.0150031   -97.121  &lt; 2e-16 ***\nDESTIN_SZTMSZ01      -0.1234559  0.0055152   -22.385  &lt; 2e-16 ***\nDESTIN_SZTMSZ02       1.5961628  0.0032599   489.635  &lt; 2e-16 ***\nDESTIN_SZTMSZ03       0.6977233  0.0037138   187.875  &lt; 2e-16 ***\nDESTIN_SZTMSZ04       0.8606606  0.0037592   228.947  &lt; 2e-16 ***\nDESTIN_SZTMSZ05       0.3750655  0.0051281    73.140  &lt; 2e-16 ***\nDESTIN_SZTNSZ01      -1.2624562  0.0066979  -188.485  &lt; 2e-16 ***\nDESTIN_SZTNSZ02      -2.0761581  0.0096538  -215.062  &lt; 2e-16 ***\nDESTIN_SZTNSZ03      -2.1128125  0.0115717  -182.584  &lt; 2e-16 ***\nDESTIN_SZTNSZ04      -1.2417494  0.0068502  -181.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ01      -0.7094356  0.0055768  -127.211  &lt; 2e-16 ***\nDESTIN_SZTPSZ02       0.1491604  0.0037260    40.032  &lt; 2e-16 ***\nDESTIN_SZTPSZ03      -0.4973355  0.0054878   -90.626  &lt; 2e-16 ***\nDESTIN_SZTPSZ04      -1.5160395  0.0071592  -211.761  &lt; 2e-16 ***\nDESTIN_SZTPSZ05      -0.9196565  0.0056750  -162.054  &lt; 2e-16 ***\nDESTIN_SZTPSZ06      -0.2710649  0.0062637   -43.276  &lt; 2e-16 ***\nDESTIN_SZTPSZ07      -2.0198681  0.0116556  -173.296  &lt; 2e-16 ***\nDESTIN_SZTPSZ08      -1.4881412  0.0085532  -173.987  &lt; 2e-16 ***\nDESTIN_SZTPSZ09      -0.5901273  0.0059394   -99.358  &lt; 2e-16 ***\nDESTIN_SZTPSZ10      -1.1215711  0.0084488  -132.749  &lt; 2e-16 ***\nDESTIN_SZTPSZ11      -0.4837089  0.0050905   -95.022  &lt; 2e-16 ***\nDESTIN_SZTPSZ12      -0.8653927  0.0061326  -141.113  &lt; 2e-16 ***\nDESTIN_SZTSSZ01      -0.5515103  0.0208541   -26.446  &lt; 2e-16 ***\nDESTIN_SZTSSZ02       0.8373778  0.0093757    89.314  &lt; 2e-16 ***\nDESTIN_SZTSSZ03       1.7021888  0.0064394   264.340  &lt; 2e-16 ***\nDESTIN_SZTSSZ04       1.5355016  0.0067855   226.292  &lt; 2e-16 ***\nDESTIN_SZTSSZ05       1.6932319  0.0073725   229.668  &lt; 2e-16 ***\nDESTIN_SZTSSZ06       0.4567808  0.0137927    33.118  &lt; 2e-16 ***\nDESTIN_SZWCSZ01       1.3967640  0.0045392   307.711  &lt; 2e-16 ***\nDESTIN_SZWCSZ02      -0.4560229  0.0122949   -37.090  &lt; 2e-16 ***\nDESTIN_SZWCSZ03      -2.0710051  0.0325121   -63.699  &lt; 2e-16 ***\nDESTIN_SZWDSZ01       1.5137342  0.0034774   435.310  &lt; 2e-16 ***\nDESTIN_SZWDSZ02      -0.3005475  0.0055149   -54.497  &lt; 2e-16 ***\nDESTIN_SZWDSZ03       1.2514543  0.0036112   346.550  &lt; 2e-16 ***\nDESTIN_SZWDSZ04      -0.1702528  0.0058295   -29.205  &lt; 2e-16 ***\nDESTIN_SZWDSZ05      -0.0005419  0.0053911    -0.101  0.91994    \nDESTIN_SZWDSZ06       0.5203361  0.0040318   129.058  &lt; 2e-16 ***\nDESTIN_SZWDSZ07       0.6006472  0.0061745    97.279  &lt; 2e-16 ***\nDESTIN_SZWDSZ08       0.6650867  0.0060867   109.268  &lt; 2e-16 ***\nDESTIN_SZWDSZ09       0.6237312  0.0044830   139.132  &lt; 2e-16 ***\nDESTIN_SZYSSZ01       1.0471638  0.0038255   273.732  &lt; 2e-16 ***\nDESTIN_SZYSSZ02       0.2341114  0.0048213    48.558  &lt; 2e-16 ***\nDESTIN_SZYSSZ03      -0.0916446  0.0051335   -17.852  &lt; 2e-16 ***\nDESTIN_SZYSSZ04      -0.0085536  0.0048684    -1.757  0.07892 .  \nDESTIN_SZYSSZ05      -1.5775071  0.0100297  -157.283  &lt; 2e-16 ***\nDESTIN_SZYSSZ06      -1.8130307  0.0098617  -183.846  &lt; 2e-16 ***\nDESTIN_SZYSSZ07      -1.1703963  0.0111525  -104.945  &lt; 2e-16 ***\nDESTIN_SZYSSZ08       0.5253514  0.0039556   132.813  &lt; 2e-16 ***\nDESTIN_SZYSSZ09       0.4353435  0.0038890   111.943  &lt; 2e-16 ***\nlog(ORIGIN_AGE25_64)  0.2249135  0.0001404  1602.353  &lt; 2e-16 ***\nlog(dist)            -0.6989356  0.0001287 -5431.279  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 26208384  on 14452  degrees of freedom\nAIC: 26300575\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(decSIM$data$TRIPS, decSIM$fitted.values)\n\n[1] 0.4972985"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#doubly-constrained",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#doubly-constrained",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.8 Doubly constrained",
    "text": "8.8 Doubly constrained\nIn this section, we fit a doubly constrained SIM by using the code chunk below.\nThe general formula of Doubly Constrained Spatial Interaction Model.\n\n\ndbcSIM &lt;- glm(formula = TRIPS ~ \n                ORIGIN_SZ + \n                DESTIN_SZ + \n                log(dist),\n              family = poisson(link = \"log\"),\n              data = SIM_data,\n              na.action = na.exclude)\nsummary(dbcSIM)\n\n\nCall:\nglm(formula = TRIPS ~ ORIGIN_SZ + DESTIN_SZ + log(dist), family = poisson(link = \"log\"), \n    data = SIM_data, na.action = na.exclude)\n\nCoefficients:\n                  Estimate Std. Error   z value Pr(&gt;|z|)    \n(Intercept)     12.4165310  0.0043949  2825.242  &lt; 2e-16 ***\nORIGIN_SZAMSZ02  0.9496891  0.0045740   207.630  &lt; 2e-16 ***\nORIGIN_SZAMSZ03  0.5519174  0.0046672   118.253  &lt; 2e-16 ***\nORIGIN_SZAMSZ04  0.1028140  0.0052468    19.596  &lt; 2e-16 ***\nORIGIN_SZAMSZ05  0.0822549  0.0058663    14.022  &lt; 2e-16 ***\nORIGIN_SZAMSZ06  0.6617809  0.0052580   125.861  &lt; 2e-16 ***\nORIGIN_SZAMSZ07 -0.9508298  0.0097681   -97.340  &lt; 2e-16 ***\nORIGIN_SZAMSZ08 -0.7271779  0.0090946   -79.958  &lt; 2e-16 ***\nORIGIN_SZAMSZ09  0.4896781  0.0055203    88.704  &lt; 2e-16 ***\nORIGIN_SZAMSZ10  0.4819428  0.0048175   100.040  &lt; 2e-16 ***\nORIGIN_SZAMSZ11 -1.7719841  0.0130695  -135.582  &lt; 2e-16 ***\nORIGIN_SZAMSZ12 -1.7679107  0.0108777  -162.526  &lt; 2e-16 ***\nORIGIN_SZBDSZ01  0.8314812  0.0045187   184.010  &lt; 2e-16 ***\nORIGIN_SZBDSZ02  0.4305836  0.0052535    81.961  &lt; 2e-16 ***\nORIGIN_SZBDSZ03  0.8009370  0.0046384   172.676  &lt; 2e-16 ***\nORIGIN_SZBDSZ04  1.4562985  0.0040456   359.971  &lt; 2e-16 ***\nORIGIN_SZBDSZ05  0.4501939  0.0046960    95.867  &lt; 2e-16 ***\nORIGIN_SZBDSZ06  0.7745026  0.0047424   163.314  &lt; 2e-16 ***\nORIGIN_SZBDSZ07 -1.1784123  0.0098105  -120.117  &lt; 2e-16 ***\nORIGIN_SZBDSZ08 -0.9830996  0.0091135  -107.873  &lt; 2e-16 ***\nORIGIN_SZBKSZ01 -0.3042966  0.0067086   -45.359  &lt; 2e-16 ***\nORIGIN_SZBKSZ02  0.4801541  0.0054160    88.655  &lt; 2e-16 ***\nORIGIN_SZBKSZ03  0.7823931  0.0052007   150.440  &lt; 2e-16 ***\nORIGIN_SZBKSZ04 -0.1292545  0.0061735   -20.937  &lt; 2e-16 ***\nORIGIN_SZBKSZ05 -0.0258584  0.0060192    -4.296 1.74e-05 ***\nORIGIN_SZBKSZ06  0.1994719  0.0061206    32.590  &lt; 2e-16 ***\nORIGIN_SZBKSZ07  0.7434860  0.0046598   159.553  &lt; 2e-16 ***\nORIGIN_SZBKSZ08  0.1625007  0.0055219    29.428  &lt; 2e-16 ***\nORIGIN_SZBKSZ09 -0.0864293  0.0059533   -14.518  &lt; 2e-16 ***\nORIGIN_SZBLSZ01 -2.1022485  0.0150316  -139.855  &lt; 2e-16 ***\nORIGIN_SZBLSZ02 -2.9460181  0.0195760  -150.491  &lt; 2e-16 ***\nORIGIN_SZBLSZ03 -4.9412872  0.0398540  -123.985  &lt; 2e-16 ***\nORIGIN_SZBLSZ04 -2.8143593  0.0239209  -117.653  &lt; 2e-16 ***\nORIGIN_SZBMSZ01 -0.0264561  0.0053639    -4.932 8.13e-07 ***\nORIGIN_SZBMSZ02 -0.8656513  0.0068511  -126.353  &lt; 2e-16 ***\nORIGIN_SZBMSZ03 -0.1723467  0.0059613   -28.911  &lt; 2e-16 ***\nORIGIN_SZBMSZ04  0.2169844  0.0053578    40.499  &lt; 2e-16 ***\nORIGIN_SZBMSZ05 -2.0252956  0.0126107  -160.602  &lt; 2e-16 ***\nORIGIN_SZBMSZ06 -1.7642018  0.0163931  -107.619  &lt; 2e-16 ***\nORIGIN_SZBMSZ07 -0.3271629  0.0058137   -56.274  &lt; 2e-16 ***\nORIGIN_SZBMSZ08 -0.2533255  0.0059335   -42.694  &lt; 2e-16 ***\nORIGIN_SZBMSZ09 -0.7712635  0.0087939   -87.704  &lt; 2e-16 ***\nORIGIN_SZBMSZ10 -1.0098048  0.0092519  -109.145  &lt; 2e-16 ***\nORIGIN_SZBMSZ11 -0.3816187  0.0067302   -56.702  &lt; 2e-16 ***\nORIGIN_SZBMSZ12 -0.6666616  0.0095680   -69.676  &lt; 2e-16 ***\nORIGIN_SZBMSZ13 -0.0076108  0.0059040    -1.289  0.19737    \nORIGIN_SZBMSZ14 -0.1682476  0.0069391   -24.246  &lt; 2e-16 ***\nORIGIN_SZBMSZ15  0.0904585  0.0062822    14.399  &lt; 2e-16 ***\nORIGIN_SZBMSZ16 -1.1808741  0.0092258  -127.997  &lt; 2e-16 ***\nORIGIN_SZBMSZ17 -1.7189127  0.0158408  -108.512  &lt; 2e-16 ***\nORIGIN_SZBPSZ01  0.4294645  0.0058051    73.980  &lt; 2e-16 ***\nORIGIN_SZBPSZ02  0.5028906  0.0068169    73.771  &lt; 2e-16 ***\nORIGIN_SZBPSZ03  0.6656178  0.0066126   100.658  &lt; 2e-16 ***\nORIGIN_SZBPSZ04  0.5203612  0.0053224    97.769  &lt; 2e-16 ***\nORIGIN_SZBPSZ05  0.5377769  0.0047907   112.256  &lt; 2e-16 ***\nORIGIN_SZBPSZ06 -1.2327809  0.0094950  -129.835  &lt; 2e-16 ***\nORIGIN_SZBPSZ07 -0.9035255  0.0088739  -101.818  &lt; 2e-16 ***\nORIGIN_SZBSSZ01  0.1210027  0.0053990    22.412  &lt; 2e-16 ***\nORIGIN_SZBSSZ02  0.4618449  0.0048641    94.951  &lt; 2e-16 ***\nORIGIN_SZBSSZ03  0.2160739  0.0047835    45.170  &lt; 2e-16 ***\nORIGIN_SZBTSZ01 -0.1108042  0.0055599   -19.929  &lt; 2e-16 ***\nORIGIN_SZBTSZ02 -0.8911221  0.0079213  -112.498  &lt; 2e-16 ***\nORIGIN_SZBTSZ03 -0.2203980  0.0059325   -37.151  &lt; 2e-16 ***\nORIGIN_SZBTSZ04 -0.6427946  0.0105438   -60.964  &lt; 2e-16 ***\nORIGIN_SZBTSZ05 -1.4662312  0.0111784  -131.166  &lt; 2e-16 ***\nORIGIN_SZBTSZ06 -0.6105884  0.0073456   -83.123  &lt; 2e-16 ***\nORIGIN_SZBTSZ07 -1.9041317  0.0132781  -143.404  &lt; 2e-16 ***\nORIGIN_SZBTSZ08 -1.0627939  0.0095982  -110.728  &lt; 2e-16 ***\nORIGIN_SZCBSZ01 -2.9365941  0.0548632   -53.526  &lt; 2e-16 ***\nORIGIN_SZCCSZ01 -1.5313555  0.0134599  -113.772  &lt; 2e-16 ***\nORIGIN_SZCHSZ01 -1.2034494  0.0119468  -100.734  &lt; 2e-16 ***\nORIGIN_SZCHSZ02 -0.8299415  0.0081984  -101.232  &lt; 2e-16 ***\nORIGIN_SZCHSZ03 -0.5143946  0.0061944   -83.042  &lt; 2e-16 ***\nORIGIN_SZCKSZ01  0.2372583  0.0053612    44.255  &lt; 2e-16 ***\nORIGIN_SZCKSZ02  0.9124836  0.0054472   167.515  &lt; 2e-16 ***\nORIGIN_SZCKSZ03  0.7237808  0.0048401   149.539  &lt; 2e-16 ***\nORIGIN_SZCKSZ04  1.6884022  0.0050169   336.540  &lt; 2e-16 ***\nORIGIN_SZCKSZ05  1.3932005  0.0062346   223.464  &lt; 2e-16 ***\nORIGIN_SZCKSZ06  1.0670053  0.0066112   161.394  &lt; 2e-16 ***\nORIGIN_SZCLSZ01 -0.8602837  0.0079240  -108.567  &lt; 2e-16 ***\nORIGIN_SZCLSZ02 -1.3853421  0.0137444  -100.793  &lt; 2e-16 ***\nORIGIN_SZCLSZ03 -0.8582608  0.0081177  -105.727  &lt; 2e-16 ***\nORIGIN_SZCLSZ04  0.7836027  0.0046427   168.782  &lt; 2e-16 ***\nORIGIN_SZCLSZ05 -1.8121756  0.0148960  -121.655  &lt; 2e-16 ***\nORIGIN_SZCLSZ06  0.8296870  0.0043909   188.955  &lt; 2e-16 ***\nORIGIN_SZCLSZ07 -0.2325219  0.0057432   -40.487  &lt; 2e-16 ***\nORIGIN_SZCLSZ08  0.2714336  0.0062625    43.342  &lt; 2e-16 ***\nORIGIN_SZCLSZ09 -2.2223744  0.0160946  -138.082  &lt; 2e-16 ***\nORIGIN_SZDTSZ02 -4.0704970  0.0834192   -48.796  &lt; 2e-16 ***\nORIGIN_SZDTSZ03 -3.4529031  0.0738295   -46.769  &lt; 2e-16 ***\nORIGIN_SZDTSZ13 -2.8301983  0.0313085   -90.397  &lt; 2e-16 ***\nORIGIN_SZGLSZ01 -1.4674986  0.0093137  -157.563  &lt; 2e-16 ***\nORIGIN_SZGLSZ02  0.2749369  0.0050051    54.931  &lt; 2e-16 ***\nORIGIN_SZGLSZ03  0.0781954  0.0049748    15.718  &lt; 2e-16 ***\nORIGIN_SZGLSZ04  0.8167797  0.0043260   188.808  &lt; 2e-16 ***\nORIGIN_SZGLSZ05  0.5277509  0.0044879   117.595  &lt; 2e-16 ***\nORIGIN_SZHGSZ01  0.2323885  0.0048555    47.861  &lt; 2e-16 ***\nORIGIN_SZHGSZ02  0.5707182  0.0048256   118.268  &lt; 2e-16 ***\nORIGIN_SZHGSZ03  0.4231170  0.0052149    81.136  &lt; 2e-16 ***\nORIGIN_SZHGSZ04  0.9341168  0.0044128   211.681  &lt; 2e-16 ***\nORIGIN_SZHGSZ05  1.2192790  0.0043790   278.437  &lt; 2e-16 ***\nORIGIN_SZHGSZ06  0.0490041  0.0054961     8.916  &lt; 2e-16 ***\nORIGIN_SZHGSZ07  0.6337041  0.0045735   138.559  &lt; 2e-16 ***\nORIGIN_SZHGSZ08  0.0312612  0.0054684     5.717 1.09e-08 ***\nORIGIN_SZHGSZ09 -0.6985397  0.0071800   -97.289  &lt; 2e-16 ***\nORIGIN_SZHGSZ10 -2.9958967  0.0422303   -70.942  &lt; 2e-16 ***\nORIGIN_SZJESZ01  0.4363431  0.0051329    85.010  &lt; 2e-16 ***\nORIGIN_SZJESZ02  0.3460900  0.0051372    67.370  &lt; 2e-16 ***\nORIGIN_SZJESZ03  0.2928005  0.0055108    53.132  &lt; 2e-16 ***\nORIGIN_SZJESZ04 -1.1924298  0.0093540  -127.478  &lt; 2e-16 ***\nORIGIN_SZJESZ05 -2.0178136  0.0139479  -144.668  &lt; 2e-16 ***\nORIGIN_SZJESZ06  0.1637633  0.0050685    32.310  &lt; 2e-16 ***\nORIGIN_SZJESZ07 -1.8227460  0.0119383  -152.680  &lt; 2e-16 ***\nORIGIN_SZJESZ08 -1.1556281  0.0117870   -98.043  &lt; 2e-16 ***\nORIGIN_SZJESZ09  0.4766229  0.0052813    90.248  &lt; 2e-16 ***\nORIGIN_SZJESZ10 -2.6868992  0.0186864  -143.789  &lt; 2e-16 ***\nORIGIN_SZJESZ11 -3.0618150  0.0199755  -153.278  &lt; 2e-16 ***\nORIGIN_SZJWSZ01  0.4417418  0.0068611    64.383  &lt; 2e-16 ***\nORIGIN_SZJWSZ02  0.9738087  0.0047905   203.281  &lt; 2e-16 ***\nORIGIN_SZJWSZ03  1.1548028  0.0045180   255.599  &lt; 2e-16 ***\nORIGIN_SZJWSZ04  0.9078417  0.0046668   194.532  &lt; 2e-16 ***\nORIGIN_SZJWSZ05 -1.7092500  0.0127422  -134.141  &lt; 2e-16 ***\nORIGIN_SZJWSZ06 -1.3284287  0.0109785  -121.002  &lt; 2e-16 ***\nORIGIN_SZJWSZ07 -2.3231549  0.0281427   -82.549  &lt; 2e-16 ***\nORIGIN_SZJWSZ08  1.9386127  0.0046041   421.059  &lt; 2e-16 ***\nORIGIN_SZJWSZ09  1.3987549  0.0042610   328.266  &lt; 2e-16 ***\nORIGIN_SZKLSZ01  0.2617735  0.0050089    52.261  &lt; 2e-16 ***\nORIGIN_SZKLSZ02 -0.4325093  0.0064279   -67.286  &lt; 2e-16 ***\nORIGIN_SZKLSZ03 -0.2787173  0.0060380   -46.161  &lt; 2e-16 ***\nORIGIN_SZKLSZ04 -1.9432693  0.0119163  -163.076  &lt; 2e-16 ***\nORIGIN_SZKLSZ05 -0.5420067  0.0085529   -63.371  &lt; 2e-16 ***\nORIGIN_SZKLSZ06 -4.2949009  0.1857686   -23.120  &lt; 2e-16 ***\nORIGIN_SZKLSZ07 -0.8576946  0.0085178  -100.694  &lt; 2e-16 ***\nORIGIN_SZKLSZ08 -1.3840925  0.0092323  -149.918  &lt; 2e-16 ***\nORIGIN_SZLKSZ01 -2.8108510  0.0392356   -71.640  &lt; 2e-16 ***\nORIGIN_SZMDSZ01 -1.6745388  0.0296543   -56.469  &lt; 2e-16 ***\nORIGIN_SZMDSZ02 -0.8193738  0.0106631   -76.842  &lt; 2e-16 ***\nORIGIN_SZMDSZ03 -1.5088267  0.0172032   -87.706  &lt; 2e-16 ***\nORIGIN_SZMPSZ01 -0.9860154  0.0085053  -115.929  &lt; 2e-16 ***\nORIGIN_SZMPSZ02 -0.5958875  0.0070097   -85.008  &lt; 2e-16 ***\nORIGIN_SZMPSZ03 -0.0490122  0.0054582    -8.980  &lt; 2e-16 ***\nORIGIN_SZMUSZ02 -3.5233367  0.1037749   -33.952  &lt; 2e-16 ***\nORIGIN_SZNTSZ01 -2.6451541  0.0353125   -74.907  &lt; 2e-16 ***\nORIGIN_SZNTSZ02 -2.7710546  0.0232841  -119.011  &lt; 2e-16 ***\nORIGIN_SZNTSZ03 -0.6123404  0.0079083   -77.430  &lt; 2e-16 ***\nORIGIN_SZNTSZ05 -2.9257445  0.0496704   -58.903  &lt; 2e-16 ***\nORIGIN_SZNTSZ06 -3.3260031  0.0557966   -59.609  &lt; 2e-16 ***\nORIGIN_SZNVSZ01  0.6421306  0.0046037   139.482  &lt; 2e-16 ***\nORIGIN_SZNVSZ02 -0.4251550  0.0065890   -64.525  &lt; 2e-16 ***\nORIGIN_SZNVSZ03 -1.0765622  0.0078766  -136.679  &lt; 2e-16 ***\nORIGIN_SZNVSZ04 -1.2289504  0.0091468  -134.358  &lt; 2e-16 ***\nORIGIN_SZNVSZ05 -2.3551389  0.0158219  -148.853  &lt; 2e-16 ***\nORIGIN_SZPGSZ01  0.1518212  0.0154825     9.806  &lt; 2e-16 ***\nORIGIN_SZPGSZ02 -0.4062609  0.0073780   -55.064  &lt; 2e-16 ***\nORIGIN_SZPGSZ03  0.8976913  0.0046122   194.636  &lt; 2e-16 ***\nORIGIN_SZPGSZ04  1.1161685  0.0045850   243.437  &lt; 2e-16 ***\nORIGIN_SZPGSZ05  0.4794249  0.0060213    79.621  &lt; 2e-16 ***\nORIGIN_SZPLSZ01 -0.8322377  0.0107898   -77.132  &lt; 2e-16 ***\nORIGIN_SZPLSZ02 -1.2968937  0.0149841   -86.551  &lt; 2e-16 ***\nORIGIN_SZPLSZ03 -3.2744991  0.0374541   -87.427  &lt; 2e-16 ***\nORIGIN_SZPLSZ04 -3.5423615  0.0372570   -95.079  &lt; 2e-16 ***\nORIGIN_SZPLSZ05 -2.4343705  0.0227807  -106.861  &lt; 2e-16 ***\nORIGIN_SZPNSZ01  0.8052461  0.0056124   143.476  &lt; 2e-16 ***\nORIGIN_SZPNSZ02 -1.8042362  0.0128222  -140.712  &lt; 2e-16 ***\nORIGIN_SZPNSZ03 -2.6363996  0.0200058  -131.782  &lt; 2e-16 ***\nORIGIN_SZPNSZ04 -4.8427070  0.0320126  -151.275  &lt; 2e-16 ***\nORIGIN_SZPNSZ05 -3.6613775  0.0285686  -128.161  &lt; 2e-16 ***\nORIGIN_SZPRSZ01 -0.5645384  0.0117126   -48.199  &lt; 2e-16 ***\nORIGIN_SZPRSZ02  0.9145886  0.0048137   189.998  &lt; 2e-16 ***\nORIGIN_SZPRSZ03  0.4478971  0.0048102    93.113  &lt; 2e-16 ***\nORIGIN_SZPRSZ04 -0.5312444  0.0079019   -67.230  &lt; 2e-16 ***\nORIGIN_SZPRSZ05  1.1462662  0.0045250   253.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ06 -0.7392744  0.0090347   -81.826  &lt; 2e-16 ***\nORIGIN_SZPRSZ07 -2.1667862  0.0162528  -133.318  &lt; 2e-16 ***\nORIGIN_SZPRSZ08 -0.1327079  0.0065712   -20.195  &lt; 2e-16 ***\nORIGIN_SZQTSZ01  0.1062151  0.0071538    14.847  &lt; 2e-16 ***\nORIGIN_SZQTSZ02 -0.4993990  0.0064382   -77.568  &lt; 2e-16 ***\nORIGIN_SZQTSZ03  0.1161844  0.0058822    19.752  &lt; 2e-16 ***\nORIGIN_SZQTSZ04 -0.8102612  0.0072742  -111.389  &lt; 2e-16 ***\nORIGIN_SZQTSZ05 -0.0417272  0.0061917    -6.739 1.59e-11 ***\nORIGIN_SZQTSZ06 -0.2521417  0.0066449   -37.945  &lt; 2e-16 ***\nORIGIN_SZQTSZ07 -1.2395975  0.0097496  -127.143  &lt; 2e-16 ***\nORIGIN_SZQTSZ08 -0.1105467  0.0059364   -18.622  &lt; 2e-16 ***\nORIGIN_SZQTSZ09 -0.5078461  0.0067895   -74.798  &lt; 2e-16 ***\nORIGIN_SZQTSZ10 -0.3866593  0.0066995   -57.714  &lt; 2e-16 ***\nORIGIN_SZQTSZ11 -1.5264609  0.0099770  -152.998  &lt; 2e-16 ***\nORIGIN_SZQTSZ12 -1.3866518  0.0106887  -129.730  &lt; 2e-16 ***\nORIGIN_SZQTSZ13 -0.3764286  0.0066707   -56.430  &lt; 2e-16 ***\nORIGIN_SZQTSZ14 -1.4907399  0.0100120  -148.896  &lt; 2e-16 ***\nORIGIN_SZQTSZ15 -1.0552239  0.0108792   -96.994  &lt; 2e-16 ***\nORIGIN_SZRCSZ01 -1.3136074  0.0126986  -103.445  &lt; 2e-16 ***\nORIGIN_SZRCSZ06 -0.2418276  0.0085509   -28.281  &lt; 2e-16 ***\nORIGIN_SZRVSZ01 -2.9263747  0.0324968   -90.051  &lt; 2e-16 ***\nORIGIN_SZRVSZ02 -2.2980940  0.0278202   -82.605  &lt; 2e-16 ***\nORIGIN_SZRVSZ03 -2.4663765  0.0238674  -103.336  &lt; 2e-16 ***\nORIGIN_SZRVSZ04 -3.1853677  0.0556939   -57.194  &lt; 2e-16 ***\nORIGIN_SZRVSZ05 -1.5695490  0.0166684   -94.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ01  0.7674590  0.0061811   124.163  &lt; 2e-16 ***\nORIGIN_SZSBSZ02 -0.7307279  0.0084105   -86.883  &lt; 2e-16 ***\nORIGIN_SZSBSZ03  0.5920074  0.0050167   118.008  &lt; 2e-16 ***\nORIGIN_SZSBSZ04  0.3684857  0.0058575    62.908  &lt; 2e-16 ***\nORIGIN_SZSBSZ05 -0.0036863  0.0068459    -0.538  0.59026    \nORIGIN_SZSBSZ06 -1.1939284  0.0181541   -65.766  &lt; 2e-16 ***\nORIGIN_SZSBSZ07 -0.4896579  0.0135618   -36.106  &lt; 2e-16 ***\nORIGIN_SZSBSZ08 -2.1221691  0.0127258  -166.762  &lt; 2e-16 ***\nORIGIN_SZSBSZ09 -1.2032410  0.0089611  -134.273  &lt; 2e-16 ***\nORIGIN_SZSESZ02  1.0721820  0.0045336   236.498  &lt; 2e-16 ***\nORIGIN_SZSESZ03  1.0808012  0.0042923   251.801  &lt; 2e-16 ***\nORIGIN_SZSESZ04  1.0137448  0.0050668   200.076  &lt; 2e-16 ***\nORIGIN_SZSESZ05 -0.1678679  0.0060206   -27.882  &lt; 2e-16 ***\nORIGIN_SZSESZ06  0.9165834  0.0048323   189.677  &lt; 2e-16 ***\nORIGIN_SZSESZ07 -2.2499789  0.0196327  -114.603  &lt; 2e-16 ***\nORIGIN_SZSGSZ01 -0.9369800  0.0087282  -107.351  &lt; 2e-16 ***\nORIGIN_SZSGSZ02 -1.1690716  0.0097131  -120.360  &lt; 2e-16 ***\nORIGIN_SZSGSZ03  0.2604352  0.0052709    49.410  &lt; 2e-16 ***\nORIGIN_SZSGSZ04  0.3468823  0.0048897    70.942  &lt; 2e-16 ***\nORIGIN_SZSGSZ05 -1.5927797  0.0106308  -149.827  &lt; 2e-16 ***\nORIGIN_SZSGSZ06  0.3605651  0.0046361    77.774  &lt; 2e-16 ***\nORIGIN_SZSGSZ07 -0.5333873  0.0063119   -84.504  &lt; 2e-16 ***\nORIGIN_SZSKSZ01 -0.2706750  0.0082836   -32.676  &lt; 2e-16 ***\nORIGIN_SZSKSZ02  0.0970953  0.0063378    15.320  &lt; 2e-16 ***\nORIGIN_SZSKSZ03 -0.6954342  0.0082538   -84.256  &lt; 2e-16 ***\nORIGIN_SZSKSZ04 -2.3863580  0.0284607   -83.847  &lt; 2e-16 ***\nORIGIN_SZSKSZ05 -1.5443140  0.0179059   -86.246  &lt; 2e-16 ***\nORIGIN_SZSLSZ01 -2.9450656  0.0307283   -95.842  &lt; 2e-16 ***\nORIGIN_SZSLSZ04 -0.5739349  0.0077851   -73.722  &lt; 2e-16 ***\nORIGIN_SZSRSZ01 -1.6136735  0.0160199  -100.729  &lt; 2e-16 ***\nORIGIN_SZTHSZ01 -2.6034976  0.0489378   -53.200  &lt; 2e-16 ***\nORIGIN_SZTHSZ03 -1.2770601  0.0229815   -55.569  &lt; 2e-16 ***\nORIGIN_SZTHSZ04 -2.0110399  0.0287527   -69.943  &lt; 2e-16 ***\nORIGIN_SZTHSZ06 -1.7720116  0.0180394   -98.230  &lt; 2e-16 ***\nORIGIN_SZTMSZ01  0.1254729  0.0060924    20.595  &lt; 2e-16 ***\nORIGIN_SZTMSZ02  1.6667504  0.0039836   418.403  &lt; 2e-16 ***\nORIGIN_SZTMSZ03  1.0941176  0.0042911   254.976  &lt; 2e-16 ***\nORIGIN_SZTMSZ04  0.3209520  0.0050349    63.746  &lt; 2e-16 ***\nORIGIN_SZTMSZ05 -0.8155124  0.0079342  -102.785  &lt; 2e-16 ***\nORIGIN_SZTNSZ01 -1.4237298  0.0104636  -136.064  &lt; 2e-16 ***\nORIGIN_SZTNSZ02 -1.2718890  0.0098660  -128.916  &lt; 2e-16 ***\nORIGIN_SZTNSZ03 -1.7960517  0.0134675  -133.362  &lt; 2e-16 ***\nORIGIN_SZTNSZ04 -0.3508142  0.0073556   -47.694  &lt; 2e-16 ***\nORIGIN_SZTPSZ01 -0.3841699  0.0064137   -59.898  &lt; 2e-16 ***\nORIGIN_SZTPSZ02  0.5315265  0.0044497   119.451  &lt; 2e-16 ***\nORIGIN_SZTPSZ03 -0.4669723  0.0062160   -75.124  &lt; 2e-16 ***\nORIGIN_SZTPSZ04 -0.0617169  0.0058830   -10.491  &lt; 2e-16 ***\nORIGIN_SZTPSZ05  0.0713309  0.0062133    11.480  &lt; 2e-16 ***\nORIGIN_SZTPSZ06  0.6800356  0.0069456    97.909  &lt; 2e-16 ***\nORIGIN_SZTPSZ07 -0.0432782  0.0064382    -6.722 1.79e-11 ***\nORIGIN_SZTPSZ08 -0.6976429  0.0092416   -75.490  &lt; 2e-16 ***\nORIGIN_SZTPSZ09 -0.3708833  0.0063548   -58.363  &lt; 2e-16 ***\nORIGIN_SZTPSZ10 -0.4063575  0.0077803   -52.229  &lt; 2e-16 ***\nORIGIN_SZTPSZ11  0.1040282  0.0056115    18.538  &lt; 2e-16 ***\nORIGIN_SZTPSZ12 -0.5104672  0.0066261   -77.039  &lt; 2e-16 ***\nORIGIN_SZTSSZ01 -3.5036830  0.0487290   -71.901  &lt; 2e-16 ***\nORIGIN_SZTSSZ02 -0.0386819  0.0094886    -4.077 4.57e-05 ***\nORIGIN_SZTSSZ03 -0.3862387  0.0095139   -40.597  &lt; 2e-16 ***\nORIGIN_SZTSSZ04 -0.6380676  0.0099905   -63.867  &lt; 2e-16 ***\nORIGIN_SZTSSZ05 -2.7354613  0.0162414  -168.425  &lt; 2e-16 ***\nORIGIN_SZTSSZ06 -2.6310865  0.0255772  -102.868  &lt; 2e-16 ***\nORIGIN_SZWCSZ01 -1.1561047  0.0087394  -132.286  &lt; 2e-16 ***\nORIGIN_SZWCSZ02 -2.6956217  0.0319117   -84.471  &lt; 2e-16 ***\nORIGIN_SZWCSZ03 -4.3526889  0.1241082   -35.072  &lt; 2e-16 ***\nORIGIN_SZWDSZ01  0.8712417  0.0043720   199.277  &lt; 2e-16 ***\nORIGIN_SZWDSZ02  0.9119539  0.0050326   181.210  &lt; 2e-16 ***\nORIGIN_SZWDSZ03  1.6205678  0.0045250   358.136  &lt; 2e-16 ***\nORIGIN_SZWDSZ04  1.2081941  0.0054272   222.618  &lt; 2e-16 ***\nORIGIN_SZWDSZ05  0.4284783  0.0052752    81.224  &lt; 2e-16 ***\nORIGIN_SZWDSZ06  0.9018716  0.0049820   181.028  &lt; 2e-16 ***\nORIGIN_SZWDSZ07 -0.6444820  0.0084731   -76.062  &lt; 2e-16 ***\nORIGIN_SZWDSZ08 -0.8764983  0.0082622  -106.085  &lt; 2e-16 ***\nORIGIN_SZWDSZ09  1.3292589  0.0048663   273.158  &lt; 2e-16 ***\nORIGIN_SZYSSZ01 -0.4780462  0.0058489   -81.733  &lt; 2e-16 ***\nORIGIN_SZYSSZ02  0.9323419  0.0054402   171.380  &lt; 2e-16 ***\nORIGIN_SZYSSZ03  2.0577240  0.0046737   440.274  &lt; 2e-16 ***\nORIGIN_SZYSSZ04  0.8697472  0.0047269   184.000  &lt; 2e-16 ***\nORIGIN_SZYSSZ05  0.1662764  0.0060376    27.540  &lt; 2e-16 ***\nORIGIN_SZYSSZ06 -0.8115617  0.0109084   -74.398  &lt; 2e-16 ***\nORIGIN_SZYSSZ07 -0.8971248  0.0119220   -75.250  &lt; 2e-16 ***\nORIGIN_SZYSSZ08 -0.2738680  0.0063553   -43.093  &lt; 2e-16 ***\nORIGIN_SZYSSZ09  1.2274518  0.0044951   273.066  &lt; 2e-16 ***\nDESTIN_SZAMSZ02 -0.0516322  0.0042829   -12.055  &lt; 2e-16 ***\nDESTIN_SZAMSZ03  0.0801823  0.0041904    19.135  &lt; 2e-16 ***\nDESTIN_SZAMSZ04 -0.9282211  0.0061322  -151.368  &lt; 2e-16 ***\nDESTIN_SZAMSZ05 -1.0794168  0.0062543  -172.588  &lt; 2e-16 ***\nDESTIN_SZAMSZ06 -0.8839603  0.0060851  -145.267  &lt; 2e-16 ***\nDESTIN_SZAMSZ07 -1.5835093  0.0096846  -163.508  &lt; 2e-16 ***\nDESTIN_SZAMSZ08 -0.9756903  0.0068829  -141.756  &lt; 2e-16 ***\nDESTIN_SZAMSZ09 -1.0362692  0.0061651  -168.087  &lt; 2e-16 ***\nDESTIN_SZAMSZ10 -0.1227646  0.0044788   -27.410  &lt; 2e-16 ***\nDESTIN_SZAMSZ11 -0.4802374  0.0088108   -54.506  &lt; 2e-16 ***\nDESTIN_SZAMSZ12  0.2142621  0.0050653    42.300  &lt; 2e-16 ***\nDESTIN_SZBDSZ01  0.3582789  0.0039578    90.524  &lt; 2e-16 ***\nDESTIN_SZBDSZ02 -0.4368229  0.0051384   -85.012  &lt; 2e-16 ***\nDESTIN_SZBDSZ03 -0.1568727  0.0044329   -35.388  &lt; 2e-16 ***\nDESTIN_SZBDSZ04  0.6731669  0.0036215   185.882  &lt; 2e-16 ***\nDESTIN_SZBDSZ05  0.3647198  0.0040496    90.062  &lt; 2e-16 ***\nDESTIN_SZBDSZ06  0.0589240  0.0044352    13.286  &lt; 2e-16 ***\nDESTIN_SZBDSZ07 -0.6648168  0.0095742   -69.438  &lt; 2e-16 ***\nDESTIN_SZBDSZ08 -1.7214136  0.0106600  -161.483  &lt; 2e-16 ***\nDESTIN_SZBKSZ01 -1.2688264  0.0067263  -188.637  &lt; 2e-16 ***\nDESTIN_SZBKSZ02 -0.3912129  0.0055446   -70.558  &lt; 2e-16 ***\nDESTIN_SZBKSZ03 -0.8663392  0.0058693  -147.605  &lt; 2e-16 ***\nDESTIN_SZBKSZ04 -0.1247273  0.0051254   -24.335  &lt; 2e-16 ***\nDESTIN_SZBKSZ05 -0.7407774  0.0059120  -125.300  &lt; 2e-16 ***\nDESTIN_SZBKSZ06 -0.9934643  0.0063345  -156.834  &lt; 2e-16 ***\nDESTIN_SZBKSZ07  0.0882230  0.0042928    20.551  &lt; 2e-16 ***\nDESTIN_SZBKSZ08 -1.1134447  0.0070752  -157.372  &lt; 2e-16 ***\nDESTIN_SZBKSZ09 -0.1788171  0.0051327   -34.839  &lt; 2e-16 ***\nDESTIN_SZBLSZ01 -0.7696433  0.0071898  -107.047  &lt; 2e-16 ***\nDESTIN_SZBLSZ02  0.4076650  0.0068001    59.950  &lt; 2e-16 ***\nDESTIN_SZBLSZ03  1.5398488  0.0078230   196.836  &lt; 2e-16 ***\nDESTIN_SZBLSZ04 -0.3499486  0.0136985   -25.546  &lt; 2e-16 ***\nDESTIN_SZBMSZ01 -0.2114705  0.0048311   -43.773  &lt; 2e-16 ***\nDESTIN_SZBMSZ02 -0.3316806  0.0049958   -66.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ03 -0.5134774  0.0058534   -87.723  &lt; 2e-16 ***\nDESTIN_SZBMSZ04 -0.2205274  0.0051028   -43.217  &lt; 2e-16 ***\nDESTIN_SZBMSZ05 -0.2101165  0.0067710   -31.032  &lt; 2e-16 ***\nDESTIN_SZBMSZ06 -1.3832385  0.0124821  -110.818  &lt; 2e-16 ***\nDESTIN_SZBMSZ07 -0.0133462  0.0046787    -2.853  0.00434 ** \nDESTIN_SZBMSZ08 -0.9056756  0.0063868  -141.805  &lt; 2e-16 ***\nDESTIN_SZBMSZ09 -2.3175407  0.0144523  -160.358  &lt; 2e-16 ***\nDESTIN_SZBMSZ10 -1.3973725  0.0090463  -154.470  &lt; 2e-16 ***\nDESTIN_SZBMSZ11 -1.3950206  0.0080459  -173.383  &lt; 2e-16 ***\nDESTIN_SZBMSZ12 -0.6882789  0.0081539   -84.411  &lt; 2e-16 ***\nDESTIN_SZBMSZ13 -0.2729120  0.0052969   -51.523  &lt; 2e-16 ***\nDESTIN_SZBMSZ14 -0.7581980  0.0080215   -94.521  &lt; 2e-16 ***\nDESTIN_SZBMSZ15 -0.9323237  0.0071093  -131.142  &lt; 2e-16 ***\nDESTIN_SZBMSZ16 -2.0655530  0.0108490  -190.391  &lt; 2e-16 ***\nDESTIN_SZBMSZ17 -2.5124893  0.0165366  -151.935  &lt; 2e-16 ***\nDESTIN_SZBPSZ01 -0.8203274  0.0057682  -142.216  &lt; 2e-16 ***\nDESTIN_SZBPSZ02 -1.5284265  0.0087447  -174.783  &lt; 2e-16 ***\nDESTIN_SZBPSZ03 -1.2434382  0.0080852  -153.792  &lt; 2e-16 ***\nDESTIN_SZBPSZ04 -0.7778558  0.0060900  -127.727  &lt; 2e-16 ***\nDESTIN_SZBPSZ05  0.1782204  0.0042331    42.101  &lt; 2e-16 ***\nDESTIN_SZBPSZ06 -0.6758807  0.0079728   -84.773  &lt; 2e-16 ***\nDESTIN_SZBPSZ07 -0.5029450  0.0081151   -61.976  &lt; 2e-16 ***\nDESTIN_SZBSSZ01 -0.1269916  0.0046949   -27.049  &lt; 2e-16 ***\nDESTIN_SZBSSZ02 -0.7536917  0.0051895  -145.233  &lt; 2e-16 ***\nDESTIN_SZBSSZ03  0.2747969  0.0039115    70.254  &lt; 2e-16 ***\nDESTIN_SZBTSZ01  0.1708577  0.0043381    39.385  &lt; 2e-16 ***\nDESTIN_SZBTSZ02 -0.6820190  0.0067243  -101.427  &lt; 2e-16 ***\nDESTIN_SZBTSZ03  0.0610599  0.0049825    12.255  &lt; 2e-16 ***\nDESTIN_SZBTSZ04 -1.3199639  0.0107063  -123.288  &lt; 2e-16 ***\nDESTIN_SZBTSZ05 -0.4174991  0.0069221   -60.314  &lt; 2e-16 ***\nDESTIN_SZBTSZ06 -0.5260242  0.0061145   -86.029  &lt; 2e-16 ***\nDESTIN_SZBTSZ07 -1.6678047  0.0106335  -156.844  &lt; 2e-16 ***\nDESTIN_SZBTSZ08 -0.7999935  0.0089175   -89.711  &lt; 2e-16 ***\nDESTIN_SZCBSZ01 -5.6321332  0.3162476   -17.809  &lt; 2e-16 ***\nDESTIN_SZCCSZ01 -0.9342781  0.0081409  -114.763  &lt; 2e-16 ***\nDESTIN_SZCHSZ01 -1.2808546  0.0096774  -132.355  &lt; 2e-16 ***\nDESTIN_SZCHSZ02  0.0067332  0.0054322     1.239  0.21516    \nDESTIN_SZCHSZ03  1.0988838  0.0041378   265.570  &lt; 2e-16 ***\nDESTIN_SZCKSZ01 -0.3192235  0.0050632   -63.048  &lt; 2e-16 ***\nDESTIN_SZCKSZ02 -0.7776453  0.0055279  -140.676  &lt; 2e-16 ***\nDESTIN_SZCKSZ03  0.2772358  0.0042541    65.170  &lt; 2e-16 ***\nDESTIN_SZCKSZ04 -1.3842048  0.0065159  -212.436  &lt; 2e-16 ***\nDESTIN_SZCKSZ05 -1.2051808  0.0076814  -156.897  &lt; 2e-16 ***\nDESTIN_SZCKSZ06  0.1321955  0.0061568    21.472  &lt; 2e-16 ***\nDESTIN_SZCLSZ01  0.1942449  0.0049977    38.867  &lt; 2e-16 ***\nDESTIN_SZCLSZ02 -2.0828648  0.0134597  -154.749  &lt; 2e-16 ***\nDESTIN_SZCLSZ03 -0.8823728  0.0078307  -112.681  &lt; 2e-16 ***\nDESTIN_SZCLSZ04 -0.2311432  0.0047194   -48.977  &lt; 2e-16 ***\nDESTIN_SZCLSZ05 -1.0113430  0.0085536  -118.237  &lt; 2e-16 ***\nDESTIN_SZCLSZ06  0.0694682  0.0042166    16.475  &lt; 2e-16 ***\nDESTIN_SZCLSZ07 -0.4953961  0.0054184   -91.429  &lt; 2e-16 ***\nDESTIN_SZCLSZ08 -0.3849563  0.0061404   -62.693  &lt; 2e-16 ***\nDESTIN_SZCLSZ09  0.4201808  0.0067112    62.609  &lt; 2e-16 ***\nDESTIN_SZDTSZ02 -2.6513032  0.0348725   -76.029  &lt; 2e-16 ***\nDESTIN_SZDTSZ03 -1.5192228  0.0144477  -105.153  &lt; 2e-16 ***\nDESTIN_SZDTSZ13 -2.2041951  0.0161726  -136.292  &lt; 2e-16 ***\nDESTIN_SZGLSZ01 -0.0139744  0.0052464    -2.664  0.00773 ** \nDESTIN_SZGLSZ02 -0.2850816  0.0047467   -60.059  &lt; 2e-16 ***\nDESTIN_SZGLSZ03  0.3511872  0.0039473    88.969  &lt; 2e-16 ***\nDESTIN_SZGLSZ04  0.2909117  0.0039436    73.769  &lt; 2e-16 ***\nDESTIN_SZGLSZ05  0.1845361  0.0040011    46.121  &lt; 2e-16 ***\nDESTIN_SZHGSZ01  0.1418382  0.0039875    35.571  &lt; 2e-16 ***\nDESTIN_SZHGSZ02 -0.7233151  0.0052374  -138.105  &lt; 2e-16 ***\nDESTIN_SZHGSZ03 -1.1918463  0.0062129  -191.834  &lt; 2e-16 ***\nDESTIN_SZHGSZ04 -0.4380360  0.0044839   -97.691  &lt; 2e-16 ***\nDESTIN_SZHGSZ05 -0.5671024  0.0046427  -122.149  &lt; 2e-16 ***\nDESTIN_SZHGSZ06 -0.8271411  0.0054935  -150.566  &lt; 2e-16 ***\nDESTIN_SZHGSZ07  0.0721800  0.0041589    17.356  &lt; 2e-16 ***\nDESTIN_SZHGSZ08 -0.4297429  0.0050021   -85.913  &lt; 2e-16 ***\nDESTIN_SZHGSZ09 -0.2085461  0.0052544   -39.690  &lt; 2e-16 ***\nDESTIN_SZHGSZ10 -2.9169699  0.0262698  -111.039  &lt; 2e-16 ***\nDESTIN_SZJESZ01 -0.2822473  0.0051166   -55.163  &lt; 2e-16 ***\nDESTIN_SZJESZ02 -0.6761389  0.0053635  -126.063  &lt; 2e-16 ***\nDESTIN_SZJESZ03 -0.7371756  0.0058983  -124.980  &lt; 2e-16 ***\nDESTIN_SZJESZ04 -0.4593491  0.0067970   -67.581  &lt; 2e-16 ***\nDESTIN_SZJESZ05 -1.1418012  0.0099049  -115.277  &lt; 2e-16 ***\nDESTIN_SZJESZ06  0.1759680  0.0042791    41.123  &lt; 2e-16 ***\nDESTIN_SZJESZ07 -1.2260587  0.0082714  -148.229  &lt; 2e-16 ***\nDESTIN_SZJESZ08 -0.8547001  0.0080417  -106.283  &lt; 2e-16 ***\nDESTIN_SZJESZ09 -0.4306353  0.0057006   -75.542  &lt; 2e-16 ***\nDESTIN_SZJESZ10  0.6584971  0.0073664    89.392  &lt; 2e-16 ***\nDESTIN_SZJESZ11  0.9661208  0.0070491   137.056  &lt; 2e-16 ***\nDESTIN_SZJWSZ01 -0.9128436  0.0069529  -131.290  &lt; 2e-16 ***\nDESTIN_SZJWSZ02 -0.7285851  0.0054839  -132.859  &lt; 2e-16 ***\nDESTIN_SZJWSZ03  0.2601455  0.0043215    60.198  &lt; 2e-16 ***\nDESTIN_SZJWSZ04  0.6860274  0.0041135   166.775  &lt; 2e-16 ***\nDESTIN_SZJWSZ05 -0.4684576  0.0062875   -74.506  &lt; 2e-16 ***\nDESTIN_SZJWSZ06 -0.2459774  0.0057575   -42.723  &lt; 2e-16 ***\nDESTIN_SZJWSZ07 -1.8854234  0.0287721   -65.529  &lt; 2e-16 ***\nDESTIN_SZJWSZ08 -0.5523308  0.0051054  -108.186  &lt; 2e-16 ***\nDESTIN_SZJWSZ09  0.8818747  0.0037800   233.301  &lt; 2e-16 ***\nDESTIN_SZKLSZ01 -0.5814386  0.0052711  -110.308  &lt; 2e-16 ***\nDESTIN_SZKLSZ02 -0.7090577  0.0058161  -121.914  &lt; 2e-16 ***\nDESTIN_SZKLSZ03 -1.2191910  0.0065984  -184.772  &lt; 2e-16 ***\nDESTIN_SZKLSZ04 -1.6961428  0.0087866  -193.038  &lt; 2e-16 ***\nDESTIN_SZKLSZ05 -0.6927144  0.0073574   -94.153  &lt; 2e-16 ***\nDESTIN_SZKLSZ06 -2.2967464  0.0362605   -63.340  &lt; 2e-16 ***\nDESTIN_SZKLSZ07 -0.9536980  0.0066777  -142.819  &lt; 2e-16 ***\nDESTIN_SZKLSZ08 -0.4565596  0.0051736   -88.249  &lt; 2e-16 ***\nDESTIN_SZLKSZ01 -1.7277135  0.0207336   -83.329  &lt; 2e-16 ***\nDESTIN_SZMDSZ01 -1.7155417  0.0210080   -81.661  &lt; 2e-16 ***\nDESTIN_SZMDSZ02 -1.3694928  0.0114174  -119.948  &lt; 2e-16 ***\nDESTIN_SZMDSZ03 -2.7183729  0.0252678  -107.582  &lt; 2e-16 ***\nDESTIN_SZMPSZ01 -0.8051991  0.0078564  -102.490  &lt; 2e-16 ***\nDESTIN_SZMPSZ02 -0.7627000  0.0061386  -124.246  &lt; 2e-16 ***\nDESTIN_SZMPSZ03 -0.0649484  0.0047787   -13.591  &lt; 2e-16 ***\nDESTIN_SZMUSZ02 -1.9549128  0.0200160   -97.667  &lt; 2e-16 ***\nDESTIN_SZNTSZ01 -3.3048398  0.0448053   -73.760  &lt; 2e-16 ***\nDESTIN_SZNTSZ02 -1.6454847  0.0109337  -150.497  &lt; 2e-16 ***\nDESTIN_SZNTSZ03 -1.1389723  0.0077396  -147.161  &lt; 2e-16 ***\nDESTIN_SZNTSZ05 -2.0264109  0.0250226   -80.983  &lt; 2e-16 ***\nDESTIN_SZNTSZ06 -3.3496282  0.0428989   -78.082  &lt; 2e-16 ***\nDESTIN_SZNVSZ01 -0.3407614  0.0045493   -74.905  &lt; 2e-16 ***\nDESTIN_SZNVSZ02 -0.4987695  0.0053942   -92.465  &lt; 2e-16 ***\nDESTIN_SZNVSZ03 -0.4936107  0.0055158   -89.491  &lt; 2e-16 ***\nDESTIN_SZNVSZ04 -1.9141281  0.0107557  -177.964  &lt; 2e-16 ***\nDESTIN_SZNVSZ05 -1.5378263  0.0089577  -171.677  &lt; 2e-16 ***\nDESTIN_SZPGSZ01 -1.7744485  0.0194346   -91.304  &lt; 2e-16 ***\nDESTIN_SZPGSZ02 -0.9282918  0.0069006  -134.523  &lt; 2e-16 ***\nDESTIN_SZPGSZ03  0.0885025  0.0042145    21.000  &lt; 2e-16 ***\nDESTIN_SZPGSZ04 -0.3879375  0.0046862   -82.784  &lt; 2e-16 ***\nDESTIN_SZPGSZ05 -0.9649873  0.0074625  -129.311  &lt; 2e-16 ***\nDESTIN_SZPLSZ01 -0.6159175  0.0070845   -86.939  &lt; 2e-16 ***\nDESTIN_SZPLSZ02 -1.7551386  0.0133081  -131.885  &lt; 2e-16 ***\nDESTIN_SZPLSZ03 -0.1378379  0.0098704   -13.965  &lt; 2e-16 ***\nDESTIN_SZPLSZ04 -0.1411200  0.0096446   -14.632  &lt; 2e-16 ***\nDESTIN_SZPLSZ05 -0.8483196  0.0119048   -71.259  &lt; 2e-16 ***\nDESTIN_SZPNSZ01 -0.1579087  0.0057330   -27.544  &lt; 2e-16 ***\nDESTIN_SZPNSZ02  1.0243480  0.0076680   133.587  &lt; 2e-16 ***\nDESTIN_SZPNSZ03  0.0451598  0.0081444     5.545 2.94e-08 ***\nDESTIN_SZPNSZ04  1.8941928  0.0087479   216.530  &lt; 2e-16 ***\nDESTIN_SZPNSZ05  1.0341581  0.0130830    79.046  &lt; 2e-16 ***\nDESTIN_SZPRSZ01 -1.4038513  0.0086911  -161.527  &lt; 2e-16 ***\nDESTIN_SZPRSZ02 -0.4942539  0.0052403   -94.319  &lt; 2e-16 ***\nDESTIN_SZPRSZ03  0.4219510  0.0040281   104.751  &lt; 2e-16 ***\nDESTIN_SZPRSZ04 -0.4841099  0.0083498   -57.979  &lt; 2e-16 ***\nDESTIN_SZPRSZ05 -0.2988481  0.0047512   -62.899  &lt; 2e-16 ***\nDESTIN_SZPRSZ06  0.0012333  0.0054530     0.226  0.82108    \nDESTIN_SZPRSZ07 -1.1417482  0.0118845   -96.070  &lt; 2e-16 ***\nDESTIN_SZPRSZ08 -0.8259249  0.0066757  -123.720  &lt; 2e-16 ***\nDESTIN_SZQTSZ01 -1.2134330  0.0089222  -136.002  &lt; 2e-16 ***\nDESTIN_SZQTSZ02 -1.2397956  0.0074512  -166.388  &lt; 2e-16 ***\nDESTIN_SZQTSZ03 -0.7448659  0.0066511  -111.992  &lt; 2e-16 ***\nDESTIN_SZQTSZ04 -0.6243112  0.0066812   -93.443  &lt; 2e-16 ***\nDESTIN_SZQTSZ05 -0.6102589  0.0060458  -100.940  &lt; 2e-16 ***\nDESTIN_SZQTSZ06 -0.9164592  0.0065095  -140.788  &lt; 2e-16 ***\nDESTIN_SZQTSZ07 -1.4600643  0.0109976  -132.762  &lt; 2e-16 ***\nDESTIN_SZQTSZ08  0.0004582  0.0050178     0.091  0.92724    \nDESTIN_SZQTSZ09 -0.5226213  0.0058901   -88.728  &lt; 2e-16 ***\nDESTIN_SZQTSZ10 -0.3867082  0.0055876   -69.208  &lt; 2e-16 ***\nDESTIN_SZQTSZ11  0.0260589  0.0055065     4.732 2.22e-06 ***\nDESTIN_SZQTSZ12 -0.3387634  0.0072779   -46.547  &lt; 2e-16 ***\nDESTIN_SZQTSZ13 -0.0512118  0.0053664    -9.543  &lt; 2e-16 ***\nDESTIN_SZQTSZ14 -0.2555346  0.0063792   -40.057  &lt; 2e-16 ***\nDESTIN_SZQTSZ15 -0.1820651  0.0077537   -23.481  &lt; 2e-16 ***\nDESTIN_SZRCSZ01 -0.4641196  0.0072515   -64.003  &lt; 2e-16 ***\nDESTIN_SZRCSZ06 -2.0929548  0.0189106  -110.676  &lt; 2e-16 ***\nDESTIN_SZRVSZ01 -1.7885682  0.0163492  -109.398  &lt; 2e-16 ***\nDESTIN_SZRVSZ02 -3.1669721  0.0326320   -97.051  &lt; 2e-16 ***\nDESTIN_SZRVSZ03 -2.0306835  0.0135749  -149.591  &lt; 2e-16 ***\nDESTIN_SZRVSZ04 -1.5113470  0.0155637   -97.107  &lt; 2e-16 ***\nDESTIN_SZRVSZ05 -2.3683855  0.0259334   -91.326  &lt; 2e-16 ***\nDESTIN_SZSBSZ01 -0.5841063  0.0068588   -85.162  &lt; 2e-16 ***\nDESTIN_SZSBSZ02 -1.0777704  0.0078288  -137.667  &lt; 2e-16 ***\nDESTIN_SZSBSZ03  0.4734371  0.0045880   103.190  &lt; 2e-16 ***\nDESTIN_SZSBSZ04  0.0546094  0.0057517     9.494  &lt; 2e-16 ***\nDESTIN_SZSBSZ05 -0.9588198  0.0075242  -127.431  &lt; 2e-16 ***\nDESTIN_SZSBSZ06 -1.8528944  0.0234040   -79.170  &lt; 2e-16 ***\nDESTIN_SZSBSZ07 -1.8403768  0.0195878   -93.955  &lt; 2e-16 ***\nDESTIN_SZSBSZ08  0.9205969  0.0055698   165.285  &lt; 2e-16 ***\nDESTIN_SZSBSZ09  0.5166486  0.0051939    99.472  &lt; 2e-16 ***\nDESTIN_SZSESZ02 -0.5728211  0.0048270  -118.669  &lt; 2e-16 ***\nDESTIN_SZSESZ03  0.2554787  0.0038335    66.645  &lt; 2e-16 ***\nDESTIN_SZSESZ04 -0.8982794  0.0056698  -158.432  &lt; 2e-16 ***\nDESTIN_SZSESZ05 -0.4661655  0.0048578   -95.962  &lt; 2e-16 ***\nDESTIN_SZSESZ06 -0.8392849  0.0059198  -141.777  &lt; 2e-16 ***\nDESTIN_SZSESZ07 -3.2182325  0.0227089  -141.717  &lt; 2e-16 ***\nDESTIN_SZSGSZ01 -0.2751206  0.0059581   -46.176  &lt; 2e-16 ***\nDESTIN_SZSGSZ02 -0.2951806  0.0052515   -56.209  &lt; 2e-16 ***\nDESTIN_SZSGSZ03 -0.4469508  0.0048181   -92.766  &lt; 2e-16 ***\nDESTIN_SZSGSZ04 -0.2842809  0.0047961   -59.274  &lt; 2e-16 ***\nDESTIN_SZSGSZ05 -2.0643753  0.0098252  -210.109  &lt; 2e-16 ***\nDESTIN_SZSGSZ06  0.2501247  0.0038873    64.343  &lt; 2e-16 ***\nDESTIN_SZSGSZ07 -0.5743750  0.0052184  -110.067  &lt; 2e-16 ***\nDESTIN_SZSISZ01 -1.1030669  0.0259113   -42.571  &lt; 2e-16 ***\nDESTIN_SZSKSZ01 -0.5462538  0.0071443   -76.460  &lt; 2e-16 ***\nDESTIN_SZSKSZ02  0.2965180  0.0056707    52.290  &lt; 2e-16 ***\nDESTIN_SZSKSZ03 -0.4521490  0.0062177   -72.719  &lt; 2e-16 ***\nDESTIN_SZSKSZ04 -0.6665145  0.0148252   -44.958  &lt; 2e-16 ***\nDESTIN_SZSKSZ05 -0.1474142  0.0121958   -12.087  &lt; 2e-16 ***\nDESTIN_SZSLSZ01 -0.8855715  0.0084587  -104.693  &lt; 2e-16 ***\nDESTIN_SZSLSZ04 -1.1787840  0.0071355  -165.200  &lt; 2e-16 ***\nDESTIN_SZSRSZ01 -1.6435064  0.0128822  -127.580  &lt; 2e-16 ***\nDESTIN_SZTHSZ01 -3.4388625  0.0367651   -93.536  &lt; 2e-16 ***\nDESTIN_SZTHSZ03 -2.5809435  0.0256853  -100.483  &lt; 2e-16 ***\nDESTIN_SZTHSZ04 -2.4887189  0.0214441  -116.056  &lt; 2e-16 ***\nDESTIN_SZTHSZ06 -1.7965101  0.0152160  -118.067  &lt; 2e-16 ***\nDESTIN_SZTMSZ01 -0.3251891  0.0058067   -56.002  &lt; 2e-16 ***\nDESTIN_SZTMSZ02  1.1558743  0.0034703   333.080  &lt; 2e-16 ***\nDESTIN_SZTMSZ03  0.4525619  0.0039244   115.319  &lt; 2e-16 ***\nDESTIN_SZTMSZ04  0.8223271  0.0040060   205.274  &lt; 2e-16 ***\nDESTIN_SZTMSZ05  0.3880619  0.0054308    71.456  &lt; 2e-16 ***\nDESTIN_SZTNSZ01 -0.9533112  0.0067853  -140.496  &lt; 2e-16 ***\nDESTIN_SZTNSZ02 -1.5909451  0.0097396  -163.348  &lt; 2e-16 ***\nDESTIN_SZTNSZ03 -1.6470771  0.0116598  -141.261  &lt; 2e-16 ***\nDESTIN_SZTNSZ04 -1.0686173  0.0069848  -152.993  &lt; 2e-16 ***\nDESTIN_SZTPSZ01 -0.5180183  0.0056886   -91.063  &lt; 2e-16 ***\nDESTIN_SZTPSZ02  0.2160781  0.0038283    56.443  &lt; 2e-16 ***\nDESTIN_SZTPSZ03 -0.2479956  0.0056651   -43.776  &lt; 2e-16 ***\nDESTIN_SZTPSZ04 -1.5015463  0.0072444  -207.271  &lt; 2e-16 ***\nDESTIN_SZTPSZ05 -0.9551144  0.0057981  -164.729  &lt; 2e-16 ***\nDESTIN_SZTPSZ06 -0.4846634  0.0074621   -64.950  &lt; 2e-16 ***\nDESTIN_SZTPSZ07 -1.9753440  0.0118295  -166.984  &lt; 2e-16 ***\nDESTIN_SZTPSZ08 -1.3455063  0.0086909  -154.817  &lt; 2e-16 ***\nDESTIN_SZTPSZ09 -0.3556620  0.0061296   -58.024  &lt; 2e-16 ***\nDESTIN_SZTPSZ10 -1.3213501  0.0085951  -153.733  &lt; 2e-16 ***\nDESTIN_SZTPSZ11 -0.3877006  0.0052409   -73.977  &lt; 2e-16 ***\nDESTIN_SZTPSZ12 -0.7064020  0.0062472  -113.075  &lt; 2e-16 ***\nDESTIN_SZTSSZ01 -0.8827157  0.0218327   -40.431  &lt; 2e-16 ***\nDESTIN_SZTSSZ02 -0.6067055  0.0115514   -52.522  &lt; 2e-16 ***\nDESTIN_SZTSSZ03  0.4380259  0.0086774    50.479  &lt; 2e-16 ***\nDESTIN_SZTSSZ04  0.4902124  0.0089922    54.515  &lt; 2e-16 ***\nDESTIN_SZTSSZ05  1.4336278  0.0093410   153.477  &lt; 2e-16 ***\nDESTIN_SZTSSZ06  0.9223573  0.0209024    44.127  &lt; 2e-16 ***\nDESTIN_SZWCSZ01  1.1559309  0.0051787   223.208  &lt; 2e-16 ***\nDESTIN_SZWCSZ02 -1.2664455  0.0126131  -100.407  &lt; 2e-16 ***\nDESTIN_SZWCSZ03 -2.7360882  0.0325753   -83.993  &lt; 2e-16 ***\nDESTIN_SZWDSZ01  0.8193492  0.0037301   219.657  &lt; 2e-16 ***\nDESTIN_SZWDSZ02 -0.7852474  0.0058655  -133.875  &lt; 2e-16 ***\nDESTIN_SZWDSZ03  0.5742422  0.0041884   137.104  &lt; 2e-16 ***\nDESTIN_SZWDSZ04 -0.8391525  0.0065075  -128.951  &lt; 2e-16 ***\nDESTIN_SZWDSZ05 -0.3510692  0.0057253   -61.319  &lt; 2e-16 ***\nDESTIN_SZWDSZ06  0.1358804  0.0043968    30.905  &lt; 2e-16 ***\nDESTIN_SZWDSZ07 -0.2207379  0.0066369   -33.259  &lt; 2e-16 ***\nDESTIN_SZWDSZ08 -0.0264655  0.0065065    -4.068 4.75e-05 ***\nDESTIN_SZWDSZ09 -0.2065828  0.0050524   -40.888  &lt; 2e-16 ***\nDESTIN_SZYSSZ01  0.7467996  0.0040979   182.238  &lt; 2e-16 ***\nDESTIN_SZYSSZ02 -0.3002718  0.0053434   -56.195  &lt; 2e-16 ***\nDESTIN_SZYSSZ03 -1.1087686  0.0057219  -193.778  &lt; 2e-16 ***\nDESTIN_SZYSSZ04 -0.3748076  0.0051481   -72.805  &lt; 2e-16 ***\nDESTIN_SZYSSZ05 -1.7909654  0.0102064  -175.475  &lt; 2e-16 ***\nDESTIN_SZYSSZ06 -1.8519179  0.0099601  -185.933  &lt; 2e-16 ***\nDESTIN_SZYSSZ07 -0.9246626  0.0118101   -78.294  &lt; 2e-16 ***\nDESTIN_SZYSSZ08  0.4403129  0.0041268   106.697  &lt; 2e-16 ***\nDESTIN_SZYSSZ09  0.0267012  0.0041393     6.451 1.11e-10 ***\nlog(dist)       -0.6721961  0.0001353 -4969.566  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 60796037  on 14733  degrees of freedom\nResidual deviance: 20988409  on 14175  degrees of freedom\nAIC: 21081154\n\nNumber of Fisher Scoring iterations: 7\n\n\nWe can examine how the constraints hold for destinations this time.\n\nCalcRSquared(dbcSIM$data$TRIPS, dbcSIM$fitted.values)\n\n[1] 0.5739638\n\n\nNotice that there is a relatively significant improvement in the R^2 value."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#model-comparison",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#model-comparison",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.9 Model comparison",
    "text": "8.9 Model comparison\nAnother useful measure of model performance for a continuous dependent variable is the Root Mean Squared Error (RMSE). In this section, we will use the compare_performance() function from the performance package to assess RMSE.\nFirst, we create a list called model_list using the code chunk below.\n\nmodel_list &lt;- list(unconstrained=uncSIM,\n                   originConstrained=orcSIM,\n                   destinationConstrained=decSIM,\n                   doublyConstrained=dbcSIM)\n\nNext, we compute the RMSE of all the models in model_list using the code chunk below.\n\ncompare_performance(model_list,\n                    metrics = \"RMSE\")\n\n# Comparison of Model Performance Indices\n\nName                   | Model |     RMSE\n-----------------------------------------\nunconstrained          |   glm | 4288.012\noriginConstrained      |   glm | 3659.954\ndestinationConstrained |   glm | 3389.556\ndoublyConstrained      |   glm | 3252.297\n\n\nThe print above reveals that doubly constrained SIM is the best model among all the four SIMs because it has the smallest RMSE value of 3252.3."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#visualize-fitted-values",
    "href": "Hands-on_Ex/Hands-on_Ex10/Hands-on_Ex102.html#visualize-fitted-values",
    "title": "Hands-on Exercise 10.2: Calibrate Spatial Interaction Models with R",
    "section": "8.10 Visualize fitted values",
    "text": "8.10 Visualize fitted values\nIn this section, we explore how to visualise the observed values and fitted values.\nFirstly we extract the fitted values from each model by using the code chunk below.\n\ndf &lt;- as.data.frame(uncSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\nNext, we will join the values to SIM_data data frame.\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(uncTRIPS = \"uncSIM$fitted.values\")\n\nRepeat the same step for Origin Constrained SIM (orcSIM).\n\ndf &lt;- as.data.frame(orcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(orcTRIPS = \"orcSIM$fitted.values\")\n\nRepeat the same step by for Destination Constrained SIM (i.e. decSIM).\n\ndf &lt;- as.data.frame(decSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(decTRIPS = \"decSIM$fitted.values\")\n\nRepeat the same step by for Doubly Constrained SIM (i.e. dbcSIM).\n\ndf &lt;- as.data.frame(dbcSIM$fitted.values) %&gt;%\n  round(digits = 0)\n\n\nSIM_data &lt;- SIM_data %&gt;%\n  cbind(df) %&gt;%\n  rename(dbcTRIPS = \"dbcSIM$fitted.values\")\n\n\nunc_p &lt;- ggplot(data = SIM_data,\n                aes(x = uncTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\norc_p &lt;- ggplot(data = SIM_data,\n                aes(x = orcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndec_p &lt;- ggplot(data = SIM_data,\n                aes(x = decTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\ndbc_p &lt;- ggplot(data = SIM_data,\n                aes(x = dbcTRIPS,\n                    y = TRIPS)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\nNow, we put all the graphs into a single visual for better comparison using the code chunk below.\n\nggarrange(unc_p, orc_p, dec_p, dbc_p,\n          ncol = 2,\n          nrow = 2)\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'"
  }
]